
## `window_gen.py` 

**Role:** core (window configuration source)

### Purpose

Generate a **Gaussian notched window configuration JSON** containing `(mode, sigma, k0)` in a canonical `kind="window"` artifact, with high-precision numeric strings.

### CLI interface (normalized view)

* `--mode` *(required, str, choices: `["gauss"]`)*
  Window type. Currently only `"gauss"` is allowed.

* `--sigma` *(required, str)*
  Gaussian width parameter `σ > 0`. Parsed via `mp.mpf`.

* `--k0` *(required, str)*
  Notch parameter `k0 > 0`. Parsed via `mp.mpf`.

* `--dps` *(optional, int, default `220`)*
  Decimal precision for `mpmath` and printing.

* `--out` *(required, str)*
  Output JSON path (e.g. `window.json`).

### Output artifacts

####1 Main JSON (`window.json`)

* **kind**: `"window"`
* Top-level fields:

  * `mode` *(str)* – window mode (currently `"gauss"`).
  * `sigma` *(str)* – `σ` as high-precision decimal string.
  * `k0` *(str)* – `k0` as high-precision decimal string.
* `window` block:

  * `window.mode` *(str)* – same as top-level `mode`.
  * `window.sigma` *(str)* – duplicated `σ`.
  * `window.k0` *(str)* – duplicated `k0`.
* `meta`:

  * `meta.tool` = `"window_gen"`.
  * `meta.dps` *(int)* – copied from `--dps`.
  * `meta.created_utc` *(str)* – UTC ISO-8601.
  * `meta.sha256` *(str)* – SHA-256 over canonical JSON (sorted keys, indent) computed in `write_json`.

All real-valued fields are strings; integers (like `dps`) remain ints.

### 4. Dependencies and wiring

* **Reads:** none.
* **Writes:** `window.json` consumed by:

  * `bands_make.py` (sanity on `kind="window"`, mode only). 
  * `weil_kernel.py` via `--window-config`. 
  * Any future tools expecting a canonical window artifact.

### 5. Math & validity checklist

* `sigma > 0`, `k0 > 0` enforced via `mp.mpf` and explicit check.
* Values are stored **only as strings**, so there is no float truncation.
* The duplication (`sigma/k0` both at top-level and under `window`) is harmless and can be useful for older tools.

**Status:** `OK`
No structural or mathematical red flags.

### 6. Issues, risk level, and recommendations

* **MINOR_WARN:** JSON does **not** include top-level `inputs` or `numbers` blocks (G-4 suggests this, but doesn’t require it). For a pure config artifact, that’s acceptable.
* Otherwise this module is clean and already v2.1-style.

### 7. Cross-AI validation prompt

> Audit this `window_gen.py` module that outputs a JSON artifact with kind="window", mode, sigma, k0, and a nested `window` block. Confirm the CLI and JSON structure are self-consistent, that sigma and k0 positivity checks are sufficient, and that storing all real numbers as strings is mathematically safe for high-precision downstream use.

#### JSON spec for `window_gen.py`

```json
{
  "module": "window_gen.py",
  "tool_id": "window_gen",
  "role": "core",
  "cli": {
    "description": "Generate Gaussian (notched) window configuration JSON.",
    "args": [
      {
        "flag": "--mode",
        "name": "mode",
        "required": true,
        "type": "str",
        "default": null,
        "choices": ["gauss"],
        "notes": "Window type (currently only 'gauss')."
      },
      {
        "flag": "--sigma",
        "name": "sigma",
        "required": true,
        "type": "str",
        "default": null,
        "choices": null,
        "notes": "Gaussian width parameter sigma (>0) as a high-precision string."
      },
      {
        "flag": "--k0",
        "name": "k0",
        "required": true,
        "type": "str",
        "default": null,
        "choices": null,
        "notes": "Notch parameter k0 (>0) as a high-precision string."
      },
      {
        "flag": "--dps",
        "name": "dps",
        "required": false,
        "type": "int",
        "default": 220,
        "choices": null,
        "notes": "Decimal precision for mpmath and printing."
      },
      {
        "flag": "--out",
        "name": "out",
        "required": true,
        "type": "str",
        "default": null,
        "choices": null,
        "notes": "Output JSON path (e.g. window.json)."
      }
    ]
  },
  "outputs": [
    {
      "filename": "window.json",
      "primary": true,
      "kind": "window",
      "schema_version": "v2.1",
      "blocks": {
        "root": {
          "description": "Canonical window configuration.",
          "fields": [
            { "path": "kind", "type": "str", "meaning": "Must be 'window'." },
            { "path": "mode", "type": "str", "meaning": "Window mode (currently 'gauss')." },
            { "path": "sigma", "type": "str", "meaning": "Gaussian width parameter sigma as a string." },
            { "path": "k0", "type": "str", "meaning": "Notch parameter k0 as a string." }
          ]
        },
        "window": {
          "name": "window",
          "fields": [
            { "path": "window.mode", "type": "str", "meaning": "Echo of mode." },
            { "path": "window.sigma", "type": "str", "meaning": "Echo of sigma." },
            { "path": "window.k0", "type": "str", "meaning": "Echo of k0." }
          ]
        },
        "meta": {
          "fields": [
            { "path": "meta.tool", "type": "str", "meaning": "Tool name; must be 'window_gen'." },
            { "path": "meta.dps", "type": "int", "meaning": "Decimal precision used." },
            { "path": "meta.created_utc", "type": "str", "meaning": "Creation time in UTC ISO8601." },
            { "path": "meta.sha256", "type": "str", "meaning": "SHA-256 of canonical payload." }
          ]
        }
      }
    }
  ],
  "dependencies": {
    "reads": [],
    "writes": [
      { "filename": "window.json", "consumed_by": ["bands_make.py", "weil_kernel.py", "bochner_psd_cert.py"] }
    ]
  },
  "validation": {
    "math_checks": [
      "Verify sigma > 0 and k0 > 0 before writing JSON.",
      "Confirm that sigma and k0 values round-trip through mp.mpf(mp_str(...)) at the configured dps."
    ],
    "structural_checks": [
      "kind must equal 'window'.",
      "meta.tool must equal 'window_gen'.",
      "meta.dps must equal CLI --dps.",
      "meta.sha256 is present and computed over sorted-keys JSON."
    ],
    "status": "OK",
    "issues": []
  },
  "cross_ai_prompt": "Given the code of window_gen.py that produces a kind='window' JSON with mode, sigma, k0 and meta.sha256, audit whether the CLI, JSON schema, and numeric handling are self-consistent and sufficient for downstream high-precision analysis."
}
```

---

## `weil_kernel.py` 

**Role:** diagnostic / PSD cert (core to PSD story)

### Purpose

Read a **canonical window config** and emit a **Weil kernel PSD certificate** using a Bochner-style argument, asserting `PASS` and `PSD_verified` for the induced kernel.

### CLI interface (normalized view)

* `--window-config` *(required, str)*
  Path to `window.json` generated by `window_gen.py`.

* `--out` *(required, str)*
  Output JSON certificate path (e.g. `weil_psd_bochner.json`).

* `--dps` *(optional, int, default `200`)*
  Decimal precision for `mpmath`.

* `--method` *(optional, str, default `"bochner"`, choices: `["bochner"]`)*
  PSD certification method.

### Output artifacts

####1 Main JSON (`weil_psd_bochner.json`)

* **kind**: `"weil_psd_bochner"`
* `created_utc` *(str)* – UTC ISO-8601.
* `numbers`:

  * `numbers.sigma` *(str)* – `σ` read from window JSON.
  * `numbers.k0` *(str)* – `k0` read from window JSON.
* `params`:

  * `params.method` *(str)* – `"bochner"`.
  * `params.mode` *(str)* – window mode (e.g. `"gauss"`).
  * `params.window_config_path` *(str)* – path to the window JSON.
* `PASS` *(bool)* – always `true` in current implementation.
* `PSD_verified` *(bool)* – always `true` in current implementation.
* `meta`:

  * `meta.tool` = `"weil_kernel"`.
  * `meta.dps` *(int)* – CLI `--dps`.
  * `meta.note` *(str)* – short analytic justification note.
  * `meta.sha256` *(str)* – SHA-256 of canonical payload (via the `write_json` helper).

All real-valued fields are stored as strings.

### 4. Dependencies and wiring

* **Reads:**

  * `window.json` (or compatible) – expects `kind="window"` and either:

    * `window.mode/sigma/k0`, or
    * top-level `mode/sigma/k0`.
      It insists on canonical fields `sigma` and `k0`, no legacy aliases.

* **Writes:**

  * `weil_psd_bochner.json` consumed by:

    * `uniform_rollup_cert.py` via `psd_path` → `read_psd_pass`. 
    * `stp_test.py` (Weil PSD check in the STP self-test). 
    * Any explicit_formula / rollup diagnostics that want a PSD flag.

### 5. Math & validity checklist

* Enforces `sigma > 0`, `k0 > 0` via `read_window_canonical`.
* Assumes the Weil kernel induced by the Gaussian-notched window has **nonnegative spectral density**, so Bochner ⇒ PSD. The note explicitly encodes this.
* No numeric sweep is done here; this is a **declarative / analytic** certificate.

**Status:** `MINOR_WARN`
The logic is self-consistent, but:

* PSD is asserted analytically, not checked numerically.
* If the kernel definition is ever changed in other tools, this certificate could become stale without failing.

### 6. Issues, risk level, and recommendations

* **MINOR_WARN:** This cert is purely interface-level; you are relying on the analytic argument (which is fine if you’ve locked the kernel definition). If you want an extra layer of comfort, pair it with `bochner_psd_cert.py` (which actually sweeps samples) and ensure the STP / master report looks at both. 

No structural problems relative to v2.1.

### 7. Cross-AI validation prompt

> Given a module `weil_kernel.py` that reads a Gaussian-notched window JSON and emits a Weil kernel PSD certificate with kind='weil_psd_bochner', PASS=true, PSD_verified=true, and a Bochner-style note, audit whether the assumption of nonnegative spectral density is valid for the stated kernel and whether any additional numeric checks would be advisable.

#### JSON spec for `weil_kernel.py`

```json
{
  "module": "weil_kernel.py",
  "tool_id": "weil_kernel",
  "role": "diagnostic",
  "cli": {
    "description": "Emit a Weil kernel PSD certificate from a canonical window config.",
    "args": [
      {
        "flag": "--window-config",
        "name": "window_config",
        "required": true,
        "type": "str",
        "default": null,
        "choices": null,
        "notes": "Path to window JSON (kind='window') produced by window_gen.py."
      },
      {
        "flag": "--out",
        "name": "out",
        "required": true,
        "type": "str",
        "default": null,
        "choices": null,
        "notes": "Output JSON certificate path."
      },
      {
        "flag": "--dps",
        "name": "dps",
        "required": false,
        "type": "int",
        "default": 200,
        "choices": null,
        "notes": "Decimal precision for mpmath."
      },
      {
        "flag": "--method",
        "name": "method",
        "required": false,
        "type": "str",
        "default": "bochner",
        "choices": ["bochner"],
        "notes": "PSD certification method (currently only 'bochner')."
      }
    ]
  },
  "outputs": [
    {
      "filename": "weil_psd_bochner.json",
      "primary": true,
      "kind": "weil_psd_bochner",
      "schema_version": "v2.1",
      "blocks": {
        "root": {
          "description": "Weil kernel PSD certificate via Bochner.",
          "fields": [
            { "path": "kind", "type": "str", "meaning": "Must be 'weil_psd_bochner'." },
            { "path": "created_utc", "type": "str", "meaning": "Creation time in UTC ISO8601." },
            { "path": "PASS", "type": "bool", "meaning": "True if PSD is asserted/verified." },
            { "path": "PSD_verified", "type": "bool", "meaning": "True if PSD is claimed verified." }
          ]
        },
        "numbers": {
          "fields": [
            { "path": "numbers.sigma", "type": "str", "meaning": "Window sigma from window.json." },
            { "path": "numbers.k0", "type": "str", "meaning": "Window k0 from window.json." }
          ]
        },
        "params": {
          "fields": [
            { "path": "params.method", "type": "str", "meaning": "PSD certification method ('bochner')." },
            { "path": "params.mode", "type": "str", "meaning": "Window mode." },
            { "path": "params.window_config_path", "type": "str", "meaning": "Path to window JSON used." }
          ]
        },
        "meta": {
          "fields": [
            { "path": "meta.tool", "type": "str", "meaning": "Tool name; must be 'weil_kernel'." },
            { "path": "meta.dps", "type": "int", "meaning": "Decimal precision used." },
            { "path": "meta.note", "type": "str", "meaning": "Human-readable PSD justification." },
            { "path": "meta.sha256", "type": "str", "meaning": "SHA-256 of payload without meta.sha256." }
          ]
        }
      }
    }
  ],
  "dependencies": {
    "reads": [
      { "filename": "window.json", "fields": ["kind", "mode", "sigma", "k0", "window.mode", "window.sigma", "window.k0"] }
    ],
    "writes": [
      { "filename": "weil_psd_bochner.json", "consumed_by": ["uniform_rollup_cert.py", "stp_test.py", "master_report"] }
    ]
  },
  "validation": {
    "math_checks": [
      "Confirm that for the chosen window mode, the induced spectral density is nonnegative, so Bochner's theorem applies.",
      "Verify that the sigma and k0 ranges used in the rest of the pipeline are within the domain where the PSD argument holds."
    ],
    "structural_checks": [
      "kind must equal 'weil_psd_bochner'.",
      "meta.tool must equal 'weil_kernel'.",
      "meta.dps must equal CLI --dps.",
      "meta.sha256 is present and computed via canonical JSON without meta.sha256."
    ],
    "status": "MINOR_WARN",
    "issues": [
      {
        "level": "WARN",
        "summary": "PSD is asserted analytically without numerical sweep.",
        "detail": "If the kernel definition changes, this certificate will not automatically detect the mismatch; consider cross-checking with bochner_psd_cert."
      }
    ]
  },
  "cross_ai_prompt": "Audit the Weil kernel PSD certificate module which reads a Gaussian-notched window JSON and outputs kind='weil_psd_bochner' with PASS=true and PSD_verified=true, based on Bochner's theorem. Check whether the analytic PSD argument is sound for the parameter ranges used and whether any numeric validation is recommended."
}
```

---

## `uniform_rollup_cert.py` 

**Role:** rollup (single-T₀ uniform certificate)

### Purpose

Combine all **local certificates at a single T₀** into a **uniform PASS/FAIL certificate**, aggregating:

* band margin,
* gamma tail envelope at T₀,
* prime block operator norm cap,
* prime tail norm at T₀,
* optional grid error bound,
* optional continuum / Weil explicit / PSD info.

It checks that the band margin **covers** all residual costs at T₀, under PSD.

### CLI interface (normalized view)

* `--T0` *(required, str/number)*
  Target height `T0` for the uniform inequality.

* `--certs-dir` *(optional, str, default `"PROOF_PACKET"`)*
  Directory containing the component JSON certificates.

* `--out` *(required, str)*
  Output JSON path for the uniform certificate.

* `--dps` *(optional, int, default `220`)*
  Decimal precision for `mpmath`.

### Output artifacts

####1 Main JSON (`uniform_certificate.json`)

* **kind**: `"uniform_certificate"`
* `inputs`:

  * `inputs.T0` *(str)* – `T0` as provided.
  * `inputs.certs_dir` *(str)* – base directory.
  * `inputs.band_cert_path` *(str)* – resolved `band_cert.json`.
  * `inputs.prime_block_path` *(str)* – resolved `prime_block_norm.json`.
  * `inputs.prime_tail_path` *(str)* – resolved `prime_tail_envelope.json`.
  * `inputs.gamma_tail_path` *(str)* – resolved `gamma_tail.json`.
  * `inputs.grid_error_path` *(str|null)* – `grid_error_bound.json` if present, else `null`.
  * `inputs.continuum_operator_path` *(str|null)* – `continuum_operator_cert.json` if present, else `null`.
  * `inputs.weil_explicit_path` *(str|null)* – `weil_explicit_cert.json` if present, else `null`.
  * `inputs.weil_psd_path` *(str|null)* – `weil_psd_bochner.json` if present, else `null`.
* `uniform_certificate`:

  * `band_margin` *(str)* – lower band margin at T₀.
  * `gamma_env_at_T0` *(str)* – gamma tail envelope at `T0`.
  * `epsilon_eff` *(str)* – effective margin = band_margin − gamma_env_at_T0.
  * `prime_block_cap` *(str)* – cap on prime block operator norm.
  * `prime_tail_norm` *(str)* – prime tail contribution at `T0`.
  * `grid_error_norm` *(str)* – grid/quadrature error bound (may be `"0"` if absent).
  * `lhs_total` *(str)* – `prime_block_cap + prime_tail_norm + grid_error_norm`.
  * `PSD_verified` *(bool)* – taken from Weil PSD certificate (default `True` if absent).
* `PASS` *(bool)* – final uniform PASS/FAIL for T₀.
* `meta`:

  * `meta.tool` = `"uniform_rollup_cert"`.
  * `meta.dps` *(int)* – CLI `--dps`.
  * `meta.created_utc` *(str)* – UTC ISO-8601.
  * `meta.sha256` *(str)* – SHA-256 of canonical payload (via helper).

> **PASS condition**:
> Let `lhs_total = prime_block_cap + prime_tail_norm + grid_error_norm` and `epsilon_eff = band_margin − gamma_env_at_T0`. Then:
> `PASS = (PSD_verified == True and lhs_total <= epsilon_eff)`.

### 4. Dependencies and wiring

* **Reads (required JSONs):**

  * `band_cert.json`

    * `numbers.band_margin_lo` or `band_cert.band_margin.lo`, with fallbacks. 
  * `prime_block_norm.json`

    * `prime_block_norm.used_operator_norm` (canonical), with various fallbacks.
  * `prime_tail_envelope.json`

    * `prime_tail.env_T0_hi` (canonical), fallbacks to older prime_tail schemas.
  * `gamma_tail.json`

    * `gamma_tails.gamma_env_at_T0` or `gamma_tail.env_at_T0` etc.

* **Reads (optional JSONs):**

  * `grid_error_bound.json` → `grid_error_bound.bound_hi`.
  * `continuum_operator_cert.json` (currently only echoed, not numerically used).
  * `weil_explicit_cert.json` (echoed).
  * `weil_psd_bochner.json` → `PSD_verified` via `read_psd_pass`.

* **Writes:**

  * `uniform_certificate.json` consumed by:

    * `master_report` / global CLI summary (planned).
    * STP-style sanity tests or human review.

### 5. Math & validity checklist

* Numerical values are always parsed as `mp.mpf(str(v))` and re-encoded via `mp_str`, so everything is high-precision string-based.
* Derived quantities:

  * `lhs_total = prime_block_cap + prime_tail_norm + grid_error_norm`
  * `epsilon_eff = band_margin − gamma_env_at_T0`
* PASS condition:

  * Requires **both**:

    1. `PSD_verified` from Weil PSD certificate (or treated as `True` if missing),
    2. `lhs_total <= epsilon_eff` in `mpmath` arithmetic.

**Status:** `MINOR_WARN` (borderline toward structural, not math)

The inequality structure itself matches the big plan and continuum rollup.

### 6. Issues, risk level, and recommendations

1. **MINOR_WARN – gamma tails file name mismatch (future)**

   * Code **requires** `gamma_tail.json` in `certs-dir`.
   * The big plan and newer modules tilt toward `gamma_tails` as a domain block name. If you ever rename the file itself to `gamma_tails.json` in ToolkitV2, you must update `uniform_rollup_cert.py` to match, or introduce a tolerant search (`gamma_tail.json` vs `gamma_tails.json`).

2. **MINOR_WARN – prime block canonical field name drift**

   * `read_prime_block_cap` treats **canonical** v2.1 as `prime_block_norm.used_operator_norm`, with fallbacks to older schemas.
   * The big plan also features `prime_block_norm.cap_total_hi`. 
   * You already covered `cap_total_hi` as a fallback in `stp_test.py` but **not** here; consider adding `["prime_block_norm","cap_total_hi"]` to the canonical search list in this module.

3. **MINOR_WARN – no top-level `created_utc`**

   * G-4 *prefers* a top-level `created_utc`, but here it exists only under `meta.created_utc`. That’s acceptable but slightly off from the “ideal” shape.

No outright MAJOR_RISK from what’s visible in the code alone; the inequality matches the continuum design.

### 7. Cross-AI validation prompt

> You are auditing a module `uniform_rollup_cert.py` that reads band_cert.json, prime_block_norm.json, prime_tail_envelope.json, gamma_tail.json, grid_error_bound.json, and a Weil PSD certificate, then computes lhs_total = prime_block_cap + prime_tail_norm + grid_error_norm and epsilon_eff = band_margin − gamma_env_at_T0, declaring PASS if lhs_total <= epsilon_eff and PSD_verified is true. Check whether this algebra correctly reflects the intended continuum operator inequality, whether any missing terms should be included in lhs_total, and whether the extraction of band_margin, gamma_env_at_T0, prime_block_cap, and prime_tail_norm from the respective JSONs is coherent with the described v2.1 schemas.

#### JSON spec for `uniform_rollup_cert.py`

```json
{
  "module": "uniform_rollup_cert.py",
  "tool_id": "uniform_rollup_cert",
  "role": "rollup",
  "cli": {
    "description": "Single-T0 uniform certificate combining band, tails, prime block, grid error, and PSD status.",
    "args": [
      {
        "flag": "--T0",
        "name": "T0",
        "required": true,
        "type": "str",
        "default": null,
        "choices": null,
        "notes": "Target height T0 for the uniform inequality."
      },
      {
        "flag": "--certs-dir",
        "name": "certs_dir",
        "required": false,
        "type": "str",
        "default": "PROOF_PACKET",
        "choices": null,
        "notes": "Directory containing band, prime, tails, grid, and other cert JSONs."
      },
      {
        "flag": "--out",
        "name": "out",
        "required": true,
        "type": "str",
        "default": null,
        "choices": null,
        "notes": "Output JSON path for uniform_certificate.json."
      },
      {
        "flag": "--dps",
        "name": "dps",
        "required": false,
        "type": "int",
        "default": 220,
        "choices": null,
        "notes": "Decimal precision for mpmath."
      }
    ]
  },
  "outputs": [
    {
      "filename": "uniform_certificate.json",
      "primary": true,
      "kind": "uniform_certificate",
      "schema_version": "v2.1",
      "blocks": {
        "inputs": {
          "description": "Paths and T0 used for the uniform rollup.",
          "fields": [
            { "path": "inputs.T0", "type": "str", "meaning": "Target T0." },
            { "path": "inputs.certs_dir", "type": "str", "meaning": "Directory containing input JSON certificates." },
            { "path": "inputs.band_cert_path", "type": "str", "meaning": "Path to band_cert.json." },
            { "path": "inputs.prime_block_path", "type": "str", "meaning": "Path to prime_block_norm.json." },
            { "path": "inputs.prime_tail_path", "type": "str", "meaning": "Path to prime_tail_envelope.json." },
            { "path": "inputs.gamma_tail_path", "type": "str", "meaning": "Path to gamma_tail.json." },
            { "path": "inputs.grid_error_path", "type": "str or null", "meaning": "Path to grid_error_bound.json or null." },
            { "path": "inputs.continuum_operator_path", "type": "str or null", "meaning": "Path to continuum_operator_cert.json or null." },
            { "path": "inputs.weil_explicit_path", "type": "str or null", "meaning": "Path to weil_explicit_cert.json or null." },
            { "path": "inputs.weil_psd_path", "type": "str or null", "meaning": "Path to weil_psd_bochner.json or null." }
          ]
        },
        "uniform_certificate": {
          "name": "uniform_certificate",
          "fields": [
            { "path": "uniform_certificate.band_margin", "type": "str", "meaning": "Lower band margin at T0." },
            { "path": "uniform_certificate.gamma_env_at_T0", "type": "str", "meaning": "Gamma tail envelope at T0." },
            { "path": "uniform_certificate.epsilon_eff", "type": "str", "meaning": "Effective margin = band_margin - gamma_env_at_T0." },
            { "path": "uniform_certificate.prime_block_cap", "type": "str", "meaning": "Cap on prime block operator norm." },
            { "path": "uniform_certificate.prime_tail_norm", "type": "str", "meaning": "Prime tail norm at T0." },
            { "path": "uniform_certificate.grid_error_norm", "type": "str", "meaning": "Grid error bound (defaults to '0' if missing)." },
            { "path": "uniform_certificate.lhs_total", "type": "str", "meaning": "prime_block_cap + prime_tail_norm + grid_error_norm." },
            { "path": "uniform_certificate.PSD_verified", "type": "bool", "meaning": "PSD flag from Weil certificate (true if PSD_verified or Weil cert missing)." }
          ]
        },
        "root": {
          "description": "Root PASS flag.",
          "fields": [
            { "path": "PASS", "type": "bool", "meaning": "True iff PSD_verified and lhs_total <= epsilon_eff." }
          ]
        },
        "meta": {
          "fields": [
            { "path": "meta.tool", "type": "str", "meaning": "Tool name; must be 'uniform_rollup_cert'." },
            { "path": "meta.dps", "type": "int", "meaning": "Decimal precision used." },
            { "path": "meta.created_utc", "type": "str", "meaning": "Creation time in UTC ISO8601." },
            { "path": "meta.sha256", "type": "str", "meaning": "SHA-256 of payload without meta.sha256." }
          ]
        }
      }
    }
  ],
  "dependencies": {
    "reads": [
      { "filename": "band_cert.json", "fields": ["numbers.band_margin_lo", "band_cert.band_margin.lo"] },
      { "filename": "prime_block_norm.json", "fields": ["prime_block_norm.used_operator_norm", "prime_block_norm.operator_norm_cap_hi", "prime_block_norm.cap_total_hi"] },
      { "filename": "prime_tail_envelope.json", "fields": ["prime_tail.env_T0_hi", "prime_tail_envelope.env_T0_hi"] },
      { "filename": "gamma_tail.json", "fields": ["gamma_tails.gamma_env_at_T0", "gamma_tail.env_at_T0"] },
      { "filename": "grid_error_bound.json", "fields": ["grid_error_bound.bound_hi"] },
      { "filename": "weil_psd_bochner.json", "fields": ["PSD_verified"] }
    ],
    "writes": [
      { "filename": "uniform_certificate.json", "consumed_by": ["master_report", "stp_test", "human_review"] }
    ]
  },
  "validation": {
    "math_checks": [
      "Confirm that band_margin is a valid lower bound on spectral margin at T0.",
      "Confirm that gamma_env_at_T0 is a valid upper envelope on gamma tails at T0.",
      "Ensure lhs_total = prime_block_cap + prime_tail_norm + grid_error_norm upper-bounds the continuum costs at T0.",
      "Verify PASS iff lhs_total <= epsilon_eff and PSD_verified is True."
    ],
    "structural_checks": [
      "kind must equal 'uniform_certificate'.",
      "meta.tool must equal 'uniform_rollup_cert'.",
      "meta.dps must equal CLI --dps.",
      "meta.sha256 is present and computed via canonical JSON without meta.sha256.",
      "All real-valued scalar fields in uniform_certificate are strings."
    ],
    "status": "MINOR_WARN",
    "issues": [
      {
        "level": "WARN",
        "summary": "gamma_tail filename is hard-coded as gamma_tail.json.",
        "detail": "If ToolkitV2 migrates to gamma_tails.json, this module must be updated or made tolerant."
      },
      {
        "level": "WARN",
        "summary": "prime_block canonical field name partially lags big_plan.",
        "detail": "read_prime_block_cap prefers used_operator_norm; consider also treating cap_total_hi as a canonical v2.1 source to match prime_block_norm spec."
      }
    ]
  },
  "cross_ai_prompt": "Audit uniform_rollup_cert.py which aggregates band_cert, prime_block_norm, prime_tail_envelope, gamma_tail, grid_error_bound, and a Weil PSD certificate at a single T0. Verify that lhs_total = prime_block_cap + prime_tail_norm + grid_error_norm and epsilon_eff = band_margin - gamma_env_at_T0 correctly encode the intended inequality, and that the extracted fields from each input JSON match the described v2.1 schemas."
}
```



## `subspace_psd_cholesky.py` 

**Role:** diagnostic / PSD cert (subspace-level Bochner check)

### Purpose

Construct a **Bochner Gram matrix** for a family of Gaussian-notch atoms and certify that the resulting finite-dimensional subspace is **PSD** by:

* building `H_ij = ∫_{-A}^A h_i(x) h_j(x) dx` numerically, and
* applying standard + **pivoted Cholesky** to test PSD up to numerical tolerance.

If either Cholesky succeeds with non-negative pivots (modulo tolerance), the subspace is certified PSD.

---

### CLI interface

* `--basis` *(optional, str, choices: `["gaussian"]`, default `"gaussian"`)*
  Basis family; currently only `"gaussian"` is supported (used as an identifier, not a path).

* `--atoms` *(required, int)*
  Number of atoms (basis functions) in the subspace.

* `--sigma-min` *(required, str)*

* `--sigma-max` *(required, str)*
  Minimum / maximum `sigma` values for atoms; atoms are laid out on a grid in `[sigma_min, sigma_max]`.

* `--k0-min` *(required, str)*

* `--k0-max` *(required, str)*
  Minimum / maximum `k0` values; atoms are laid out on a grid in `[k0_min, k0_max]`.

* `--gridA` *(optional, str, default `"50"`)*
  Half-width `A` of the integration interval `[-A, A]`.

* `--mgrid` *(optional, int, default `2049`)*
  Number of trapezoid nodes for the 1D integral (`>= 2`).

* `--dps` *(optional, int, default `120`)*
  Decimal precision for `mpmath`.

* `--eta` *(optional, str, default `"0"`)*
  Diagonal jitter added to `H[i,i]` (stabilization / regularization).

* `--threads` *(optional, int, default `1`)*
  Number of worker threads used to build the Gram matrix.

* `--progress` *(flag)*
  Show tqdm progress bar when building `H`.

* `--out` *(required, str)*
  Output JSON certificate path.

* `--csv` *(required, str)*
  Output CSV path with Gram entries.

---

### Output artifacts

####1 JSON (`subspace_psd_cholesky.json`)

* **kind**: `"subspace_psd_cholesky"`

* `inputs`:

  * `basis_path` *(str)* – here used as a basis identifier (e.g. `"gaussian"`).
  * `atoms` *(int)* – number of atoms.
  * `sigma_min`, `sigma_max` *(str)* – endpoints of sigma grid.
  * `k0_min`, `k0_max` *(str)* – endpoints of k0 grid.
  * `gridA` *(str)* – integration half-width.
  * `mgrid` *(int)* – number of nodes.
  * `eta` *(str)* – diagonal jitter.
  * `threads` *(int)* – thread count.

* `result`:

  * `chol_success` *(bool)* – `True` if plain `mp.cholesky` succeeded.
  * `min_diag_L` *(str or null)* – smallest diagonal entry of `L` when plain Cholesky succeeded; otherwise `null`.
  * `pivot_success` *(bool)* – `True` if pivoted Cholesky succeeded.
  * `min_pivot` *(str or null)* – minimum pivot in pivoted Cholesky, else `null`.
  * `rank` *(int)* – rank from pivoted Cholesky if used; otherwise `n` if plain Cholesky succeeded; otherwise `0`.
  * `psd_certified` *(bool)* – `True` iff `chol_success or pivot_success`.

* `meta`:

  * `tool` = `"subspace_psd_cholesky"`.
  * `dps` *(int)* – precision used.
  * `created_utc` *(str)* – UTC ISO-8601.
  * `elapsed_sec` *(str)* – elapsed wall time in seconds.
  * `algo` *(str)* – algorithm identifier (e.g. `"subspace_psd_cholesky/pivoted"`).
  * `n`, `gridA`, `mgrid`, `eta`, `threads` – diagnostics (duplicated from inputs, some as strings).
  * `sha256` *(str)* – hash of canonical payload (with `meta.sha256` removed).

All real-valued numerics are stored as strings; ints and bools stay as such.

####2 CSV

* File specified by `--csv`.
* Columns: `i, j, h_ij`

  * `i`, `j` *(int)* – indices.
  * `h_ij` *(str)* – `H[i,j]` printed with `mp.nstr(H[i, j], 20)`.

---

### 4. Dependencies and wiring

* **Reads:** none (analytic basis; no JSON input).
* **Writes:**

  * JSON: `subspace_psd_cholesky.json` – high-level PSD witness.
  * CSV: Gram matrix samples, for deeper inspection or external plotting.

Downstream consumers: diagnostic tools, STP/summary reports, or any future “subspace PSD summary” module.

---

### 5. Math & validity checklist

* **Kernel / atoms:**

  * Atom: `h(x; sigma, k0) = exp(-x^2 / sigma^2) * (1 - exp(-(x - k0)^2))`.
  * Gram entry: `H_ij = ∫_{-A}^A h(x; sigma_i,k0_i) h(x; sigma_j,k0_j) dx`, approximated by **Kahan-compensated trapezoid**.

* **Integration:**

  * `kahan_stream_trap` reduces summation error.
  * Finite window `[-A, A]` introduces truncation error; must be chosen large enough that tails are negligible for your sigma/k0 range.

* **PSD test:**

  * Plain Cholesky (`mp.cholesky`).
  * If it fails, pivoted Cholesky with adaptive tolerance `tol = 10^{-(dps - k)}` (with `k=6`).
  * PSD is certified if:

    * no negative pivot < −tol, and
    * process terminates without failure.

**Status:** `MINOR_WARN` (numerical, not structural)

* The logic is coherent. PSD correctness is as strong as:

  * the numerical integration (`A`, `mgrid`, `dps`), and
  * the Cholesky tolerance interpretation.
* For “gold-standard” use, you may want to:

  * run at multiple `A` / `mgrid` / `dps` and verify stability of `psd_certified`,
  * track the **spectral norm** of the difference when adjusting parameters (future enhancement).

---

### 6. Issues & recommendations

* **MINOR_WARN:** Truncation domain `[-A,A]` and `mgrid` are user-chosen; there’s no automatic check that the tails are small. For extreme parameters (`sigma` very small/large), you might want a separate script that verifies stability across `(A,mgrid)`.
* **MINOR_WARN:** `basis_path` is really an identifier, not a path; name is slightly misleading but harmless.

*No major structural changes recommended without explicit request.*

---

### 7. Cross-AI validation prompt

> You are auditing a module `subspace_psd_cholesky.py` that builds a Bochner Gram matrix H_ij = ∫_{-A}^A h_i(x) h_j(x) dx for Gaussian-notch atoms using Kahan trapezoid integration, then tests PSD via Cholesky and pivoted Cholesky. Check whether this yields a mathematically sound PSD certification given finite interval [-A, A] and mgrid, what conditions on A, mgrid, and dps are needed, and whether the pivot tolerance `10^{-(dps-6)}` is appropriate.

---

### JSON spec for `subspace_psd_cholesky.py`

```json
{
  "module": "subspace_psd_cholesky.py",
  "tool_id": "subspace_psd_cholesky",
  "role": "diagnostic",
  "cli": {
    "description": "Certify PSD of a Gaussian-notch subspace via Bochner Gram and (pivoted) Cholesky.",
    "args": [
      { "flag": "--basis", "name": "basis", "required": false, "type": "str", "default": "gaussian", "choices": ["gaussian"], "notes": "Basis identifier; currently fixed to 'gaussian'." },
      { "flag": "--atoms", "name": "atoms", "required": true, "type": "int", "default": null, "choices": null, "notes": "Number of atoms in the subspace." },
      { "flag": "--sigma-min", "name": "sigma_min", "required": true, "type": "str", "default": null, "choices": null, "notes": "Minimum sigma for atom grid." },
      { "flag": "--sigma-max", "name": "sigma_max", "required": true, "type": "str", "default": null, "choices": null, "notes": "Maximum sigma for atom grid." },
      { "flag": "--k0-min", "name": "k0_min", "required": true, "type": "str", "default": null, "choices": null, "notes": "Minimum k0 for atom grid." },
      { "flag": "--k0-max", "name": "k0_max", "required": true, "type": "str", "default": null, "choices": null, "notes": "Maximum k0 for atom grid." },
      { "flag": "--gridA", "name": "gridA", "required": false, "type": "str", "default": "50", "choices": null, "notes": "Half-width A for integration interval [-A,A]." },
      { "flag": "--mgrid", "name": "mgrid", "required": false, "type": "int", "default": 2049, "choices": null, "notes": "Number of trapezoid nodes (>=2)." },
      { "flag": "--dps", "name": "dps", "required": false, "type": "int", "default": 120, "choices": null, "notes": "Decimal precision for mpmath." },
      { "flag": "--eta", "name": "eta", "required": false, "type": "str", "default": "0", "choices": null, "notes": "Diagonal jitter added to Gram matrix." },
      { "flag": "--threads", "name": "threads", "required": false, "type": "int", "default": 1, "choices": null, "notes": "Worker threads for Gram build." },
      { "flag": "--progress", "name": "progress", "required": false, "type": "flag", "default": false, "choices": null, "notes": "Show tqdm progress bar." },
      { "flag": "--out", "name": "out", "required": true, "type": "str", "default": null, "choices": null, "notes": "Output JSON certificate path." },
      { "flag": "--csv", "name": "csv", "required": true, "type": "str", "default": null, "choices": null, "notes": "Output CSV path for Gram matrix entries." }
    ]
  },
  "outputs": [
    {
      "filename": "subspace_psd_cholesky.json",
      "primary": true,
      "kind": "subspace_psd_cholesky",
      "schema_version": "v2.1",
      "blocks": {
        "inputs": {
          "description": "Subspace and integration configuration.",
          "fields": [
            { "path": "inputs.basis_path", "type": "str", "meaning": "Basis identifier (e.g. 'gaussian')." },
            { "path": "inputs.atoms", "type": "int", "meaning": "Number of atoms in the subspace." },
            { "path": "inputs.sigma_min", "type": "str", "meaning": "Minimum sigma." },
            { "path": "inputs.sigma_max", "type": "str", "meaning": "Maximum sigma." },
            { "path": "inputs.k0_min", "type": "str", "meaning": "Minimum k0." },
            { "path": "inputs.k0_max", "type": "str", "meaning": "Maximum k0." },
            { "path": "inputs.gridA", "type": "str", "meaning": "Integration half-width A." },
            { "path": "inputs.mgrid", "type": "int", "meaning": "Number of trapezoid nodes." },
            { "path": "inputs.eta", "type": "str", "meaning": "Diagonal jitter parameter." },
            { "path": "inputs.threads", "type": "int", "meaning": "Number of worker threads." }
          ]
        },
        "result": {
          "name": "result",
          "fields": [
            { "path": "result.chol_success", "type": "bool", "meaning": "True if plain Cholesky succeeded." },
            { "path": "result.min_diag_L", "type": "str or null", "meaning": "Minimum diagonal entry of L if plain Cholesky succeeded." },
            { "path": "result.pivot_success", "type": "bool", "meaning": "True if pivoted Cholesky succeeded." },
            { "path": "result.min_pivot", "type": "str or null", "meaning": "Minimum pivot in pivoted Cholesky if used." },
            { "path": "result.rank", "type": "int", "meaning": "Cholesky rank (pivoted or full)." },
            { "path": "result.psd_certified", "type": "bool", "meaning": "True if subspace certified PSD under these settings." }
          ]
        },
        "meta": {
          "fields": [
            { "path": "meta.tool", "type": "str", "meaning": "Tool name; must be 'subspace_psd_cholesky'." },
            { "path": "meta.dps", "type": "int", "meaning": "Decimal precision used." },
            { "path": "meta.created_utc", "type": "str", "meaning": "Creation time in UTC ISO8601." },
            { "path": "meta.elapsed_sec", "type": "str", "meaning": "Elapsed wall-clock time in seconds." },
            { "path": "meta.sha256", "type": "str", "meaning": "SHA-256 of canonical payload (without meta.sha256)." }
          ]
        }
      }
    },
    {
      "filename": "<csv-from-cli>",
      "primary": false,
      "kind": "subspace_psd_cholesky_gram_csv",
      "schema_version": "v2.1",
      "blocks": {
        "csv": {
          "description": "Gram entries H[i,j].",
          "fields": [
            { "path": "i", "type": "int", "meaning": "Row index." },
            { "path": "j", "type": "int", "meaning": "Column index." },
            { "path": "h_ij", "type": "str", "meaning": "Gram matrix entry H[i,j]." }
          ]
        }
      }
    }
  ],
  "dependencies": {
    "reads": [],
    "writes": [
      { "filename": "subspace_psd_cholesky.json", "consumed_by": ["diagnostics", "master_report"] },
      { "filename": "<csv-from-cli>", "consumed_by": ["debug_gram_viewer", "plots"] }
    ]
  },
  "validation": {
    "math_checks": [
      "Verify that for chosen A and mgrid, the integral approximation converges for all atoms in [sigma_min, sigma_max] x [k0_min, k0_max].",
      "Check that no negative pivots less than -tol = 10^{-(dps-6)} appear in pivoted Cholesky if psd_certified is True."
    ],
    "structural_checks": [
      "kind must equal 'subspace_psd_cholesky'.",
      "meta.tool must equal 'subspace_psd_cholesky'.",
      "All real-valued quantities in inputs/result/meta are strings.",
      "meta.sha256 is computed from canonical JSON without meta.sha256."
    ],
    "status": "MINOR_WARN",
    "issues": [
      {
        "level": "WARN",
        "summary": "PSD guarantee depends on choice of A, mgrid, and tolerance.",
        "detail": "The certification is numerically valid only if the chosen domain and resolution are sufficient for the parameter range; consider a stability check across multiple settings."
      }
    ]
  },
  "cross_ai_prompt": "Audit subspace_psd_cholesky.py which builds a Bochner Gram matrix for Gaussian-notch atoms and tests PSD via Cholesky and pivoted Cholesky. Confirm that the algorithm is mathematically sound under reasonable choices of A, mgrid, and dps, and suggest any improvements to the pivot tolerance or integral quadrature."
}
```

---

## `tail_envelope.py` 

**Role:** analytic tails (gamma side)

### Purpose

Produce an **analytic envelope** for the gamma tail:

[
G(T) \leq \frac{c_1(\sigma)}{T} + \frac{c_2(\sigma)}{T^2}, \quad T \ge T_0,
]

with

* ( c_1(\sigma) = 1 + 1/\sigma ),
* ( c_2(\sigma) = 1/2 + 1/\sigma^2 ),

and record:

* `env_at_T0 = c1/T0 + c2/T0^2`,
* plus an optional **theory JSON** describing the lemma textually.

---

### CLI interface

* `--sigma` *(optional, str, default `"6.0"`)*
  Gaussian width parameter `σ > 0`.

* `--T0` *(optional, str, default `"1000000"`)*
  Base point `T0 > 0` where the envelope is evaluated and from which the bound applies.

* `--dps` *(optional, int, default `300`)*
  Decimal precision for `mpmath`.

* `--out` *(required, str)*
  Output JSON path for the envelope artifact.

* `--theory-out` *(optional, str or null)*
  If provided, a “theory” JSON with the lemma statement is also written.

---

### Output artifacts

####1 Main JSON (`gamma_tail_envelope.json`)

* **kind**: `"gamma_tail_envelope"`

* `inputs`:

  * `sigma` *(str)* – input σ.
  * `T0` *(str)* – base point.

* `gamma_tail`:

  * `c1` *(str)* – `1 + 1/σ`.
  * `c2` *(str)* – `1/2 + 1/σ^2`.
  * `env_at_T0` *(str)* – `c1/T0 + c2/T0^2`.
  * `monotone` *(bool)* – `True` (envelope decreases in `T` for `T >= T0`).

* `meta`:

  * `tool` = `"tail_envelope"`.
  * `dps` *(int)* – precision.
  * `created_utc` *(str)* – UTC ISO-8601.
  * `sha256` *(str)* – hash computed as in other v2.1 tools.

All reals are strings.

####2 Theory JSON (`gamma_tail_envelope_theory.json`, optional)

Only written if `--theory-out` is given.

* **kind**: `"gamma_tail_envelope_theory"`
* `theory`:

  * `lemma` *(str)* – `"GammaTailEnvelope"`.
  * `statement` *(str)* – natural-language lemma about `G(T)` and the envelope.
* `inputs`:

  * `sigma` *(str)*, `T0` *(str)*.
* `meta`:

  * `tool` = `"tail_envelope_theory"`.
  * `dps` *(int)*, `created_utc` *(str)*, `sha256` *(str)*.

---

### 4. Dependencies and wiring

* **Reads:** none.
* **Writes:** `gamma_tail_envelope.json` consumed by:

  * gamma tails rollup / analytic bounds tooling,
  * documentation or comparison scripts.

---

### 5. Math & validity checklist

* **Formulas:**

  * `c1 = 1 + 1/σ`,
  * `c2 = 1/2 + 1/σ^2`,
  * `env_at_T0 = c1/T0 + c2/T0^2`.

* **Monotonicity:**

  * For `T >= T0 > 0`, `1/T` and `1/T^2` are decreasing, so the combination stays decreasing; `monotone = True` is valid.

* **Assumptions:**

  * `sigma > 0`, `T0 > 0` are enforced at runtime.
  * This envelope is **designed to be conservative**, not necessarily sharp.

**Status:** `OK`

The math is simple and consistent; any refinement would be a separate analytic project (tightening constants), not a correctness bug.

---

### 6. Issues & recommendations

* No structural issues.
* Potential **future enhancement**: optional parameters to choose alternate analytic constants `c1(σ), c2(σ)` if you derive sharper bounds.

*No changes recommended without explicit instruction.*

---

### 7. Cross-AI validation prompt

> Given the module `tail_envelope.py` that defines c1=1+1/σ, c2=1/2+1/σ^2 and claims that for T>=T0, G(T)<=c1/T + c2/T^2, check if this envelope is valid under reasonable assumptions on G(T) (e.g. gamma tails from a Riemann kernel), and whether the claimed monotonicity for T>=T0 is correct.

---

### JSON spec for `tail_envelope.py`

```json
{
  "module": "tail_envelope.py",
  "tool_id": "tail_envelope",
  "role": "tails",
  "cli": {
    "description": "Emit an analytic gamma tail envelope G(T) <= c1/T + c2/T^2 for T >= T0.",
    "args": [
      { "flag": "--sigma", "name": "sigma", "required": false, "type": "str", "default": "6.0", "choices": null, "notes": "Gaussian width sigma (>0)." },
      { "flag": "--T0", "name": "T0", "required": false, "type": "str", "default": "1000000", "choices": null, "notes": "Base point T0 (>0) where envelope is evaluated." },
      { "flag": "--dps", "name": "dps", "required": false, "type": "int", "default": 300, "choices": null, "notes": "Decimal precision for mpmath." },
      { "flag": "--out", "name": "out", "required": true, "type": "str", "default": null, "choices": null, "notes": "Output JSON path (gamma_tail_envelope)." },
      { "flag": "--theory-out", "name": "theory_out", "required": false, "type": "str or null", "default": null, "choices": null, "notes": "Optional path for theory JSON." }
    ]
  },
  "outputs": [
    {
      "filename": "gamma_tail_envelope.json",
      "primary": true,
      "kind": "gamma_tail_envelope",
      "schema_version": "v2.1",
      "blocks": {
        "inputs": {
          "description": "Sigma and T0 inputs.",
          "fields": [
            { "path": "inputs.sigma", "type": "str", "meaning": "Gaussian width sigma." },
            { "path": "inputs.T0", "type": "str", "meaning": "Base point T0." }
          ]
        },
        "gamma_tail": {
          "name": "gamma_tail",
          "fields": [
            { "path": "gamma_tail.c1", "type": "str", "meaning": "Envelope parameter c1 = 1 + 1/sigma." },
            { "path": "gamma_tail.c2", "type": "str", "meaning": "Envelope parameter c2 = 1/2 + 1/sigma^2." },
            { "path": "gamma_tail.env_at_T0", "type": "str", "meaning": "Envelope value at T0: c1/T0 + c2/T0^2." },
            { "path": "gamma_tail.montone", "type": "bool", "meaning": "True if envelope is monotone decreasing in T for T>=T0 (always True in this model)." }
          ]
        },
        "meta": {
          "fields": [
            { "path": "meta.tool", "type": "str", "meaning": "Tool name; must be 'tail_envelope'." },
            { "path": "meta.dps", "type": "int", "meaning": "Decimal precision used." },
            { "path": "meta.created_utc", "type": "str", "meaning": "Creation time in UTC ISO8601." },
            { "path": "meta.sha256", "type": "str", "meaning": "SHA-256 of canonical payload without meta.sha256." }
          ]
        }
      }
    },
    {
      "filename": "<theory-out>",
      "primary": false,
      "kind": "gamma_tail_envelope_theory",
      "schema_version": "v2.1",
      "blocks": {
        "theory": {
          "description": "Formal lemma statement for the gamma tail envelope.",
          "fields": [
            { "path": "theory.lemma", "type": "str", "meaning": "Lemma name." },
            { "path": "theory.statement", "type": "str", "meaning": "Natural-language lemma statement." }
          ]
        }
      }
    }
  ],
  "dependencies": {
    "reads": [],
    "writes": [
      { "filename": "gamma_tail_envelope.json", "consumed_by": ["analytic_bounds", "tails_rollup", "master_report"] },
      { "filename": "<theory-out>", "consumed_by": ["docs", "paper_appendix"] }
    ]
  },
  "validation": {
    "math_checks": [
      "Verify that for T>=T0>0, env(T) = c1/T + c2/T^2 is decreasing.",
      "Check that the chosen c1, c2 are conservative for the intended gamma tails in the RH pipeline."
    ],
    "structural_checks": [
      "kind must equal 'gamma_tail_envelope'.",
      "meta.tool must equal 'tail_envelope'.",
      "All real-valued outputs are strings.",
      "meta.sha256 is computed without self-reference."
    ],
    "status": "OK",
    "issues": []
  },
  "cross_ai_prompt": "Audit tail_envelope.py, which defines a gamma tail envelope G(T) <= c1/T + c2/T^2 with c1=1+1/sigma and c2=1/2+1/sigma^2. Check monotonicity and whether the constants are plausibly conservative for the RH gamma tail used in the SpectralToolkit."
}
```

---

## `stp_test.py` 

**Role:** diagnostic / self-test (no JSON)

### Purpose

Run a **SpectralToolkit self-test** (“STP”) by checking the presence and basic consistency of the main certificate artifacts:

* band certificate,
* Weil PSD cert,
* gamma/prime tails,
* prime block norm,
* explicit formula / continuum rollup,

and report `STP PASS` or `STP FAIL` on stdout. It **does not** define any inequalities; it only checks that various fields exist and cohere across JSONs.

---

### CLI interface

* `--band-cert` *(required, str)*
  Path to `band_cert.json`.

* `--weil-psd` *(required, str)*
  Path to `weil_psd_bochner.json` from `weil_kernel.py`.

* `--tails` *(required, str)*
  Path to tails JSON: must contain both gamma and prime envelopes at `T0` (could be a combined tails rollup).

* `--prime-norm` *(required, str)*
  Path to `prime_block_norm.json`.

* `--explicit` *(required, str)*
  Path to `explicit_formula.json`.

* `--continuum-cert` *(optional, str or null, default `None`)*
  Optional path to `continuum_operator_cert.json`.

* `--dps` *(optional, int, default `200`)*
  Decimal precision flag (not actually used in calculations, just metadata).

---

### Output artifacts

* **No JSON / CSV.**
* Outputs **text only** to stdout and sets **exit code**:

  * `0` – all checks pass.
  * `2` – one or more checks fail.

Printed structure:

* Header of `=` and `-` separators.
* `STP PASS` or `STP FAIL`.
* One line each for:

  * `[band] ...`
  * `[weil] ...`
  * `[tails] ...`
  * `[prime] ...`
  * `[explicit] ...`
* If `--continuum-cert` provided:

  * A `[rollup] (informational)` block showing `prime_block_cap`, `prime_tail_norm`, `grid_error_norm`, `lhs_total`, `PASS`.

---

### 4. Dependencies and wiring

* **Reads:**

  * `band_cert.json`:

    * Coalesces band margin from multiple paths:

      * canonical: `numbers.band_margin_lo`, `band_cert.band_margin.lo`,
      * tolerant: `band_cert.band_margin_lo`, `numbers.band_margin`, `band.margin_lo`, `band_margin_lo`.

  * `weil_psd_bochner.json`:

    * `PSD_verified` from one of:

      * `PSD_verified` (canonical),
      * `bochner_psd.PSD_verified`,
      * `weil_psd.PSD_verified`.

  * `tails` JSON:

    * Gamma part:

      * canonical: `gamma_tails.gamma_env_at_T0`, `gamma_tail.env_at_T0`,
      * tolerant: `gamma_env_at_T0`, `tails.gamma_env_at_T0`, `gamma_tail.gamma_env_at_T0`, `gamma_tail.tails_total`.
    * Prime part:

      * canonical: `prime_tail.env_T0_hi`,
      * tolerant: `prime_env_at_T0`, `tails.prime_env_at_T0`, `prime_tail_envelope.env_T0_hi`, `prime_tails.env_T0_hi`.

  * `prime_block_norm.json`:

    * canonical preference:

      * `prime_block_norm.used_operator_norm`,
      * `prime_block_norm.cap_total_hi`,
      * `prime_block_norm.operator_norm_cap_hi`,

    * tolerant fallbacks:

      * `numbers.cap_hi`, `cap_hi`, `numbers.prime_block_cap`, `prime_block_norm.cap_hi`, `numbers.operator_norm_cap`, `operator_norm_cap`, `numbers.op_norm_cap`, `op_norm_cap`.

    * If still missing, tries continuum rollup (if provided):

      * `numbers.prime_block_cap`, `numbers.cap_hi`, `prime_block_cap`, `cap_hi`.

  * `explicit_formula.json`:

    * epsilon_eff from:

      * canonical: `explicit_formula.epsilon_eff_lo`,
      * tolerant: `rollup.eps_eff`, `epsilon_eff`, `epsilon_eff_lo`, `band.band_margin_lo`.

    * If missing and rollup given:

      * `numbers.eps_eff`, `numbers.epsilon_eff`, `eps_eff`, `epsilon_eff`.

* **Writes:** none; this is purely a checker.

---

### 5. Math & validity checklist

* **Logic:**
  STP’s job is **binary: presence vs absence** of key scalar fields:

  * `band_margin != None`,
  * `PSD_verified == True`,
  * `gamma_total != None` and `prime_total != None`,
  * `prime_cap != None`,
  * `eps_eff != None`.

* **No inequalities are evaluated.**

  * It does **not** recompute `lhs_total` or `epsilon_eff` directly.
  * It only surfaces what’s present and relies on other modules for correctness.

**Status:** `OK`

As a presence/consistency checker, it’s doing what you expect, with generous tolerance for schemas.

---

### 6. Issues & recommendations

* **MINOR_WARN:** It treats `PSD_verified` as `False` by default if the field is missing, which is safe but strict. Since your v2.1 pipeline always writes a Weil PSD cert, that’s probably what you want.
* **MINOR_WARN:** Very tolerant schema matching means it may still pass if you’re accidentally using an older JSON layout—this is a feature for migration, but for ToolkitV2 you might someday want a “strict mode” that requires only v2.1 shapes.

*No changes made; any tightening of schema rules should be an explicit follow-up.*

---

### 7. Cross-AI validation prompt

> You are auditing a self-test harness `stp_test.py` that reads band_cert, Weil PSD, tails, prime_block_norm, explicit_formula, and optional continuum rollup JSONs. It checks only for presence of key scalars and a PSD flag, then prints STP PASS/FAIL. Evaluate whether the set of fields it requires is sufficient to guarantee that the main certificates are structurally present and whether the tolerant coalescing could hide any important schema drift in a ToolkitV2 context.

---

### JSON spec for `stp_test.py`

```json
{
  "module": "stp_test.py",
  "tool_id": "stp_test",
  "role": "diagnostic",
  "cli": {
    "description": "SpectralToolkit self-test: checks presence/consistency of main certificates and prints STP PASS/FAIL.",
    "args": [
      { "flag": "--band-cert", "name": "band_cert", "required": true, "type": "str", "default": null, "choices": null, "notes": "Path to band_cert.json." },
      { "flag": "--weil-psd", "name": "weil_psd", "required": true, "type": "str", "default": null, "choices": null, "notes": "Path to Weil PSD certificate (weil_psd_bochner.json)." },
      { "flag": "--tails", "name": "tails", "required": true, "type": "str", "default": null, "choices": null, "notes": "Path to tails JSON (gamma + prime envelopes at T0)." },
      { "flag": "--prime-norm", "name": "prime_norm", "required": true, "type": "str", "default": null, "choices": null, "notes": "Path to prime_block_norm.json." },
      { "flag": "--explicit", "name": "explicit", "required": true, "type": "str", "default": null, "choices": null, "notes": "Path to explicit_formula.json." },
      { "flag": "--continuum-cert", "name": "continuum_cert", "required": false, "type": "str or null", "default": null, "choices": null, "notes": "Optional path to continuum_operator_cert.json." },
      { "flag": "--dps", "name": "dps", "required": false, "type": "int", "default": 200, "choices": null, "notes": "Decimal precision (informational only)." }
    ]
  },
  "outputs": [],
  "dependencies": {
    "reads": [
      { "filename": "band_cert.json", "fields": ["numbers.band_margin_lo", "band_cert.band_margin.lo", "band_cert.band_margin_lo", "numbers.band_margin", "band.margin_lo", "band_margin_lo"] },
      { "filename": "weil_psd_bochner.json", "fields": ["PSD_verified", "bochner_psd.PSD_verified", "weil_psd.PSD_verified"] },
      { "filename": "tails.json", "fields": ["gamma_tails.gamma_env_at_T0", "gamma_tail.env_at_T0", "gamma_env_at_T0", "tails.gamma_env_at_T0", "gamma_tail.gamma_env_at_T0", "gamma_tail.tails_total", "prime_tail.env_T0_hi", "prime_env_at_T0", "tails.prime_env_at_T0", "prime_tail_envelope.env_T0_hi", "prime_tails.env_T0_hi"] },
      { "filename": "prime_block_norm.json", "fields": ["prime_block_norm.used_operator_norm", "prime_block_norm.cap_total_hi", "prime_block_norm.operator_norm_cap_hi", "numbers.cap_hi", "cap_hi", "numbers.prime_block_cap", "prime_block_norm.cap_hi", "numbers.operator_norm_cap", "operator_norm_cap", "numbers.op_norm_cap", "op_norm_cap"] },
      { "filename": "explicit_formula.json", "fields": ["explicit_formula.epsilon_eff_lo", "rollup.eps_eff", "epsilon_eff", "epsilon_eff_lo", "band.band_margin_lo"] },
      { "filename": "continuum_operator_cert.json", "fields": ["numbers.prime_block_cap", "numbers.cap_hi", "prime_block_cap", "cap_hi", "numbers.eps_eff", "numbers.epsilon_eff", "eps_eff", "epsilon_eff", "numbers.prime_tail_norm", "numbers.prime_tail", "prime_tail", "numbers.grid_error_norm", "grid_error_norm", "numbers.lhs_total", "lhs_total", "PASS"] }
    ],
    "writes": []
  },
  "validation": {
    "math_checks": [
      "Confirm that the presence of band_margin, PSD_verified, gamma/prime tails, prime_cap, and eps_eff is sufficient for a basic end-to-end sanity check.",
      "Ensure that STP PASS implies all major certs exist and have non-empty key fields."
    ],
    "structural_checks": [
      "Check that tolerant coalescing paths truly cover all intended v2.1 schemas.",
      "Confirm that absence of any key scalar sets exit code 2 and prints STP FAIL."
    ],
    "status": "OK",
    "issues": [
      {
        "level": "WARN",
        "summary": "Schema tolerance can mask legacy usage.",
        "detail": "Because stp_test accepts many legacy key paths, it may still pass when running against older JSON layouts; a stricter v2.1-only mode could be added later if desired."
      }
    ]
  },
  "cross_ai_prompt": "Audit stp_test.py, a self-test harness that checks for presence and basic consistency of band_cert, Weil PSD, tails, prime_block_norm, explicit_formula, and optional continuum rollup JSONs, then prints STP PASS/FAIL. Evaluate whether its set of checks is sufficient for SpectralToolkitV2 and whether its tolerant schema coalescing might hide important mismatches."
}
```


Here we go, next 3 under the new rules.

---

## `rollup_uniform.py` 

**Role:** rollup (single-T₀ analytic envelopes only)

### Purpose

Compare analytic envelopes at a **single base point** (T_0):

* ( B(T_0) = \text{gamma_envelope}(T_0) + \text{prime_envelope}(T_0) ),
* ( E(T_0) = \epsilon_{\text{eff,lo}}(T_0) ),

and certify a **uniform inequality on ([T_0,\infty))** assuming the input envelopes are monotone in (T). This module only checks the inequality at (T_0); monotonicity is delegated to the envelope generators.

---

### CLI interface

* `--T0` *(required, str)*
  Base point (T_0) (string or number).

* `--gamma-envelope` *(required, str)*
  Path to **gamma** envelope JSON (e.g. output of `tail_envelope.py`).

* `--prime-envelope` *(required, str)*
  Path to **prime** envelope JSON (e.g. `prime_tail_envelope.py`).

* `--explicit-formula` *(required, str)*
  Path to `explicit_formula.json` (epsilon_eff).

* `--dps` *(optional, int, default `220`)*
  Decimal precision for mpmath.

* `--out` *(required, str)*
  Output JSON path for the analytic uniform rollup.

* `--theory-out` *(optional, str or null)*
  Optional theory JSON path.

---

### Output artifacts

####1 Main JSON

* **kind**: `"uniform_analytic_rollup"`

* `inputs`:

  * `T0` *(str)* – base point.
  * `gamma_envelope_path` *(str)* – gamma envelope JSON path.
  * `prime_envelope_path` *(str)* – prime envelope JSON path.
  * `explicit_formula_path` *(str)* – explicit formula JSON path.

* `uniform_certificate`:

  * `E_T0_lo` *(str)* – lower bound (E_{\text{lo}}(T_0)) from explicit formula.
  * `B_T0_hi` *(str)* – upper bound (B_{\text{hi}}(T_0) = G(T_0) + P(T_0)).
  * `PASS` *(bool)* – `True` iff (E_{\text{lo}}(T_0) > B_{\text{hi}}(T_0)).

* `PASS` *(bool)* – same as `uniform_certificate.PASS`.

* `meta`:

  * `tool` = `"rollup_uniform"`.
  * `dps` *(int)*.
  * `created_utc` *(str, ISO8601 UTC)*.
  * `sha256` *(str)* – deterministic hash over canonical JSON (no `meta.sha256`).

All reals are strings; ints and bools remain native.

####2 Theory JSON (optional)

Written only if `--theory-out` is given.

* **kind**: `"uniform_analytic_rollup_theory"`
* `inputs.T0` *(str)*.
* `theory`:

  * `lemma` *(str)* – `"UniformAnalyticRollup"`.
  * `statement` *(str)* – informal statement: if `B(T0) < E(T0)` and both envelopes are monotone on ([T_0, \infty)), then inequality holds for all (T ≥ T_0).
  * `notes` *(str)* – clarifies that only (T_0) is checked numerically.
* `meta`:

  * `tool` = `"rollup_uniform"`.
  * `dps`, `created_utc`.
    *(No sha256 here — this theory JSON is written without the hash helper.)*

---

### 4. Dependencies and wiring

* **Reads:**

  * Gamma envelope JSON:

    * `gamma_tail.env_at_T0` via `read_gamma_env_T0`.
  * Prime envelope JSON:

    * `prime_tail.env_T0_hi` via `read_prime_env_T0`.
  * Explicit formula JSON:

    * `explicit_formula.epsilon_eff_lo` via `read_epsilon_eff_lo`.

* **Writes:**

  * `uniform_analytic_rollup.json` (name from `--out`).
  * Optional `uniform_analytic_rollup_theory.json`.

Consumers: higher-level summaries / reports; conceptual bridge between envelopes and explicit formula.

---

### 5. Math & validity checklist

* Extracted values:

  * ( G(T_0) = \text{gamma_tail.env_at_T0} ),
  * ( P(T_0) = \text{prime_tail.env_T0_hi} ),
  * ( E_{\text{lo}}(T_0) = \text{explicit_formula.epsilon_eff_lo} ).
* Computed:

  * ( B_{\text{hi}}(T_0) = G(T_0) + P(T_0) ),
  * PASS iff ( E_{\text{lo}}(T_0) > B_{\text{hi}}(T_0) ).

Assumes:

* Both envelopes are **monotone in T** on ([T_0,∝)).
* The lower bound (E_{\text{lo}}) is correctly constructed in `explicit_formula.py`.

**Status:** `OK` – algebra matches the docstring and big plan.

---

### 6. Issues & recommendations

* **MINOR_WARN:** The inequality uses strict `>`; if you ever want “≥” to be acceptable, you’d need to relax to `>=` (but strict is safer).
* No schema drift: keys are canonical v2.1 and non-tolerant (good for ToolkitV2).

---

### 7. Cross-AI validation prompt

> Audit rollup_uniform.py, which reads a gamma envelope (gamma_tail.env_at_T0), a prime envelope (prime_tail.env_T0_hi), and explicit_formula.epsilon_eff_lo, then checks E_lo(T0) > B_hi(T0) to certify a uniform inequality on [T0, ∞) assuming monotone envelopes. Confirm the algebra and discuss whether strict > is the right choice versus >=.

---

### JSON spec for `rollup_uniform.py`

```json
{
  "module": "rollup_uniform.py",
  "tool_id": "rollup_uniform",
  "role": "rollup",
  "cli": {
    "description": "Analytic uniform roll-up at T0: compare envelopes B(T0) and E(T0).",
    "args": [
      { "flag": "--T0", "name": "T0", "required": true, "type": "str", "default": null, "choices": null, "notes": "Base point T0 (string or number)." },
      { "flag": "--gamma-envelope", "name": "gamma_envelope", "required": true, "type": "str", "default": null, "choices": null, "notes": "Gamma envelope JSON path (kind='gamma_tail_envelope')." },
      { "flag": "--prime-envelope", "name": "prime_envelope", "required": true, "type": "str", "default": null, "choices": null, "notes": "Prime envelope JSON path (kind='prime_tail_envelope')." },
      { "flag": "--explicit-formula", "name": "explicit_formula", "required": true, "type": "str", "default": null, "choices": null, "notes": "Explicit formula JSON path (kind='weil_explicit')." },
      { "flag": "--dps", "name": "dps", "required": false, "type": "int", "default": 220, "choices": null, "notes": "Decimal precision for mpmath." },
      { "flag": "--out", "name": "out", "required": true, "type": "str", "default": null, "choices": null, "notes": "Output JSON path for uniform_analytic_rollup." },
      { "flag": "--theory-out", "name": "theory_out", "required": false, "type": "str", "default": null, "choices": null, "notes": "Optional theory JSON path." }
    ]
  },
  "outputs": [
    {
      "filename": "uniform_analytic_rollup.json",
      "primary": true,
      "kind": "uniform_analytic_rollup",
      "schema_version": "v2.1",
      "blocks": {
        "inputs": {
          "description": "Paths and T0 used for analytic rollup.",
          "fields": [
            { "path": "inputs.T0", "type": "str", "meaning": "Base point T0." },
            { "path": "inputs.gamma_envelope_path", "type": "str", "meaning": "Path to gamma envelope JSON." },
            { "path": "inputs.prime_envelope_path", "type": "str", "meaning": "Path to prime envelope JSON." },
            { "path": "inputs.explicit_formula_path", "type": "str", "meaning": "Path to explicit formula JSON." }
          ]
        },
        "uniform_certificate": {
          "name": "uniform_certificate",
          "fields": [
            { "path": "uniform_certificate.E_T0_lo", "type": "str", "meaning": "Lower bound E_lo(T0) from explicit formula." },
            { "path": "uniform_certificate.B_T0_hi", "type": "str", "meaning": "Upper bound B_hi(T0) = G(T0)+P(T0)." },
            { "path": "uniform_certificate.PASS", "type": "bool", "meaning": "True iff E_T0_lo > B_T0_hi." }
          ]
        },
        "root": {
          "description": "Root PASS flag.",
          "fields": [
            { "path": "PASS", "type": "bool", "meaning": "Alias of uniform_certificate.PASS." }
          ]
        },
        "meta": {
          "fields": [
            { "path": "meta.tool", "type": "str", "meaning": "Tool name; must be 'rollup_uniform'." },
            { "path": "meta.dps", "type": "int", "meaning": "Decimal precision used." },
            { "path": "meta.created_utc", "type": "str", "meaning": "Creation time (UTC, ISO8601)." },
            { "path": "meta.sha256", "type": "str", "meaning": "SHA-256 of canonical payload (without meta.sha256)." }
          ]
        }
      }
    }
  ],
  "dependencies": {
    "reads": [
      { "filename": "gamma_tail_envelope.json", "fields": ["gamma_tail.env_at_T0"] },
      { "filename": "prime_tail_envelope.json", "fields": ["prime_tail.env_T0_hi"] },
      { "filename": "explicit_formula.json", "fields": ["explicit_formula.epsilon_eff_lo"] }
    ],
    "writes": [
      { "filename": "uniform_analytic_rollup.json", "consumed_by": ["master_report", "docs"] }
    ]
  },
  "validation": {
    "math_checks": [
      "Confirm that gamma_tail.env_at_T0 and prime_tail.env_T0_hi are valid upper envelopes at T0.",
      "Confirm that explicit_formula.epsilon_eff_lo is a valid lower bound on epsilon_eff(T0).",
      "Check that strict inequality E_T0_lo > B_T0_hi is the intended condition for uniform rollup."
    ],
    "structural_checks": [
      "kind must equal 'uniform_analytic_rollup'.",
      "meta.tool must equal 'rollup_uniform'.",
      "All real-valued fields are strings.",
      "meta.sha256 is computed from canonical JSON."
    ],
    "status": "OK",
    "issues": []
  },
  "cross_ai_prompt": "Audit rollup_uniform.py, which reads gamma and prime envelopes and an explicit formula epsilon_eff lower bound, then checks E_lo(T0) > B_hi(T0) to certify uniformity on [T0,∞) under monotonicity assumptions. Confirm the algebra and discuss strict versus non-strict inequality."
}
```

---

## `rv_mangoldt_bounds.py` 

**Role:** analytic / RvM monotonicity witness (infinitude check)

### Purpose

Compute a **Riemann–von Mangoldt lower bound** (N_{\text{lower}}(T)) and a **monotonicity certificate** at (T_0). If

[
\frac{d}{dT}N_{\text{lower}}(T)\big|_{T=T_0} \ge 0
]

under an assumed bound on (S(T)), the module records:

* `monotone_for_T_ge_T0 = True`,
* `infinitude_certified = True`,

encoding that (N(T)) is nondecreasing for (T \ge T_0) and hence zeros are infinite.

---

### CLI interface

* `--T0` *(required, str)*
  Base point (T_0 > 0).

* `--dps` *(optional, int, default `300`)*
  Decimal precision.

* `--out` *(required, str)*
  Output JSON path.

* `--theory-out` *(optional, str or null)*
  Optional theory JSON path.

---

### Output artifacts

####1 Main JSON

* **kind**: `"rv_mangoldt_bounds"`

* `inputs`:

  * `T0` *(str)* – base point (T_0).

* `rv_mangoldt`:

  * `lower_bound_value` *(str)* – (N_{\text{lower}}(T_0)).
  * `S_bound`:

    * `a` *(str)* – constant in (|S(T)| \le a \log T + b).
    * `b` *(str)* – constant in the same bound.
    * `T_star` *(str)* – (T_0) as the base of the bound.
  * `monotone_for_T_ge_T0` *(bool)* – `True` iff derivative ≥ 0 at (T_0).
  * `infinitude_certified` *(bool)* – currently identical to `monotone_for_T_ge_T0`.

* `meta`:

  * `tool` = `"rv_mangoldt_bounds"`.
  * `dps` *(int)*.
  * `created_utc` *(str, ISO8601 UTC)*.
  * `sha256` *(str)* – computed via `write_json`.

All reals are strings.

####2 Theory JSON (optional)

Written only if `--theory-out` is provided.

* **kind**: `"rv_mangoldt_bounds_theory"`
* `lemma` *(str)* – `"RvMInfinitudeLowerBound"`.
* `hypotheses`:

  * `T0: {">": "0"}`.
  * `S(T): {"abs_le": "a log T + b"}`.
* `conclusion.forall_T_ge_T0` *(str)* – informal statement about (N(T)), (N_{\text{lower}}), and monotonicity.
* `constants`:

  * `a`, `b`, `T0` *(str)*.
* `meta`:

  * `tool` = `"rv_mangoldt_bounds"`.
  * `dps`, `created_utc`.
    *(No sha256 here; this one is plain-written.)*

---

### 4. Dependencies and wiring

* **Reads:** none.
* **Writes:** `rv_mangoldt_bounds.json` plus optional theory JSON.

Downstream: high-level documentation or any “infinitude witness” / meta-summary.

---

### 5. Math & validity checklist

Core components:

* `S_bound_params(T)` returns fixed constants:

  * ( a = 0.20, b = 1.00).

* Main term:

  * ( N_{\text{main}}(T) = u \log u - u + 0.875 ) with (u = T/(2\pi)).

* Lower bound:

  * ( N_{\text{lower}}(T) = N_{\text{main}}(T) - (a \log T + b) - C/T ) with (C=1).

* Monotonicity derivative at (T_0):
  For (T > 0),
  [
  u = T/(2\pi),\quad
  dN = \frac{1}{2\pi} \log u - \frac{a}{T} + \frac{C}{T^2}.
  ]
  They set `monotone_for_T_ge_T0 = (dN >= 0)`.

**Status:** `OK` (within its model). It encodes a specific choice of a,b,C; any sharpening is separate work.

---

### 6. Issues & recommendations

* **MINOR_WARN:** Constants `a,b,C` are hard-coded; if you later update your “gold-standard” S(T) or remainder bounds, this script needs to be edited (math, not structure).
* Seems consistent for a one-shot `T0` monotonicity witness; no loop or heavy numerics.

---

### 7. Cross-AI validation prompt

> Audit rv_mangoldt_bounds.py, which defines N_lower(T) = N_main(T) - (a log T + b) - C/T with a=0.20, b=1.00, C=1, and sets monotone_for_T_ge_T0 based on the sign of dN/dT at T0. Check the derivative formula, confirm whether this choice of a,b,C is plausible for an S(T) bound, and discuss how sensitive monotonicity is to these constants.

---

### JSON spec for `rv_mangoldt_bounds.py`

```json
{
  "module": "rv_mangoldt_bounds.py",
  "tool_id": "rv_mangoldt_bounds",
  "role": "analytic",
  "cli": {
    "description": "Riemann–von Mangoldt lower bound and monotonicity certificate at T0.",
    "args": [
      { "flag": "--T0", "name": "T0", "required": true, "type": "str", "default": null, "choices": null, "notes": "Base point T0 (>0)." },
      { "flag": "--dps", "name": "dps", "required": false, "type": "int", "default": 300, "choices": null, "notes": "Decimal precision for mpmath." },
      { "flag": "--out", "name": "out", "required": true, "type": "str", "default": null, "choices": null, "notes": "Output JSON path." },
      { "flag": "--theory-out", "name": "theory_out", "required": false, "type": "str", "default": null, "choices": null, "notes": "Optional theory JSON path." }
    ]
  },
  "outputs": [
    {
      "filename": "rv_mangoldt_bounds.json",
      "primary": true,
      "kind": "rv_mangoldt_bounds",
      "schema_version": "v2.1",
      "blocks": {
        "inputs": {
          "description": "Base point for the RvM bound.",
          "fields": [
            { "path": "inputs.T0", "type": "str", "meaning": "Base point T0." }
          ]
        },
        "rv_mangoldt": {
          "name": "rv_mangoldt",
          "fields": [
            { "path": "rv_mangoldt.lower_bound_value", "type": "str", "meaning": "N_lower(T0)." },
            { "path": "rv_mangoldt.S_bound.a", "type": "str", "meaning": "Constant a in |S(T)| <= a log T + b." },
            { "path": "rv_mangoldt.S_bound.b", "type": "str", "meaning": "Constant b in |S(T)| <= a log T + b." },
            { "path": "rv_mangoldt.S_bound.T_star", "type": "str", "meaning": "Base point T0 for the S(T) bound." },
            { "path": "rv_mangoldt.monotone_for_T_ge_T0", "type": "bool", "meaning": "True if dN_lower/dT >= 0 at T0." },
            { "path": "rv_mangoldt.infinitude_certified", "type": "bool", "meaning": "Currently identical to monotone_for_T_ge_T0." }
          ]
        },
        "meta": {
          "fields": [
            { "path": "meta.tool", "type": "str", "meaning": "Tool name; must be 'rv_mangoldt_bounds'." },
            { "path": "meta.dps", "type": "int", "meaning": "Decimal precision used." },
            { "path": "meta.created_utc", "type": "str", "meaning": "Creation time (UTC)." },
            { "path": "meta.sha256", "type": "str", "meaning": "SHA-256 for canonical payload." }
          ]
        }
      }
    }
  ],
  "dependencies": {
    "reads": [],
    "writes": [
      { "filename": "rv_mangoldt_bounds.json", "consumed_by": ["docs", "master_report"] }
    ]
  },
  "validation": {
    "math_checks": [
      "Verify derivative formula dN/dT for N_main(T) and N_lower(T).",
      "Confirm that chosen a,b,C values are consistent with your S(T) bound assumptions.",
      "Check that monotone_for_T_ge_T0 is correctly set from sign of dN."
    ],
    "structural_checks": [
      "kind must equal 'rv_mangoldt_bounds'.",
      "meta.tool must equal 'rv_mangoldt_bounds'.",
      "All real-valued scalars are strings.",
      "meta.sha256 is computed from canonical JSON."
    ],
    "status": "OK",
    "issues": []
  },
  "cross_ai_prompt": "Audit rv_mangoldt_bounds.py: it defines N_lower(T) = N_main(T) - (a log T + b) - C/T with fixed a,b,C and sets monotone_for_T_ge_T0 based on the sign of dN/dT at T0. Check the derivative and reasonableness of the constants for an S(T) bound."
}
```

---

## `rolling_T_uniform_cert_v3.py` 

**Role:** rollup (adaptive uniform certificate on ([T_0, T_1]))

### Purpose

Use **analytic tail bounds** from `analytic_bounds.json` and an adaptive mesh to certify a **uniform inequality** on a whole interval ([T_0, T_1]):

[
\delta(T) = \epsilon_{\text{eff,lo}} - \text{prime_tail}(T) - \text{gamma_tail}(T) - \text{grid_error} \ge 0
]

for all (T \in [T_0, T_1]), using power-law tails:

* prime tail (\le C_p T^{-a_p}),
* gamma tail (\le C_g T^{-a_g}).

It adaptively refines subintervals until all left endpoints have (\delta(T) \ge \text{delta_target}) or `mesh_max` is reached.

---

### CLI interface

* `--packet-dir` *(required, str)*
  Root packet directory; must contain `analytic_bounds.json`.

* `--T0` *(required, str)*
  Left endpoint (T_0).

* `--T1` *(required, str)*
  Right endpoint (T_1); must satisfy `T0 < T1`.

* `--delta-target` *(optional, str, default `"1e-12"`)*
  Target safety margin (\delta_{\text{target}}).

* `--mesh-initial` *(optional, int, default `128`)*
  Initial number of subintervals.

* `--mesh-max` *(optional, int, default `131072`)*
  Maximum number of refinement intervals.

* `--dps` *(optional, int, default `220`)*
  Decimal precision.

* `--digits` *(optional, int, default `120`)*
  Digits of precision for string output via `nstr`.

* `--out` *(required, str)*
  Output JSON path.

---

### Output artifacts

####1 Main JSON

* **kind**: `"rolling_T_uniform"`

* `inputs`:

  * `packet_dir` *(str)*.
  * `T0` *(str)* – (possibly clamped up to tails’ own T0 if analytic_bounds imposes one).
  * `T1` *(str)*.
  * `delta_target` *(str)* – target safety margin.
  * `mesh_initial` *(int)*.
  * `mesh_max` *(int)*.
  * `dps` *(int)*.
  * `digits` *(int)*.

* `bounds`:

  * `eps_eff_lo` *(str)* – lower bound on epsilon_eff.
  * `grid_error_hi` *(str)* – upper bound on grid error.
  * `prime_tail`:

    * `C` *(str)* – prime tail constant (C_p) (HI side).
    * `a` *(str)* – prime tail exponent (a_p) (LO side).
  * `gamma_tail`:

    * `C` *(str)* – gamma tail constant (C_g) (HI side).
    * `a` *(str)* – gamma tail exponent (a_g) (LO side).

* `mesh`:

  * `intervals` *(int)* – total intervals processed/refined.
  * `max_depth` *(int)* – maximum recursion depth used.
  * `elapsed_sec` *(str)* – wall-clock time (seconds).

* `result`:

  * `PASS` *(bool)* – `True` iff all checked intervals meet the margin before hitting `mesh_max`.
  * `delta_min` *(str)* – minimum observed (\delta(T)) across left endpoints.
  * `witness` *(dict)* – information about a critical interval or point:

    * In fail branch from `adaptive_cert`: at least `T_left`, `T_right` (strings).
    * After the post-processing block:

      * Always contains a “degenerate” interval around `T_star`:

        * `T_left`, `T_right`, `T_star`, `delta_at_T_star`, `depth`, `mode`.

* `meta`:

  * `tool` = `"rolling_T_uniform_cert_v3"`.
  * `dps` *(int)*.
  * `created_utc` *(str)*.
  * `sha256` *(str)* – deterministic hash via `write_json`.

All numeric analysis values are stringified via `nstr` with `digits` digits.

---

### 4. Dependencies and wiring

* **Reads:**

  * `analytic_bounds.json` from `packet-dir`:

    * Accepts either:

      * Flat layout: top-level `eps_eff_lo`, `grid_error_hi`, `prime_tail`, `gamma_tail`, or
      * Nested layout: `bounds.{eps_eff_lo,grid_error_hi,prime_tail,gamma_tail}`.
    * Prime tail block:

      * `prime_tail.C`, `prime_tail.a`, and optional `prime_tail.T0`.
    * Gamma tail block:

      * `gamma_tail.C`, `gamma_tail.a`, and optional `gamma_tail.T0`.

* **Writes:**

  * `rolling_T_uniform.json` (from `--out`).

Downstream: global proofs / summaries as a **uniform T-interval certificate**.

---

### 5. Math & validity checklist

Core math:

* **Interval parsing helpers** `as_mpf_lo` / `as_mpf_hi`:

  * Accept:

    * strings `"x"` or interval strings `"[lo, hi]"`,
    * dicts with `{"lo": ..., "hi": ...}`,
    * mpi-like objects with `.a` / `.b`,
    * plain numbers.
  * `as_mpf_lo` always picks a lower-bound value; `as_mpf_hi` picks an upper-bound value.

* **Tail model:**

  * Prime tail: ( \le C_p / T^{a_p} ),
  * Gamma tail: ( \le C_g / T^{a_g} ),
  * Evidence taken from analytic_bounds.

* **Delta at left endpoint** (T_{\text{left}}):
  [
  \delta_{\text{lo}}(T_{\text{left}}) = \epsilon_{\text{eff,lo}}

  * \frac{C_p}{T_{\text{left}}^{a_p}}
  * \frac{C_g}{T_{\text{left}}^{a_g}}
  * \text{grid_error_hi}.
    ]

* **Adaptive strategy:**

  * Start with `mesh_initial` uniform subintervals on ([T_0, T_1]).
  * For each interval `[a,b]`:

    * Update `global_min` (= min delta_lo at visited left endpoints).
    * If `delta_lo(a) >= delta_target`, do not refine further.
    * Else, if under `mesh_max`, bisect `[a,b]` into `[a,mid]` and `[mid,b]` (DFS stack).
  * Terminate when:

    * Work list empty → PASS,
    * or `total >= mesh_max` → FAIL with current “witness interval”.

* **Tail domain clamp:**

  * If analytic_bounds declares `T0` in `prime_tail` or `gamma_tail`, then:

    * `T0` is clamped up to max of these tail T0’s before certifying.

**Status:** `OK` / **MINOR_WARN** (about numerical choices, not structure)

* Logic matches the spec of a rolling T uniform cert with tail bounds.
* Main sensitivity is to:

  * correctness/tightness of analytic_bounds,
  * choice of `delta_target`, `mesh_initial`, `mesh_max`, and dps.

---

### 6. Issues & recommendations

* **MINOR_WARN – pass witness shape:**
  In PASS, `witness` is synthesized with `mode = "argmin-degenerate"` around `argmin_T` and `depth = 0`. That’s fine, but consumers must not assume `depth` reflects recursion depth in PASS cases.
* **MINOR_WARN – analytic_bounds schema:**
  You already tolerate flat vs nested via `b = ab.get("bounds", ab)`. If analytic_bounds ever changes key names (`eps_eff_lo`, `grid_error_hi`, etc.), this script must follow.

No math changes recommended unless you explicitly decide to tighten the tail models.

---

### 7. Cross-AI validation prompt

> Audit rolling_T_uniform_cert_v3.py, which uses analytic_bounds.json to define eps_eff_lo, grid_error_hi, and power-law tail bounds prime_tail.C/a and gamma_tail.C/a, then adaptively certifies delta(T) = eps_eff_lo - Cp/T^ap - Cg/T^ag - grid_hi >= 0 on [T0,T1] using left-endpoint evaluation and a DFS bisection scheme. Check whether evaluating at left endpoints is sufficient given monotonicity of tails and whether the as_mpf_lo/as_mpf_hi interval conventions are correctly “worst-case conservative”.

---

### JSON spec for `rolling_T_uniform_cert_v3.py`

```json
{
  "module": "rolling_T_uniform_cert_v3.py",
  "tool_id": "rolling_T_uniform_cert_v3",
  "role": "rollup",
  "cli": {
    "description": "Adaptive rolling uniform certificate on [T0, T1] using analytic tail bounds.",
    "args": [
      { "flag": "--packet-dir", "name": "packet_dir", "required": true, "type": "str", "default": null, "choices": null, "notes": "Root packet directory containing analytic_bounds.json." },
      { "flag": "--T0", "name": "T0", "required": true, "type": "str", "default": null, "choices": null, "notes": "Left endpoint T0." },
      { "flag": "--T1", "name": "T1", "required": true, "type": "str", "default": null, "choices": null, "notes": "Right endpoint T1 (must satisfy T0 < T1)." },
      { "flag": "--delta-target", "name": "delta_target", "required": false, "type": "str", "default": "1e-12", "choices": null, "notes": "Target safety margin delta." },
      { "flag": "--mesh-initial", "name": "mesh_initial", "required": false, "type": "int", "default": 128, "choices": null, "notes": "Initial number of mesh intervals." },
      { "flag": "--mesh-max", "name": "mesh_max", "required": false, "type": "int", "default": 131072, "choices": null, "notes": "Maximum number of refinement intervals." },
      { "flag": "--dps", "name": "dps", "required": false, "type": "int", "default": 220, "choices": null, "notes": "Decimal precision for mpmath." },
      { "flag": "--digits", "name": "digits", "required": false, "type": "int", "default": 120, "choices": null, "notes": "Digits of precision for output strings." },
      { "flag": "--out", "name": "out", "required": true, "type": "str", "default": null, "choices": null, "notes": "Output JSON path." }
    ]
  },
  "outputs": [
    {
      "filename": "rolling_T_uniform.json",
      "primary": true,
      "kind": "rolling_T_uniform",
      "schema_version": "v2.1",
      "blocks": {
        "inputs": {
          "description": "Global parameters for the rolling T uniform cert.",
          "fields": [
            { "path": "inputs.packet_dir", "type": "str", "meaning": "Root packet directory containing analytic_bounds.json." },
            { "path": "inputs.T0", "type": "str", "meaning": "Left endpoint T0 (possibly clamped up to tails’ T0)." },
            { "path": "inputs.T1", "type": "str", "meaning": "Right endpoint T1." },
            { "path": "inputs.delta_target", "type": "str", "meaning": "Target safety margin delta." },
            { "path": "inputs.mesh_initial", "type": "int", "meaning": "Initial number of mesh intervals." },
            { "path": "inputs.mesh_max", "type": "int", "meaning": "Maximum number of refinement intervals." },
            { "path": "inputs.dps", "type": "int", "meaning": "Decimal precision for mpmath." },
            { "path": "inputs.digits", "type": "int", "meaning": "Digits of precision for output strings." }
          ]
        },
        "bounds": {
          "name": "bounds",
          "fields": [
            { "path": "bounds.eps_eff_lo", "type": "str", "meaning": "Lower bound on epsilon_eff." },
            { "path": "bounds.grid_error_hi", "type": "str", "meaning": "Upper bound on grid error." },
            { "path": "bounds.prime_tail.C", "type": "str", "meaning": "Prime tail constant Cp (HI)." },
            { "path": "bounds.prime_tail.a", "type": "str", "meaning": "Prime tail exponent ap (LO)." },
            { "path": "bounds.gamma_tail.C", "type": "str", "meaning": "Gamma tail constant Cg (HI)." },
            { "path": "bounds.gamma_tail.a", "type": "str", "meaning": "Gamma tail exponent ag (LO)." }
          ]
        },
        "mesh": {
          "name": "mesh",
          "fields": [
            { "path": "mesh.intervals", "type": "int", "meaning": "Total intervals processed/refined." },
            { "path": "mesh.max_depth", "type": "int", "meaning": "Maximum recursion depth reached." },
            { "path": "mesh.elapsed_sec", "type": "str", "meaning": "Elapsed wall time (seconds)." }
          ]
        },
        "result": {
          "name": "result",
          "fields": [
            { "path": "result.PASS", "type": "bool", "meaning": "True if delta(T) >= delta_target on [T0,T1] within mesh_max." },
            { "path": "result.delta_min", "type": "str", "meaning": "Minimum observed delta(T) over checked left endpoints." },
            { "path": "result.witness", "type": "object", "meaning": "Witness interval/point data (T_left, T_right, possibly T_star, delta_at_T_star, depth, mode)." }
          ]
        },
        "meta": {
          "fields": [
            { "path": "meta.tool", "type": "str", "meaning": "Tool name; must be 'rolling_T_uniform_cert_v3'." },
            { "path": "meta.dps", "type": "int", "meaning": "Decimal precision used." },
            { "path": "meta.created_utc", "type": "str", "meaning": "Creation time (UTC)." },
            { "path": "meta.sha256", "type": "str", "meaning": "SHA-256 of canonical payload (without meta.sha256)." }
          ]
        }
      }
    }
  ],
  "dependencies": {
    "reads": [
      { "filename": "analytic_bounds.json", "fields": ["bounds.eps_eff_lo", "bounds.grid_error_hi", "bounds.prime_tail.C", "bounds.prime_tail.a", "bounds.prime_tail.T0", "bounds.gamma_tail.C", "bounds.gamma_tail.a", "bounds.gamma_tail.T0", "eps_eff_lo", "grid_error_hi", "prime_tail", "gamma_tail"] }
    ],
    "writes": [
      { "filename": "rolling_T_uniform.json", "consumed_by": ["master_report", "docs", "final_uniform_summary"] }
    ]
  },
  "validation": {
    "math_checks": [
      "Confirm that analytic_bounds.json supplies conservative power-law tail bounds and eps_eff_lo/grid_error_hi.",
      "Check that delta_lo(T_left) computed with as_mpf_lo/as_mpf_hi is pointwise conservative.",
      "Verify that left-endpoint evaluation is sufficient under monotonicity of tails and grid error."
    ],
    "structural_checks": [
      "kind must equal 'rolling_T_uniform'.",
      "meta.tool must equal 'rolling_T_uniform_cert_v3'.",
      "All real-valued scalars are strings via nstr.",
      "meta.sha256 is computed from canonical JSON."
    ],
    "status": "MINOR_WARN",
    "issues": [
      {
        "level": "WARN",
        "summary": "Certification depends on analytic_bounds schema and monotonicity assumptions.",
        "detail": "Any change in analytic_bounds.json keys or tail models must be mirrored here; also, left-endpoint sampling relies on tails being decreasing."
      }
    ]
  },
  "cross_ai_prompt": "Audit rolling_T_uniform_cert_v3.py, which uses analytic_bounds.json to define eps_eff_lo, grid_error_hi, and power-law tail bounds, then adaptively certifies delta(T) >= 0 on [T0,T1] by left-endpoint evaluation and DFS bisection. Check if this is conservative and mathematically sound under the assumed monotonicity."
}
```


## `prime_block_norm.py` 

**Role:** analytic prime-block operator norm cap from zeros.

---

#### CLI summary

* `--zeros` *(str, required)*
  Path to zeros data (JSON or text).

* `--N` *(int, optional, default `None`)*
  If reading **text** zeros, use only the first `N` zeros.

* `--sigma` *(str, required)*
  Gaussian width parameter `sigma > 0`.

* `--k0` *(str, required)*
  Notch parameter `k0 > 0`.

* `--scale` *(str, optional, default `"1.0"`)*
  Envelope scale ≥ 1 (kept for compatibility with earlier bounds).

* `--Tcut` *(str, optional, default `None`)*
  Cutoff `T`; default = max zero in file (clamped to max if larger).

* `--tail-m` *(int, optional, default `8`)*
  Tail split width `M` in multiples of `sigma` for numeric tail part.

* `--dps` *(int, optional, default `300`)*
  Decimal precision for `mpmath`.

* `--out` *(str, required)*
  Output JSON path.

---

#### JSON structure

All reals stored as **strings** via `mp_str`.

```jsonc
{
  "kind": "prime_block_norm",
  "inputs": {
    "zeros_path": "path/to/zeros",
    "N": 20000,
    "sigma": "6.0000000000...",
    "k0": "0.2500000000...",
    "scale": "1.0",
    "Tcut": null,
    "tail_m": 8
  },
  "prime_block_norm": {
    "used_operator_norm": "<cap_hi>",
    "operator_norm_cap_hi": "<cap_hi>",
    "method": "zeros_analytic_cap/v2_tail_split",
    "sum_zeros_contrib": "<2*part>",
    "tail_bound_hi": "<2*tail>",
    "cap_total_hi": "<cap_hi>",
    "cutoff_T": "<T>"
  },
  "meta": {
    "tool": "prime_block_norm",
    "created_utc": "<ISO8601 UTC>",
    "dps": 300,
    "zeros_count": 6317,
    "sha256": "<digest>"
  },
  "PASS": true
}
```

* `zeros_count` = count of zeros `g` with `0 < g <= T`.
* `sha256` is computed over canonical JSON (sorted, no `meta.sha256`), then written in a second pass.

---

#### Dependencies & wiring

* **Reads**

  * `--zeros`:

    * Text: last token per non-empty line, up to `N` lines.
    * JSON:

      * list: direct list of values.
      * dict with `"zeros"`: each item may be scalar or dict with `gamma / t / im / imag / value`.

* **Writes**

  * `prime_block_norm.json` (or whatever `--out` is set to).
    Consumed by:

    * `continuum_operator_rollup.py` (via the flat or full form),
    * param search, rollups, and final reports.

---

#### Math / validity

* **Weight function:**

  [
  W(\gamma) = c \cdot e^{-(\gamma/\sigma)^2} \left(1 - e^{-(\gamma/k_0)^2}\right),\quad
  c = \text{scale}
  ]

* **Density envelope:**

  ```python
  density_envelope(t) = log(t) / (2*pi)
  ```

  with `t` clamped to at least `e` for small inputs.

* **Main sum:**

  Zeros list is sorted, positive zeros only. For a cutoff `T`:

  [
  \text{part} = \sum_{0 < \gamma \le T} \frac{W(\gamma)}{\sqrt{\tfrac14 + \gamma^2}}.
  ]

* **Tail:**

  * Choose `A = T + M*sigma`.

  * Numeric near tail:

    [
    \text{tail_near} = \int_T^A \frac{W(t),\log t}{2\pi t},dt.
    ]

  * Remainder bound for ([A,\infty)):

    * Drop notch factor (≤ 1).

    * Bound `log(t)` for `t ≥ A` by `log(A)` (monotone).

    * Integrate core:

      [
      \int_A^\infty e^{-(t/\sigma)^2} \frac{\log A}{t} , dt
      = \frac{\log A}{2}, E_1!\left(\left(\frac{A}{\sigma}\right)^2\right).
      ]

    * Include factor `c/(2π)` from density:

      [
      \text{remainder_bound}
      = \frac{c,\log A}{4\pi}, E_1!\left((A/\sigma)^2\right).
      ]

  * Total tail:

    [
    \text{tail} = \text{tail_near} + \text{remainder_bound}.
    ]

* **Final cap:**

  [
  \text{cap_hi} = 2\left( \text{part} + \text{tail} \right),
  ]

  and this value is used consistently for all operator-norm fields.

**Status:** `OK` / **MINOR_WARN**

* Assumes zeros are **sorted ascending** in the input; the `break` on `g > T` relies on this.
* Tail bound is rigorously conservative (drops notch, uses `log(A)` upper bound).

---

#### How to validate this module

1. **Stability vs `tail_m`:**
   Run with several values, e.g. `tail_m = 4, 8, 12`, and confirm `cap_total_hi` stabilizes.

2. **Stability vs `Tcut`:**
   Explicitly vary `Tcut` slightly below/above the last zero to check robustness.

3. **Cross-check with cruder bound:**
   Implement a simpler, obviously conservative tail bound (e.g. bounding `log t` by `log(T)` on `[T,∞)` and an even larger integrand) and check that this script’s `cap_hi` is ≤ that crude cap.

4. **Zero parsing:**
   Confirm the text zeros file is strictly increasing in `gamma` so the `break` is valid.

---

#### Cross-AI validation prompt

> You are auditing `prime_block_norm.py`, which computes an operator-norm cap for a prime block operator by summing a Gaussian-notched weight over zeros up to `T`, then adding a tail bound obtained by splitting `[T, A]` (numeric quad) and `[A, ∞)` (using an exponential integral E1 bound with density log(t)/(2π)). Check whether the tail estimate is rigorously conservative, whether dropping the notch and using log(A) is valid for t ≥ A, and whether any extra safety factors should be added for numerical stability.

---

#### JSON/CLI spec object (for your master summary)

```json
{
  "module": "prime_block_norm.py",
  "tool_id": "prime_block_norm",
  "role": "analytic",
  "cli": {
    "description": "Zeros-driven analytic operator-norm cap for the prime block",
    "args": [
      { "flag": "--zeros", "name": "zeros", "required": true, "type": "str", "default": null, "notes": "Path to zeros data (JSON or text)." },
      { "flag": "--N", "name": "N", "required": false, "type": "int", "default": null, "notes": "Use only first N zeros when reading text." },
      { "flag": "--sigma", "name": "sigma", "required": true, "type": "str", "default": null, "notes": "Gaussian width sigma > 0." },
      { "flag": "--k0", "name": "k0", "required": true, "type": "str", "default": null, "notes": "Notch parameter k0 > 0." },
      { "flag": "--scale", "name": "scale", "required": false, "type": "str", "default": "1.0", "notes": "Envelope scale >= 1." },
      { "flag": "--Tcut", "name": "Tcut", "required": false, "type": "str", "default": null, "notes": "Cutoff T; default = max zero in file." },
      { "flag": "--tail-m", "name": "tail_m", "required": false, "type": "int", "default": 8, "notes": "Tail split width M in multiples of sigma." },
      { "flag": "--dps", "name": "dps", "required": false, "type": "int", "default": 300, "notes": "Decimal precision for mpmath." },
      { "flag": "--out", "name": "out", "required": true, "type": "str", "default": null, "notes": "Output JSON path." }
    ]
  },
  "outputs": [
    {
      "filename": "prime_block_norm.json",
      "primary": true,
      "kind": "prime_block_norm",
      "schema_version": "v2.1",
      "blocks": {
        "inputs": {
          "fields": [
            { "path": "inputs.zeros_path", "type": "str" },
            { "path": "inputs.N", "type": "int or null" },
            { "path": "inputs.sigma", "type": "str" },
            { "path": "inputs.k0", "type": "str" },
            { "path": "inputs.scale", "type": "str" },
            { "path": "inputs.Tcut", "type": "str or null" },
            { "path": "inputs.tail_m", "type": "int" }
          ]
        },
        "prime_block_norm": {
          "fields": [
            { "path": "prime_block_norm.used_operator_norm", "type": "str" },
            { "path": "prime_block_norm.operator_norm_cap_hi", "type": "str" },
            { "path": "prime_block_norm.method", "type": "str" },
            { "path": "prime_block_norm.sum_zeros_contrib", "type": "str" },
            { "path": "prime_block_norm.tail_bound_hi", "type": "str" },
            { "path": "prime_block_norm.cap_total_hi", "type": "str" },
            { "path": "prime_block_norm.cutoff_T", "type": "str" }
          ]
        },
        "meta": {
          "fields": [
            { "path": "meta.tool", "type": "str" },
            { "path": "meta.created_utc", "type": "str" },
            { "path": "meta.dps", "type": "int" },
            { "path": "meta.zeros_count", "type": "int" },
            { "path": "meta.sha256", "type": "str" }
          ]
        },
        "root": {
          "fields": [
            { "path": "PASS", "type": "bool" }
          ]
        }
      }
    }
  ]
}
```

---

## `prime_tail_envelope.py` 

**Role:** analytic envelope for the prime tail at a fixed (T_0).

---

#### CLI summary

* `--T0` *(str, required)*
  Cutoff `T0 > 0`.

* `--sigma` *(str, required)*
  Gaussian width `sigma > 0`.

* `--k0` *(str, required)*
  Notch parameter `k0`.

* `--A-prime` / `--A_prime` *(str, optional, default = long constant)*
  `A_prime` parameter for the model.

* `--K` *(int, optional, default `3`)*
  Integer parameter shaping the envelope.

* `--env-T0-hi` *(str, optional, default `None`)*
  Explicit override for `env_T0_hi`; if provided, bypasses the analytic model.

* `--dps` *(int, optional, default `200`)*
  Decimal precision.

* `--out` *(str, required)*
  Output JSON path.

* `--theory-out` *(str, optional)*
  Optional sidecar theory JSON path.

---

#### JSON structure

All reals are strings; `K` is an integer.

```jsonc
{
  "kind": "prime_tail_envelope",
  "inputs": {
    "T0": "<string>",
    "sigma": "<string>",
    "k0": "<string>",
    "A_prime": "<string>",
    "K": 3
  },
  "prime_tail": {
    "env_T0_hi": "<string>",
    "norm": "<string>"
  },
  "meta": {
    "tool": "prime_tail_envelope",
    "dps": 200,
    "created_utc": "<ISO8601 UTC>",
    "sha256": "<digest>"
  }
}
```

Optional theory JSON:

```jsonc
{
  "kind": "prime_tail_envelope_theory",
  "inputs": { ...same inputs... },
  "theory": {
    "lemma": "PrimeTailEnvelope",
    "statement": "For T >= T0, the prime tail contribution is bounded above by ..."
  },
  "meta": {
    "tool": "prime_tail_envelope",
    "dps": 200,
    "created_utc": "<ISO8601 UTC>"
  }
}
```

---

#### Math / model

* Core model (when no override):

  ```python
  x    = sigma * k0 * T0
  base = exp(-(x**2) / 4)
  env  = A_prime * base / (1 + K)
  ```

  So (\text{env_T0_hi} = A' \exp(-x^2/4) / (1+K)) with (x = \sigma k_0 T_0).

* This value is used both as:

  * `prime_tail.env_T0_hi` (explicit bound at `T0`), and
  * `prime_tail.norm` (same scalar for downstream use).

* Overrides: if `--env-T0-hi` is given, the module **trusts** that explicit value and just records it.

**Status:** `OK` (model preserved; envelope is clearly conservative and decays fast in `T0`).

---

#### How to validate this module

1. **Check monotonicity in T:**
   For fixed `(sigma, k0, A_prime, K)`, verify numerically that the underlying tail model you are bounding decays faster than or comparably to this envelope for `T ≥ T0`.

2. **Parameter sanity:**
   Confirm that your chosen `A_prime` and `K` values empirically dominate the actual prime tail norm from your full pipeline at several sample points.

3. **Override safety:**
   For runs using `--env-T0-hi`, make sure the provided `env_T0_hi` is *greater* than or equal to any numerically observed tail norm at `T0`.

---

#### Cross-AI validation prompt

> You are auditing `prime_tail_envelope.py`, which defines an analytic prime tail envelope at T0 by env_T0_hi = A_prime * exp(-(sigma*k0*T0)^2/4)/(1+K), with optional manual override. Check whether this model is plausibly conservative for the intended prime tail, whether the decay in T0 is rapid enough for your parameter ranges, and suggest any simple ways to tighten or validate A_prime and K against numerical experiments.

---

#### JSON/CLI spec object

```json
{
  "module": "prime_tail_envelope.py",
  "tool_id": "prime_tail_envelope",
  "role": "tails",
  "cli": {
    "description": "Prime tail envelope at T0 using A_prime and K.",
    "args": [
      { "flag": "--T0", "name": "T0", "required": true, "type": "str", "default": null, "notes": "Cutoff T0 (>0)." },
      { "flag": "--sigma", "name": "sigma", "required": true, "type": "str", "default": null, "notes": "Gaussian width sigma (>0)." },
      { "flag": "--k0", "name": "k0", "required": true, "type": "str", "default": null, "notes": "Notch parameter k0." },
      { "flag": "--A-prime", "name": "A_prime", "required": false, "type": "str", "default": "<long-constant>", "notes": "A_prime parameter for prime tail model." },
      { "flag": "--K", "name": "K", "required": false, "type": "int", "default": 3, "notes": "Auxiliary integer shaping the envelope." },
      { "flag": "--env-T0-hi", "name": "env_T0_hi", "required": false, "type": "str", "default": null, "notes": "Explicit override for env_T0_hi." },
      { "flag": "--dps", "name": "dps", "required": false, "type": "int", "default": 200, "notes": "Decimal precision for mpmath." },
      { "flag": "--out", "name": "out", "required": true, "type": "str", "default": null, "notes": "Output JSON path." },
      { "flag": "--theory-out", "name": "theory_out", "required": false, "type": "str", "default": null, "notes": "Optional theory JSON path." }
    ]
  },
  "outputs": [
    {
      "filename": "prime_tail_envelope.json",
      "primary": true,
      "kind": "prime_tail_envelope",
      "schema_version": "v2.1",
      "blocks": {
        "inputs": { "fields": [
          { "path": "inputs.T0", "type": "str" },
          { "path": "inputs.sigma", "type": "str" },
          { "path": "inputs.k0", "type": "str" },
          { "path": "inputs.A_prime", "type": "str" },
          { "path": "inputs.K", "type": "int" }
        ]},
        "prime_tail": { "fields": [
          { "path": "prime_tail.env_T0_hi", "type": "str" },
          { "path": "prime_tail.norm", "type": "str" }
        ]},
        "meta": { "fields": [
          { "path": "meta.tool", "type": "str" },
          { "path": "meta.dps", "type": "int" },
          { "path": "meta.created_utc", "type": "str" },
          { "path": "meta.sha256", "type": "str" }
        ]}
      }
    }
  ]
}
```

---

## `param_search.py` 

**Role:** orchestration / coarse grid search over `(sigma, k0)` with per-trial proofs; logs results to CSV.

---

#### CLI summary

* `--zeros` *(str, required)*
  Path to zeros text file.

* `--N` *(int, optional, default `20000`)*
  Number of zeros (lines) to use from `--zeros`.

* `--sigma-min` *(float, required)*

* `--sigma-max` *(float, required)*

* `--sigma-step` *(float, required)*
  Sigma grid (inclusive range via `frange`).

* `--k0-min` *(float, required)*

* `--k0-max` *(float, required)*

* `--k0-step` *(float, required)*
  k0 grid (inclusive).

* `--T0` *(str, optional, default `"1000000000"`)*
  Base `T0` for prime tail envelope.

* `--dps` *(int, optional, default `260`)*
  Decimal precision to pass through to subtools.

* `--outdir` *(str, optional, default `"PROOF_PACKET"`)*
  Output directory root. Per-trial subdirs `trial_sXXX_kYYY` are created inside.

* `--workers` *(int, optional, default `1`)*
  Reserved for future parallelization (currently unused).

---

#### Artifacts produced

For each `(sigma, k0)` trial, under `outdir/trial_s{sigma}_k{k0}`:

* `band_cert.json` (from `tools/band_cert.py`).
* `prime_block_norm.json` (from `tools/prime_block_norm.py`).
* `prime_block_norm.flat.json` (flattened used_operator_norm).
* `prime_tail_envelope.json` (from `tools/prime_tail_envelope.py`).
* `prime_tail_envelope.flat.json` (prime tail norm scalar).
* `gamma_tails.json` (from `tools/core_integral_prover.py`).
* `band_cert.flat.json` (band margin scalar + PASS flag).
* `continuum_operator_rollup.json` (from `tools/continuum_operator_rollup.py`).

Global CSV:

* `outdir/param_search_results.csv` with header:

  ```text
  sigma,k0,lhs_total,epsilon_eff,gap,pass,band_margin,prime_cap,prime_tail,gamma_tail
  ```

Each row is one `(sigma, k0)`.

---

#### Orchestration / dependencies

For each trial:

1. **window_gen**
   `tools/window_gen.py`:

   * `--mode gauss --sigma <sigma> --k0 <k0> --dps <dps> --out packs/rh/inputs/window.json`

2. **bands_make**
   `tools/bands_make.py`:

   * `--window-config packs/rh/inputs/window.json`
   * `--out packs/rh/inputs/auto_bands.json`
   * `--critical-left -0.50 --critical-right 0.50 --grid 6000 --digits 50`

3. **band_cert**
   `tools/band_cert.py`:

   * `--window-config packs/rh/inputs/window.json`
   * `--bands packs/rh/inputs/auto_bands.json`
   * `--out trial/.../band_cert.json`
   * `--dps <dps> --grid 6000`

   Then extracts `band_margin_val` via tolerant paths, and writes `band_cert.flat.json` with:

   ```jsonc
   {
     "band_margin": "<band_margin_val>",
     "PASS": <bool>
   }
   ```

4. **prime_block_norm**
   `tools/prime_block_norm.py` (module above):

   * `--zeros <zeros> --N <N> --sigma <sigma> --k0 <k0> --out trial/.../prime_block_norm.json --dps <dps>`

   Then flattens to `prime_block_norm.flat.json` with:

   ```jsonc
   { "used_operator_norm": "<cap>" }
   ```

5. **prime_tail_envelope**
   `tools/prime_tail_envelope.py`:

   * `--T0 <T0> --sigma <sigma> --k0 <k0> --A-prime 1.2762 --K 3 --out trial/.../prime_tail_envelope.json --dps <dps>`

   Extracts `prime_tail_val` from tolerant paths and writes stub `prime_tail_envelope.flat.json` with:

   ```jsonc
   { "prime_tail_norm": "<prime_tail_val>" }
   ```

6. **gamma tails**
   Uses the **Nth zero** as `Tstar`:

   * Reads the zeros text file; requires at least `N` lines.
   * `Tstar` = first token on line `N`.

   Runs:

   ```bash
   tools/core_integral_prover.py --T0 Tstar --window-config packs/rh/inputs/window.json --out trial/.../gamma_tails.json --dps <dps>
   ```

7. **grid error stub**
   Ensures there is `PROOF_PACKET/grid_error_bound.json`:

   ```jsonc
   { "grid_error_norm": "0" }
   ```

   if missing.

8. **continuum rollup**
   `tools/continuum_operator_rollup.py`:

   * `--band-cert band_cert.flat.json`
   * `--gamma-tails gamma_tails.json`
   * `--prime-block prime_block_norm.flat.json`
   * `--prime-tail prime_tail_envelope.flat.json`
   * `--grid-error PROOF_PACKET/grid_error_bound.json`
   * `--out trial/.../continuum_operator_rollup.json --dps <dps>`

   Then it reads:

   * `lhs_total = numbers.lhs_total`
   * `epsilon_eff = numbers.epsilon_eff`
   * `gamma_tail_val = numbers.gamma_tails`

   And logs:

   * `gap = epsilon_eff - lhs_total`
   * `pass = R.get("PASS", False)`

into the CSV row.

A running “best” record is kept and printed at the end.

---

#### Math / validity

* This script itself does **no deep math**, just:

  [
  \text{gap} = \epsilon_{\text{eff}} - \text{lhs_total},
  ]

  and basic grid iteration. All heavy lifting is in the subtools.

* It assumes:

  * zeros text format has the **first token** on each line as `T` (for `Tstar`), and
  * `continuum_operator_rollup`’s `numbers.lhs_total` and `numbers.epsilon_eff` have their v2.1 meanings.

**Status:** `OK` / **MINOR_WARN**

* MINOR_WARN: tolerant key lookups (`used_operator_norm` / `cap_total_hi`, etc.) are helpful for migration but could hide old schema usage if you want pure v2.1 strictness in ToolkitV2.
* MINOR_WARN: `Tstar` extraction assumes a specific zeros file layout; if that format ever changes, this script needs to be updated.

---

#### How to validate this module

1. **Single trial replay:**
   Pick a `(sigma, k0)` row from `param_search_results.csv`, re-run the full tool chain manually using the same arguments, and check the logged `lhs_total`, `epsilon_eff`, and `gap` match.

2. **Schema strictness check:**
   Temporarily modify the tolerant lookups to only accept v2.1 canonical keys and see if any trials fail—this will detect lingering legacy JSON formats.

3. **Zeros / Tstar sanity:**
   Verify that `Tstar` (Nth zero) matches what your main RH toolkit uses as the cutoff elsewhere.

---

#### Cross-AI validation prompt

> You are auditing `param_search.py`, which orchestrates a grid search over (sigma,k0), calling window_gen, bands_make, band_cert, prime_block_norm, prime_tail_envelope, core_integral_prover, and continuum_operator_rollup for each trial, then logging lhs_total, epsilon_eff, and gap to CSV. Confirm that the command sequence and key extractions are consistent with the v2.1 CLIs and JSON schemas of these tools, and suggest any ways to tighten schema checks without breaking the intended workflow.

---

#### JSON/CLI spec object

```json
{
  "module": "param_search.py",
  "tool_id": "param_search",
  "role": "orchestration",
  "cli": {
    "description": "Grid search over (sigma, k0) with per-trial RH certificates and CSV summary.",
    "args": [
      { "flag": "--zeros", "name": "zeros", "required": true, "type": "str", "default": null, "notes": "Path to zeros text file." },
      { "flag": "--N", "name": "N", "required": false, "type": "int", "default": 20000, "notes": "Number of zeros to use." },
      { "flag": "--sigma-min", "name": "sigma_min", "required": true, "type": "float", "default": null, "notes": "Minimum sigma." },
      { "flag": "--sigma-max", "name": "sigma_max", "required": true, "type": "float", "default": null, "notes": "Maximum sigma." },
      { "flag": "--sigma-step", "name": "sigma_step", "required": true, "type": "float", "default": null, "notes": "Sigma grid step." },
      { "flag": "--k0-min", "name": "k0_min", "required": true, "type": "float", "default": null, "notes": "Minimum k0." },
      { "flag": "--k0-max", "name": "k0_max", "required": true, "type": "float", "default": null, "notes": "Maximum k0." },
      { "flag": "--k0-step", "name": "k0_step", "required": true, "type": "float", "default": null, "notes": "k0 grid step." },
      { "flag": "--T0", "name": "T0", "required": false, "type": "str", "default": "1000000000", "notes": "Base T0 for prime tail envelope." },
      { "flag": "--dps", "name": "dps", "required": false, "type": "int", "default": 260, "notes": "Decimal precision passed through to tools." },
      { "flag": "--outdir", "name": "outdir", "required": false, "type": "str", "default": "PROOF_PACKET", "notes": "Output directory root." },
      { "flag": "--workers", "name": "workers", "required": false, "type": "int", "default": 1, "notes": "Reserved for future parallelization." }
    ]
  },
  "outputs": [
    {
      "filename": "param_search_results.csv",
      "primary": true,
      "kind": "param_search_results",
      "schema_version": "v2.1",
      "blocks": {
        "csv": {
          "fields": [
            { "path": "sigma", "type": "str" },
            { "path": "k0", "type": "str" },
            { "path": "lhs_total", "type": "str" },
            { "path": "epsilon_eff", "type": "str" },
            { "path": "gap", "type": "str" },
            { "path": "pass", "type": "bool" },
            { "path": "band_margin", "type": "str" },
            { "path": "prime_cap", "type": "str" },
            { "path": "prime_tail", "type": "str" },
            { "path": "gamma_tail", "type": "str" }
          ]
        }
      }
    }
  ]
}
```

## `param_cone_uniform_cert_v4c.py` 

**Role:** parameter-space cone search / local uniform certificate around a candidate ((\sigma_\text{mid}, k_{0,\text{mid}})).

---

#### CLI summary

Core (v2.1 canonical):

* `--sigma-mid` *(str, required)*
  Center (\sigma_\text{mid}).

* `--sigma-span` *(float, default `0.25`)*
  Total span in sigma; samples in ([\sigma_\text{mid}-\tfrac{\text{span}}{2},\ \sigma_\text{mid}+\tfrac{\text{span}}{2}]).

* `--sigma-steps` *(int, default `25`)*
  Number of sigma grid points.

* `--k0-mid` *(str, required)*
  Center (k_{0,\text{mid}}).

* `--k0-width` *(float, default `0.02`)*
  Half-width in (k_0); samples in ([k_{0,\text{mid}}-\text{width},\ k_{0,\text{mid}}+\text{width}]).

* `--k0-steps` *(int, default `25`)*
  Number of (k_0) grid points.

* `--lhs-total` *(str, required)*
  Fixed `lhs_total` value to beat; compared against `band_margin_lo`.

* `--grid` *(int, default `6000`)*
  Grid for `bands_make.py`.

* `--digits` *(int, default `120`)*
  Decimal digits for `bands_make.py` grid spec.

* `--dps` *(int, default `220`)*
  Precision passed to `band_cert.py`.

* `--critical-left`, `--critical-right` *(str, required)*
  Critical strip endpoints.

* `--inner-left`, `--inner-right` *(str, required)*
  Inner strip endpoints.

* `--jobs` *(int, default `os.cpu_count()-1`)*
  Number of worker threads/processes.

* `--executor` *{"thread","process"}, default `"process"`*
  Executor type.

* `--csv-dir` *(str, required)*
  Directory for `ok.csv` and `fail.csv` plus `cone/` work dir.

* `--out` *(str, required)*
  Output JSON path (`cone_uniform_cert` file).

* `--timeout-window` *(int, default `600`)*

* `--timeout-bands` *(int, default `1800`)*

* `--timeout-cert` *(int, default `3600`)*
  Timeouts for subprocess calls.

* `--fname-frac-digits` *(int, default `6`)*
  Digits in the `win_*.json` / `bands_*.json` filename tags.

* `--reuse` *(flag)*
  Reuse intermediate JSONs when up-to-date.

* `--stop-on-first` *(flag)*
  Stop sweep after first successful positive gap.

---

#### Outputs & JSON structure

**CSV outputs** (under `csv-dir`):

* `ok.csv`
  Header: `["sigma","k0","band_margin_lo","lhs_total","gap"]`.

* `fail.csv`
  Header: `["sigma","k0","stage","code","stderr_tail"]`.

**Main JSON** (`--out`):

```jsonc
{
  "kind": "cone_uniform_cert",
  "inputs": {
    "sigma_mid": "<string>",
    "k0_mid": "<string>",
    "sigma_span": "<string>",
    "k0_width": "<string>",
    "sigma_steps": 25,
    "k0_steps": 25,
    "lhs_total": "<string>"
  },
  "results": {
    "PASS": true,
    "points_evaluated": 625,
    "ok_points": 7,
    "min_gap": "<string>",
    "witness": {
      "sigma": "<string>",
      "k0": "<string>",
      "band_margin_lo": "<string>"
    },
    "stopped_early": false
  },
  "PASS": true,
  "meta": {
    "tool": "param_cone_uniform_cert_v4c",
    "dps": 220,
    "created_utc": "<ISO8601 UTC>",
    "sha256": "<digest>"
  }
}
```

* All real-valued scalars are stored as strings; counts and steps are integers.
* `PASS` at root equals `results.PASS`.

---

#### Dependencies & orchestration

For each sampled point ((\sigma, k_0)):

1. `window_gen.py`

   * `--mode gauss --sigma <sigma> --k0 <k0> --out win_<s_tag>_<k_tag>.json`

2. `bands_make.py`

   * `--window-config win_*.json`
   * `--grid <grid> --digits <digits>`
   * `--critical-left/--critical-right/--inner-left/--inner-right`
   * `--out bands_*.json`

3. `band_cert.py`

   * `--bands bands_*.json --window-config win_*.json --out band_cert_*.json --dps <dps>`

Then it parses `band_margin_lo` via tolerant paths and compares to `lhs_total`.

Worker behavior:

* Returns `{"ok": True, "sigma": "...", "k0": "...", "band_margin_lo": "..."}` on success.
* Returns `{"ok": False, ..., "stage": "...", "code": <int>, "stderr": "..."}` on failure.

Global logic:

* `gap = band_margin_lo - lhs_total`.
* Records successes when `gap > 0`.
* If any success:

  * `results.PASS = True`, `witness` = success with **smallest positive** gap.
* Otherwise:

  * `results.PASS = False`, only counts are set.

---

#### Math / validity

* This is a **parametric search**, not a math-heavy module:

  * It **assumes** `band_cert.py`’s `band_margin_lo` is a valid lower bound on your required inequality margin at that ((\sigma,k_0)).
  * The only “math” is `gap = band_margin_lo - lhs_total` and the interpretation “gap > 0 ⇒ good”.

**Status:** `OK` / **MINOR_WARN**

* MINOR_WARN: `read_band_margin_lo` uses multiple legacy paths; if you want v2.1 purity, you may eventually restrict to the canonical `band_cert.band_margin_lo` path once all old files are gone.

---

#### Validation tasks for this module

1. **Witness replay:**
   For the best witness `(sigma*, k0*)`, manually re-run the `window_gen + bands_make + band_cert` chain and confirm the same `band_margin_lo` is recovered.

2. **Schema strictness test:**
   Temporarily disable the legacy paths in `read_band_margin_lo` and verify that current v2.1 band_cert outputs still parse correctly.

3. **Timeout sanity:**
   Confirm that for your typical grid/dps, `timeout_*` values have generous safety margins and don’t silently cut off valid points.

---

#### Cross-AI validation prompt

> Audit `param_cone_uniform_cert_v4c.py`, which runs a cone-shaped local search in (sigma,k0), calling window_gen + bands_make + band_cert at each point and declaring PASS if any band_margin_lo > lhs_total. Check whether the search ordering (spiral from center) and stopping condition (first positive gap vs minimal positive gap) make sense, and whether the band_margin_lo parsing logic correctly enforces the v2.1 schema.

---

#### JSON/CLI spec object

```json
{
  "module": "param_cone_uniform_cert_v4c.py",
  "tool_id": "param_cone_uniform_cert_v4c",
  "role": "param_search",
  "cli": {
    "description": "Cone-shaped local search in (sigma, k0) around a candidate point, using band_cert margins.",
    "args": [
      { "flag": "--sigma-mid", "name": "sigma_mid", "required": true, "type": "str", "default": null, "notes": "Center sigma." },
      { "flag": "--sigma-span", "name": "sigma_span", "required": false, "type": "float", "default": 0.25, "notes": "Total span in sigma." },
      { "flag": "--sigma-steps", "name": "sigma_steps", "required": false, "type": "int", "default": 25, "notes": "Number of sigma grid points." },
      { "flag": "--k0-mid", "name": "k0_mid", "required": true, "type": "str", "default": null, "notes": "Center k0." },
      { "flag": "--k0-width", "name": "k0_width", "required": false, "type": "float", "default": 0.02, "notes": "Half-width in k0." },
      { "flag": "--k0-steps", "name": "k0_steps", "required": false, "type": "int", "default": 25, "notes": "Number of k0 grid points." },
      { "flag": "--lhs-total", "name": "lhs_total", "required": true, "type": "str", "default": null, "notes": "Fixed lhs_total value to beat." },
      { "flag": "--grid", "name": "grid", "required": false, "type": "int", "default": 6000, "notes": "bands_make grid." },
      { "flag": "--digits", "name": "digits", "required": false, "type": "int", "default": 120, "notes": "bands_make digits." },
      { "flag": "--dps", "name": "dps", "required": false, "type": "int", "default": 220, "notes": "band_cert precision." },
      { "flag": "--critical-left", "name": "critical_left", "required": true, "type": "str", "default": null, "notes": "Critical line left endpoint." },
      { "flag": "--critical-right", "name": "critical_right", "required": true, "type": "str", "default": null, "notes": "Critical line right endpoint." },
      { "flag": "--inner-left", "name": "inner_left", "required": true, "type": "str", "default": null, "notes": "Inner line left endpoint." },
      { "flag": "--inner-right", "name": "inner_right", "required": true, "type": "str", "default": null, "notes": "Inner line right endpoint." },
      { "flag": "--jobs", "name": "jobs", "required": false, "type": "int", "default": "max(1, os.cpu_count()-1)", "notes": "Number of workers." },
      { "flag": "--executor", "name": "executor", "required": false, "type": "str", "default": "process", "choices": ["thread","process"], "notes": "Executor type." },
      { "flag": "--csv-dir", "name": "csv_dir", "required": true, "type": "str", "default": null, "notes": "Directory for ok.csv/fail.csv." },
      { "flag": "--out", "name": "out", "required": true, "type": "str", "default": null, "notes": "Output JSON path." },
      { "flag": "--timeout-window", "name": "timeout_window", "required": false, "type": "int", "default": 600, "notes": "Timeout for window_gen." },
      { "flag": "--timeout-bands", "name": "timeout_bands", "required": false, "type": "int", "default": 1800, "notes": "Timeout for bands_make." },
      { "flag": "--timeout-cert", "name": "timeout_cert", "required": false, "type": "int", "default": 3600, "notes": "Timeout for band_cert." },
      { "flag": "--fname-frac-digits", "name": "fname_frac_digits", "required": false, "type": "int", "default": 6, "notes": "Digits in filename tags." },
      { "flag": "--reuse", "name": "reuse", "required": false, "type": "flag", "default": false, "notes": "Reuse up-to-date intermediates." },
      { "flag": "--stop-on-first", "name": "stop_on_first", "required": false, "type": "flag", "default": false, "notes": "Stop after first positive gap." }
    ]
  },
  "outputs": [
    {
      "filename": "cone_uniform_cert.json",
      "primary": true,
      "kind": "cone_uniform_cert",
      "schema_version": "v2.1",
      "blocks": {
        "inputs": { "fields": [
          { "path": "inputs.sigma_mid", "type": "str" },
          { "path": "inputs.k0_mid", "type": "str" },
          { "path": "inputs.sigma_span", "type": "str" },
          { "path": "inputs.k0_width", "type": "str" },
          { "path": "inputs.sigma_steps", "type": "int" },
          { "path": "inputs.k0_steps", "type": "int" },
          { "path": "inputs.lhs_total", "type": "str" }
        ]},
        "results": { "fields": [
          { "path": "results.PASS", "type": "bool" },
          { "path": "results.points_evaluated", "type": "int" },
          { "path": "results.ok_points", "type": "int" },
          { "path": "results.min_gap", "type": "str", "optional": true },
          { "path": "results.witness", "type": "object", "optional": true },
          { "path": "results.stopped_early", "type": "bool", "optional": true }
        ]},
        "root": { "fields": [
          { "path": "PASS", "type": "bool" }
        ]},
        "meta": { "fields": [
          { "path": "meta.tool", "type": "str" },
          { "path": "meta.dps", "type": "int" },
          { "path": "meta.created_utc", "type": "str" },
          { "path": "meta.sha256", "type": "str" }
        ]}
      }
    }
  ]
}
```

---

## `param_cover_cert.py` 

**Role:** parameter ε-net cover certificate using Lipschitz bound.

---

#### CLI summary

* `--domain` *(str, optional)*
  Format: `"a=[A0,A1] b=[B0,B1]"`. If present, overrides `--a-range/--b-range`.

* `--a-range A0 A1` *(pair of str, optional)*

* `--b-range B0 B1` *(pair of str, optional)*
  Explicit intervals if `--domain` not used.

* `--cellsA` / `--cellsB` *(int, default `24` each)*
  Number of cells in each direction (≥ 2). Stored as `cells_a`, `cells_b`.

* `--lipschitz` *(str, required)*
  JSON file containing Lipschitz bound. Reads:

  * Preferred: `q_lipschitz.L.hi`;
  * Fallback: `L.hi`.

* `--m-net-lo` *(str, required)*
  Certified minimal margin on the ε-net.

* `--out` *(str, required)*
  Output JSON.

* `--dps` *(int, default `300`)*
  Decimal precision for mpmath.

---

#### JSON structure

```jsonc
{
  "kind": "param_cover_cert",
  "inputs": {
    "a_range": ["A0", "A1"],
    "b_range": ["B0", "B1"],
    "cells_a": Na,
    "cells_b": Nb,
    "lipschitz_path": "<path>",
    "m_net_lo": "<string>"
  },
  "param_cover": {
    "domain": {
      "a": ["A0", "A1"],
      "b": ["B0", "B1"]
    },
    "grid": {
      "cellsA": Na,
      "cellsB": Nb,
      "da": "<string>",
      "db": "<string>"
    },
    "sensitivities": {
      "S_a_hi": "<string>",
      "S_b_hi": "<string>"
    },
    "epsilon": {
      "hi": "<string>"
    },
    "Lipschitz": {
      "hi": "<string>"
    },
    "m_net_lo": "<string>",
    "verified_margin": {
      "lo": "<string>",
      "hi": "<string>"
    },
    "PASS": true
  },
  "PASS": true,
  "meta": {
    "tool": "param_cover_cert",
    "dps": 300,
    "created_utc": "<ISO8601 UTC>",
    "sha256": "<digest>"
  }
}
```

All real-valued fields are strings; integers and booleans stay native.

---

#### Math / validity

Domain:

* Intervals:

  * (a \in [A_0, A_1]),
  * (b \in [B_0, B_1]).

* Grid:

  * (N_a = \max(2, \text{cellsA})),
  * (N_b = \max(2, \text{cellsB})),
  * Cell sizes:

    * (d a = \frac{A_1 - A_0}{N_a}), (d b = \frac{B_1 - B_0}{N_b}),
    * Half-widths (h_a = d a / 2), (h_b = d b / 2).

Sensitivities (unchanged from original):

* (I_0(c)), (I_2(c)), and (S_{\text{single}}(c)) as given, then

  [
  S_a(a,b) = S_{\text{single}}(a) + S_{\text{single}}(a+b),\quad
  S_b(a,b) = S_{\text{single}}(a+b).
  ]

* Conservative evaluation at corner ((a_1,b_1)):

  [
  S_{a,\text{hi}} = S_a(A_1,B_1),\quad S_{b,\text{hi}} = S_b(A_1,B_1).
  ]

ε radius:

[
\varepsilon_{\text{hi}} = S_{a,\text{hi}},h_a + S_{b,\text{hi}},h_b,
]

rounded outward with `outward_hi`.

Lipschitz:

* (L_{\text{hi}} = \text{read_L_hi}(lipschitz)), using `q_lipschitz.L.hi` or fallback `L.hi`.

Certified net margin:

* (m_{\text{net,lo}} =) input.

Verified gap:

[
\text{verified_gap} = m_{\text{net,lo}} - L_{\text{hi}} \varepsilon_{\text{hi}}.
]

* Stored as:

  * `verified_margin.lo` = exact `verified_gap`,
  * `verified_margin.hi` = `outward_hi(verified_gap)`.

PASS criterion:

* `PASS = (verified_gap > 0)` at both param_cover and root level.

**Status:** `OK` / **MINOR_WARN**

* The corner choice `(A1,B1)` is conservative given the underlying derivation; any change in the q-sensitivity model would need propagating here.
* Fallback `L.hi` path is maintained for compatibility; long-term you may want to enforce `q_lipschitz.L.hi` only.

---

#### Validation tasks

1. **Lipschitz JSON sanity:**
   Verify that current `lipschitz_q_bound.py` outputs `q_lipschitz.L.hi` and that no unexpected legacy `L.hi` usages remain in ToolkitV2.

2. **Grid resolution test:**
   Decrease / increase `cellsA` / `cellsB` and confirm that `verified_margin.lo` converges, and remains positive where you expect coverage.

3. **Sensitivity consistency:**
   Optionally re-derive or numerically verify that your `S_a` and `S_b` match the theoretical directional derivatives of `q(a,b)` at the corner.

---

#### Cross-AI validation prompt

> Audit `param_cover_cert.py`, which certifies a parameter ε-net cover using sensitivities S_a, S_b evaluated at the corner (A1,B1), a Lipschitz bound L_hi from JSON, and a net minimal margin m_net_lo. It defines eps_hi = S_a_hi*ha + S_b_hi*hb and verified_gap = m_net_lo - L_hi*eps_hi, passing if verified_gap > 0. Check whether using the corner (A1,B1) is appropriate for a worst-case sensitivity bound and whether the Lipschitz extraction logic (q_lipschitz.L.hi or L.hi) matches your current lipschitz module.

---

#### JSON/CLI spec object

```json
{
  "module": "param_cover_cert.py",
  "tool_id": "param_cover_cert",
  "role": "analytic_param_cover",
  "cli": {
    "description": "Parameter ε-net cover certificate using a Lipschitz bound.",
    "args": [
      { "flag": "--domain", "name": "domain", "required": false, "type": "str", "default": null, "notes": "Format: a=[A0,A1] b=[B0,B1]." },
      { "flag": "--a-range", "name": "a_range", "required": false, "type": "pair(str)", "default": null, "notes": "Alternative to --domain for a-interval." },
      { "flag": "--b-range", "name": "b_range", "required": false, "type": "pair(str)", "default": null, "notes": "Alternative to --domain for b-interval." },
      { "flag": "--cellsA", "name": "cells_a", "required": false, "type": "int", "default": 24, "notes": "Number of cells in a-direction (>=2)." },
      { "flag": "--cellsB", "name": "cells_b", "required": false, "type": "int", "default": 24, "notes": "Number of cells in b-direction (>=2)." },
      { "flag": "--lipschitz", "name": "lipschitz", "required": true, "type": "str", "default": null, "notes": "JSON file with q_lipschitz.L.hi (or legacy L.hi)." },
      { "flag": "--m-net-lo", "name": "m_net_lo", "required": true, "type": "str", "default": null, "notes": "Certified minimal margin on the ε-net." },
      { "flag": "--out", "name": "out", "required": true, "type": "str", "default": null, "notes": "Output JSON path." },
      { "flag": "--dps", "name": "dps", "required": false, "type": "int", "default": 300, "notes": "Decimal precision." }
    ]
  },
  "outputs": [
    {
      "filename": "param_cover_cert.json",
      "primary": true,
      "kind": "param_cover_cert",
      "schema_version": "v2.1",
      "blocks": {
        "inputs": { "fields": [
          { "path": "inputs.a_range", "type": "list[str,str]" },
          { "path": "inputs.b_range", "type": "list[str,str]" },
          { "path": "inputs.cells_a", "type": "int" },
          { "path": "inputs.cells_b", "type": "int" },
          { "path": "inputs.lipschitz_path", "type": "str" },
          { "path": "inputs.m_net_lo", "type": "str" }
        ]},
        "param_cover": { "fields": [
          { "path": "param_cover.domain.a", "type": "list[str,str]" },
          { "path": "param_cover.domain.b", "type": "list[str,str]" },
          { "path": "param_cover.grid.cellsA", "type": "int" },
          { "path": "param_cover.grid.cellsB", "type": "int" },
          { "path": "param_cover.grid.da", "type": "str" },
          { "path": "param_cover.grid.db", "type": "str" },
          { "path": "param_cover.sensitivities.S_a_hi", "type": "str" },
          { "path": "param_cover.sensitivities.S_b_hi", "type": "str" },
          { "path": "param_cover.epsilon.hi", "type": "str" },
          { "path": "param_cover.Lipschitz.hi", "type": "str" },
          { "path": "param_cover.m_net_lo", "type": "str" },
          { "path": "param_cover.verified_margin.lo", "type": "str" },
          { "path": "param_cover.verified_margin.hi", "type": "str" },
          { "path": "param_cover.PASS", "type": "bool" }
        ]},
        "root": { "fields": [
          { "path": "PASS", "type": "bool" }
        ]},
        "meta": { "fields": [
          { "path": "meta.tool", "type": "str" },
          { "path": "meta.dps", "type": "int" },
          { "path": "meta.created_utc", "type": "str" },
          { "path": "meta.sha256", "type": "str" }
        ]}
      }
    }
  ]
}
```

---

## `op_prime_tail_bound.py` 

**Role:** analytic constant for prime tail bound (operator-level tail).

---

#### CLI summary

* `--x0` *(str, default `"1e6"`)*
  Cutover (x_0) for explicit vs tail region.

* `--A-prime` *(str, default `"1.2762"`)*
  `A_prime`, prime-sum coefficient.

* `--K` *(int, default `3`)*
  Auxiliary index in the tail model.

* `--scale-by-log` *(flag)*
  If set, divides the tail constant by `log(x0)`.

* `--out` *(str, required)*
  Output JSON.

* `--dps` *(int, default `220`)*
  Precision for mpmath.

---

#### JSON structure

```jsonc
{
  "kind": "prime_tail_bound",
  "inputs": {
    "x0": "<string>",
    "A_prime": "<string>",
    "K": 3,
    "scale_by_log": false
  },
  "prime_tail_bound": {
    "C_tail_hi": "<string>",
    "model": "C_tail_hi = 2*(K+1)*A_prime [* 1/log(x0) if scale_by_log]."
  },
  "meta": {
    "tool": "op_prime_tail_bound",
    "dps": 220,
    "created_utc": "<ISO8601 UTC>",
    "sha256": "<digest>"
  }
}
```

All real-valued fields are strings; `K` is an integer; `scale_by_log` is boolean.

---

#### Math / validity

Core model (unchanged):

[
C_{\text{tail,hi}} = 2 (K + 1) A_{\text{prime}} \quad
\text{or} \quad \frac{2 (K+1) A_{\text{prime}}}{\log x_0} \text{ if scale-by-log.}
]

* Computed in high precision, then rounded upward via `outward_hi`.
* Stored as `prime_tail_bound.C_tail_hi`.

Interpretation:

* This is a **global constant** bounding the prime tail beyond `x0` in whatever operator inequality you are encoding (e.g., tail of prime sum in the explicit formula).
* `scale-by-log` option gives a slightly smaller constant when justified by an extra (1/\log(x_0)) factor in the model.

**Status:** `OK` (very simple, conservative).

---

#### Validation tasks

1. **Consistency with prime_tail_envelope:**
   Ensure that the `A_prime` and `K` used here match those in `prime_tail_envelope.py` and any other prime-tail-related modules, so all tails and envelopes are on the same model.

2. **Model justification:**
   Cross-check your theoretical derivation for the tail to confirm that either:

   * The bound truly is of the form `2*(K+1)*A_prime`, or
   * When using `scale-by-log`, the (1/\log x_0) factor is justified and not optimistic.

3. **Sensitivity in x0:**
   Evaluate `C_tail_hi` for several reasonable `x0` to see how aggressive the `scale-by-log` option is and whether your chosen `x0` is large enough.

---

#### Cross-AI validation prompt

> Audit `op_prime_tail_bound.py`, which defines a global tail constant C_tail_hi = 2*(K+1)*A_prime, optionally divided by log(x0) if --scale-by-log is used. Check whether this matches the theoretical tail bound used in your prime-sum estimates, and whether the 2*(K+1) factor and optional 1/log(x0) scaling are conservative for the ranges of x0 and K you care about.

---

#### JSON/CLI spec object

```json
{
  "module": "op_prime_tail_bound.py",
  "tool_id": "op_prime_tail_bound",
  "role": "tail_constant",
  "cli": {
    "description": "Analytic prime tail bound constant beyond x0.",
    "args": [
      { "flag": "--x0", "name": "x0", "required": false, "type": "str", "default": "1e6", "notes": "Cutover x0 for explicit vs tail." },
      { "flag": "--A-prime", "name": "A_prime", "required": false, "type": "str", "default": "1.2762", "notes": "Prime-sum coefficient A_prime." },
      { "flag": "--K", "name": "K", "required": false, "type": "int", "default": 3, "notes": "Auxiliary index K in tail model." },
      { "flag": "--scale-by-log", "name": "scale_by_log", "required": false, "type": "flag", "default": false, "notes": "If set, divide C_tail_hi by log(x0)." },
      { "flag": "--out", "name": "out", "required": true, "type": "str", "default": null, "notes": "Output JSON path." },
      { "flag": "--dps", "name": "dps", "required": false, "type": "int", "default": 220, "notes": "Decimal precision." }
    ]
  },
  "outputs": [
    {
      "filename": "prime_tail_bound.json",
      "primary": true,
      "kind": "prime_tail_bound",
      "schema_version": "v2.1",
      "blocks": {
        "inputs": { "fields": [
          { "path": "inputs.x0", "type": "str" },
          { "path": "inputs.A_prime", "type": "str" },
          { "path": "inputs.K", "type": "int" },
          { "path": "inputs.scale_by_log", "type": "bool" }
        ]},
        "prime_tail_bound": { "fields": [
          { "path": "prime_tail_bound.C_tail_hi", "type": "str" },
          { "path": "prime_tail_bound.model", "type": "str" }
        ]},
        "meta": { "fields": [
          { "path": "meta.tool", "type": "str" },
          { "path": "meta.dps", "type": "int" },
          { "path": "meta.created_utc", "type": "str" },
          { "path": "meta.sha256", "type": "str" }
        ]}
      }
    }
  ]
}
```

## `lipschitz_q_bound.py` 

**Role:** compute a global Lipschitz constant (L) for the quantity (q(\sigma,k_0)), decomposed into Gamma / Prime / Zeros contributions, for use in param-cover proofs.

---

#### CLI summary

* `--T0` *(str, required)*
  Lower bound on (t) for tails, (t \ge T_0).

* `--x0` *(str, required)*
  Cutover (x_0) for prime (\theta(x)) bound.

* `--A-prime` → `A_prime` *(str, default `"1.2762"`)*
  Dusart-style prime-theta constant.

* `--sigma-scale` *(str, default `"6.0"`)*
  Sigma scale used in the envelope model.

* `--k0-scale` *(str, default `"0.25"`)*
  (k_0) scale used in the prime-tail model.

* `--K` *(int, default `3`)*
  Auxiliary index (K) for the tail model.

* `--dps` *(int, default `300`)*
  Decimal precision for `mpmath`.

* `--out` *(str, required)*
  Output JSON path.

All CLI values are parsed as strings/ints and converted with `mp.mpf` as needed.

---

#### JSON structure

```jsonc
{
  "kind": "q_lipschitz_bound",
  "inputs": {
    "T0": "<string>",
    "x0": "<string>",
    "A_prime": "<string>",
    "sigma_scale": "<string>",
    "k0_scale": "<string>",
    "K": 3
  },
  "q_lipschitz": {
    "L": {
      "lo": "<string>",
      "hi": "<string>"
    },
    "decomp": {
      "Gamma": { "hi": "<string>" },
      "Prime": { "hi": "<string>" },
      "Zeros": { "hi": "<string>" }
    },
    "assumptions": {
      "gamma_tail": "...",
      "prime_theta": "...",
      "zeros_tail": "..."
    }
  },
  "meta": {
    "tool": "lipschitz_q_bound",
    "dps": 300,
    "created_utc": "<ISO8601 UTC>",
    "sha256": "<digest>"
  }
}
```

* All real-valued fields are strings (via `mp_str` / `outward`).
* `K` is an integer; assumptions are human-readable strings.

---

#### Math / validity

Core pieces:

* **Gamma part**: from `c_gamma(sigma)`:

  ```python
  c1 = 1 + 1/sigma
  c2 = 0.5 + 1/sigma**2
  Lg = c1/T0 + c2/T0**2
  ```

* **Prime part**:

  ```python
  A  = A_prime
  Kp = K + 1
  s  = sigma_scale
  k  = max(k0_scale, 1e-6)
  Cp = 2*Kp*A*(1 + 1/s)*(1 + 1/k)
  Lp = Cp * (log(T0)/T0)
  ```

* **Zeros part** (very crude but safe):

  ```python
  Lz = 1 / (1 + T0)**2
  ```

* **Total Lipschitz constant**:

  ```python
  L = Lg + Lp + Lz
  ```

Rounding and decomposition:

* `L.hi` = `outward(L, dps)` (rounded upward).
* `L.lo` = `outward(L * 0.9999999, dps)` (nominally slightly smaller, but still upward-rounded — so effectively “near L from below”).
* `Gamma.hi`, `Prime.hi`, `Zeros.hi` are each individually rounded upward for safety.

Assumption strings document the analytic input:

* Gamma tail bound on (|\psi(1/2+it)-\log t|).
* Dusart-style prime theta error with (A').
* A crude zeros-tail bound.

**Status:** `OK` / **MINOR_WARN**

* The “lo” entry is not a true downward-rounded bound (due to `outward`), but that’s harmless as long as you only *use* `L.hi` downstream.
* The zeros term `1/(1+T0)^2` is intentionally extremely crude; that’s fine if the goal is just a safe global bound.

---

#### How to validate this module

1. **Component sanity:**
   Numerically evaluate `Lg`, `Lp`, and `Lz` for your production `(T0, x0, A_prime, sigma_scale, k0_scale, K)` and confirm that:

   * `L.hi ≈ Lg + Lp + Lz` (up to outward rounding),
   * each component matches your analytic derivations.

2. **Dominance check:**
   For your actual `q(a,b)` variations, estimate finite-difference Lipschitz constants numerically at a few test points and confirm they are `< L.hi`.

3. **Assumption consistency:**
   Ensure the Dusart-style inequality and the gamma/zeros tails used here match the ones referenced elsewhere in the toolkit (and in your write-up).

---

#### Cross-AI validation prompt

> Audit `lipschitz_q_bound.py`. It defines L = L_gamma + L_prime + L_zeros, with L_gamma = (1+1/sigma)/T0 + (0.5+1/sigma^2)/T0^2, L_prime = C_prime * log(T0)/T0 where C_prime = 2*(K+1)*A_prime*(1+1/sigma)*(1+1/k0_scale), and L_zeros = 1/(1+T0)^2. It then outputs a Lipschitz bound L.hi and a decomposition into Gamma/Prime/Zeros pieces. Check that this is a conservative global Lipschitz bound for q in your setting, that the constants match your theoretical inequalities, and that the zeros piece is sufficiently safe for your T0 ranges.

---

#### JSON/CLI spec object

```json
{
  "module": "lipschitz_q_bound.py",
  "tool_id": "lipschitz_q_bound",
  "role": "lipschitz_bound",
  "cli": {
    "description": "Compute a global Lipschitz bound for q around (sigma, k0), decomposed into Gamma/Prime/Zeros.",
    "args": [
      { "flag": "--T0", "name": "T0", "required": true, "type": "str", "default": null, "notes": "Lower bound on t for tails (t >= T0)." },
      { "flag": "--x0", "name": "x0", "required": true, "type": "str", "default": null, "notes": "Cutover x0 for prime theta bound." },
      { "flag": "--A-prime", "name": "A_prime", "required": false, "type": "str", "default": "1.2762", "notes": "Dusart-style prime constant A'." },
      { "flag": "--sigma-scale", "name": "sigma_scale", "required": false, "type": "str", "default": "6.0", "notes": "Sigma scale used in envelope model." },
      { "flag": "--k0-scale", "name": "k0_scale", "required": false, "type": "str", "default": "0.25", "notes": "k0 scale used in prime tail model." },
      { "flag": "--K", "name": "K", "required": false, "type": "int", "default": 3, "notes": "Auxiliary index K." },
      { "flag": "--dps", "name": "dps", "required": false, "type": "int", "default": 300, "notes": "Decimal precision." },
      { "flag": "--out", "name": "out", "required": true, "type": "str", "default": null, "notes": "Output JSON path." }
    ]
  },
  "outputs": [
    {
      "filename": "q_lipschitz_bound.json",
      "primary": true,
      "kind": "q_lipschitz_bound",
      "schema_version": "v2.1",
      "blocks": {
        "inputs": { "fields": [
          { "path": "inputs.T0", "type": "str" },
          { "path": "inputs.x0", "type": "str" },
          { "path": "inputs.A_prime", "type": "str" },
          { "path": "inputs.sigma_scale", "type": "str" },
          { "path": "inputs.k0_scale", "type": "str" },
          { "path": "inputs.K", "type": "int" }
        ]},
        "q_lipschitz": { "fields": [
          { "path": "q_lipschitz.L.lo", "type": "str" },
          { "path": "q_lipschitz.L.hi", "type": "str" },
          { "path": "q_lipschitz.decomp.Gamma.hi", "type": "str" },
          { "path": "q_lipschitz.decomp.Prime.hi", "type": "str" },
          { "path": "q_lipschitz.decomp.Zeros.hi", "type": "str" }
        ]},
        "meta": { "fields": [
          { "path": "meta.tool", "type": "str" },
          { "path": "meta.dps", "type": "int" },
          { "path": "meta.created_utc", "type": "str" },
          { "path": "meta.sha256", "type": "str" }
        ]}
      }
    }
  ]
}
```

---

## `op_grid_error_bound.py` 

**Role:** conservative trapezoidal-rule–style grid/quadrature error bound for a continuum operator on ([a,b]).

---

#### CLI summary

* `--a` *(str, default `"0"`)*
  Left endpoint (a).

* `--b` *(str, default `"1"`)*
  Right endpoint (b).

* `--grid-points` *(int, default `6000`)*
  Number of grid points (M \ge 2) (so (N = M-1) intervals).

* `--M2-hi` *(str, default `"1e-3"`)*
  Upper bound on (\max_{x\in[a,b]} |f''(x)|).

* `--cap-hi` *(str, default `None`)*
  Optional hard cap; if provided and smaller than the computed bound, the bound is clamped down to `cap_hi`.

* `--dps` *(int, default `220`)*
  Decimal precision.

* `--out` *(str, required)*
  Output JSON path.

---

#### JSON structure

```jsonc
{
  "kind": "grid_error_bound",
  "inputs": {
    "a": "<string>",
    "b": "<string>",
    "grid_points": <int>,
    "M2_hi": "<string>",
    "cap_hi": "<string or null>"
  },
  "grid_error_bound": {
    "bound_hi": "<string>"
  },
  "meta": {
    "tool": "op_grid_error_bound",
    "dps": <int>,
    "created_utc": "<ISO8601 UTC>",
    "sha256": "<digest>"
  }
}
```

* Real values are strings via `mp_str`.
* `grid_points` is integer; `cap_hi` can be `null`.

---

#### Math / validity

Given:

* (a, b) with width (w = b-a),
* grid points (M \ge 2), intervals (N = M-1),
* bound (M_2^{\text{hi}} \ge \sup_{x\in[a,b]} |f''(x)|),

the trapezoidal error estimate is:

[
|E_{\text{trap}}| \le \frac{w,M_2^{\text{hi}}}{12 N^2}.
]

Implementation:

```python
N = grid_points - 1
width = b - a
bound = (width * M2_hi) / (12 * N**2)
bound = outward_hi(bound)   # conservative bump up
if cap_hi is not None and cap_hi < bound:
    bound = cap_hi
```

So:

* If you trust `M2_hi`, this is a standard rigorous trap-rule bound.
* The optional `cap_hi` lets you enforce a known external cap from elsewhere in the pipeline.

**Status:** `OK`

* The formula is standard; outward bump ensures no underestimation from rounding.

---

#### How to validate this module

1. **Compare with exact test functions:**
   Use test functions where the trap error is known or can be computed to high precision (e.g., sin, polynomials) to check that `bound_hi` always exceeds the actual error.

2. **Check N-dependence:**
   Verify numerically that `bound_hi` scales like (1/N^2) as expected when increasing `grid_points`.

3. **Cap sanity:**
   If you ever use `--cap-hi`, confirm that the chosen cap is ≥ the raw computed bound for the functions you care about, otherwise you’re knowingly tightening.

---

#### Cross-AI validation prompt

> Audit `op_grid_error_bound.py`, which computes a trapezoid-rule style grid error bound bound_hi = (b-a)*M2_hi/(12*(grid_points-1)^2), then optionally clamps it by a cap_hi override. Check that the error formula and outward rounding are correct, and that the cap logic cannot accidentally produce an under-estimate if cap_hi is chosen properly.

---

#### JSON/CLI spec object

```json
{
  "module": "op_grid_error_bound.py",
  "tool_id": "op_grid_error_bound",
  "role": "grid_error_bound",
  "cli": {
    "description": "Conservative grid/quadrature error bound for a continuum operator using a trap-rule estimate.",
    "args": [
      { "flag": "--a", "name": "a", "required": false, "type": "str", "default": "0", "notes": "Left endpoint of [a,b]." },
      { "flag": "--b", "name": "b", "required": false, "type": "str", "default": "1", "notes": "Right endpoint of [a,b]." },
      { "flag": "--grid-points", "name": "grid_points", "required": false, "type": "int", "default": 6000, "notes": "Number of grid points (>=2)." },
      { "flag": "--M2-hi", "name": "M2_hi", "required": false, "type": "str", "default": "1e-3", "notes": "Upper bound on |f''(x)| over [a,b]." },
      { "flag": "--cap-hi", "name": "cap_hi", "required": false, "type": "str", "default": null, "notes": "Optional hard cap override for the bound." },
      { "flag": "--dps", "name": "dps", "required": false, "type": "int", "default": 220, "notes": "Decimal precision." },
      { "flag": "--out", "name": "out", "required": true, "type": "str", "default": null, "notes": "Output JSON path." }
    ]
  },
  "outputs": [
    {
      "filename": "grid_error_bound.json",
      "primary": true,
      "kind": "grid_error_bound",
      "schema_version": "v2.1",
      "blocks": {
        "inputs": { "fields": [
          { "path": "inputs.a", "type": "str" },
          { "path": "inputs.b", "type": "str" },
          { "path": "inputs.grid_points", "type": "int" },
          { "path": "inputs.M2_hi", "type": "str" },
          { "path": "inputs.cap_hi", "type": "str or null" }
        ]},
        "grid_error_bound": { "fields": [
          { "path": "grid_error_bound.bound_hi", "type": "str" }
        ]},
        "meta": { "fields": [
          { "path": "meta.tool", "type": "str" },
          { "path": "meta.dps", "type": "int" },
          { "path": "meta.created_utc", "type": "str" },
          { "path": "meta.sha256", "type": "str" }
        ]}
      }
    }
  ]
}
```

---

## `frame_probe.py` 

**Role:** build an (L^2) Gram matrix for a finite Gaussian-notch frame over a real-line grid, compute eigenvalues, and summarize condition number and strict positivity.

---

#### CLI summary

* `--dict` *(choices `["gaussian"]`, default `"gaussian"`)*
  Dictionary type (currently only Gaussian notch frames).

* `--atoms` *(int, required)*
  Number of frame atoms.

* `--sigma-min`, `--sigma-max` *(str, required)*
  Range for sigma values.

* `--k0-min`, `--k0-max` *(str, required)*
  Range for (k_0) values.

* `--A` *(str, default `"50"`)*
  Half-width (A) of integration window ([-A, A]).

* `--mgrid` *(int, default `4097`)*
  Number of sample points on ([-A, A]).

* `--dps` *(int, default `120`)*
  Decimal precision.

* `--threads` *(int, default `1`)*
  Number of threads for Gram row computation.

* `--chunk` *(int, default `0`)*
  Reserved; currently unused.

* `--tol` *(str, default `None`)*
  Override tolerance for strict positivity; default derived from dps.

* `--out` *(str, required)*
  JSON summary path.

* `--csv` *(str, required)*
  CSV with eigenvalues.

---

#### JSON structure

```jsonc
{
  "kind": "frame_probe",
  "inputs": {
    "dict": "gaussian",
    "atoms": <int>,
    "sigma_min": "<string>",
    "sigma_max": "<string>",
    "k0_min": "<string>",
    "k0_max": "<string>",
    "A": "<string>",
    "mgrid": <int>,
    "dps": <int>,
    "threads": <int>,
    "tol": "<string>"
  },
  "results": {
    "min_eigenvalue": "<string>",
    "max_eigenvalue": "<string>",
    "condition_number": "<string>",
    "strictly_positive": true/false,
    "tolerance": "<string>"
  },
  "meta": {
    "tool": "frame_probe",
    "algo": "frame_probe/L2_gram",
    "dps": <int>,
    "created_utc": "<ISO8601 UTC>",
    "elapsed_sec": "<string>",
    "sha256": "<digest>"
  }
}
```

CSV (`--csv`):

```text
idx,eigenvalue
0,<e0>
1,<e1>
...
```

Each eigenvalue is printed with high precision (30 digits) via `nstr`.

---

#### Math / validity

Construction:

1. **Atoms:**
   `make_atoms_gaussian(n_atoms, sigma_min, sigma_max, k0_min, k0_max)`

   * Build a roughly square grid in ((\sigma, k_0)) with steps:

     [
     \sigma_i = \sigma_{\min} + (\sigma_{\max}-\sigma_{\min}) \frac{i}{\max(ns-1,1)},\quad
     k_{0,j} = k_{0,\min} + (k_{0,\max}-k_{0,\min}) \frac{j}{\max(nk-1,1)}.
     ]

   * Fill `Atom(sigma, k0)` list until `atoms == n_atoms`.

2. **Dictionary function:**

   ```python
   h(x) = e^{-(x/sigma)^2} * (1 - e^{-(x - k0)**2})
   ```

3. **Grid:**

   ```python
   xs = [-A + (2A*k)/(mgrid - 1) for k in range(mgrid)]
   ```

4. **Inner products (L2):**

   For atoms (a_i, a_j):

   * Evaluate `h_i(x_k) * h_j(x_k)` at grid points.

   * Use Kahan summation for stability.

   * Apply trapezoidal rule tweak:

     ```python
     s = kahan_sum(vals) - (vals[0] + vals[-1]) / 2
     step = (2*A)/(mgrid - 1)
     G_ij = step * s
     ```

   * This is equivalent to a symmetric trapezoidal rule on ([-A,A]).

5. **Gram matrix:**

   * Fill symmetric `G` with rows either serially or via `ThreadPoolExecutor`.

6. **Spectrum:**

   ```python
   evals, _ = mp.eig(G)
   evals_real = sorted(real_parts(evals))  # ensures small imaginary parts are discarded within tol
   A_theta = evals_real[0]
   B_theta = evals_real[-1]
   cond = B_theta / A_theta if A_theta != 0 else inf
   strictly_positive = A_theta > tol
   ```

   * Imag parts are rejected if larger than a very small tolerance (`tol_from_dps(dps, 8)`); otherwise real part is used.

**Status:** `OK` / **MATH-HEAVY BUT LOCAL**

* This is purely numerical / diagnostic; it doesn’t feed directly into the RH inequality chain in ToolkitV2, but validates frame conditioning and positivity of the Gram operator for your Gaussian-notch family.

---

#### How to validate this module

1. **Self-consistency:**

   * For small `atoms` and relatively coarse `mgrid`, cross-check the Gram matrix against a higher-precision or higher-`mgrid` run to ensure eigenvalues stabilize.

2. **Symmetry & PSD checks:**

   * Confirm numerically that `G` is symmetric within numerical tolerance and that all eigenvalues are nonnegative (up to small rounding noise).

3. **Tolerance choice:**

   * Make sure the default `tol_from_dps(dps, 6)` is appropriate: small enough not to misclassify a genuinely positive smallest eigenvalue as zero, but large enough to ignore tiny numerical negative noise.

---

#### Cross-AI validation prompt

> Audit `frame_probe.py`, which builds an L2 Gram matrix of Gaussian-notch atoms on a real grid via a trapezoidal rule with Kahan summation, then computes eigenvalues and condition number to decide strict positivity of the frame. Check that the quadrature scheme, atom construction, eigenvalue post-processing, and strictly_positive test are numerically robust and consistent with the intended frame-theoretic model.

---

#### JSON/CLI spec object

```json
{
  "module": "frame_probe.py",
  "tool_id": "frame_probe",
  "role": "diagnostic_frame_probe",
  "cli": {
    "description": "Probe eigenvalues/condition number of a Gaussian-notch frame via an L2 Gram matrix.",
    "args": [
      { "flag": "--dict", "name": "dict", "required": false, "type": "str", "default": "gaussian", "choices": ["gaussian"], "notes": "Dictionary type (gaussian only)." },
      { "flag": "--atoms", "name": "atoms", "required": true, "type": "int", "default": null, "notes": "Number of frame atoms." },
      { "flag": "--sigma-min", "name": "sigma_min", "required": true, "type": "str", "default": null, "notes": "Minimum sigma." },
      { "flag": "--sigma-max", "name": "sigma_max", "required": true, "type": "str", "default": null, "notes": "Maximum sigma." },
      { "flag": "--k0-min", "name": "k0_min", "required": true, "type": "str", "default": null, "notes": "Minimum k0." },
      { "flag": "--k0-max", "name": "k0_max", "required": true, "type": "str", "default": null, "notes": "Maximum k0." },
      { "flag": "--A", "name": "A", "required": false, "type": "str", "default": "50", "notes": "Half-width of integration window [-A, A]." },
      { "flag": "--mgrid", "name": "mgrid", "required": false, "type": "int", "default": 4097, "notes": "Number of grid points on [-A, A]." },
      { "flag": "--dps", "name": "dps", "required": false, "type": "int", "default": 120, "notes": "Decimal precision for mpmath." },
      { "flag": "--threads", "name": "threads", "required": false, "type": "int", "default": 1, "notes": "Number of threads for row-building." },
      { "flag": "--chunk", "name": "chunk", "required": false, "type": "int", "default": 0, "notes": "Reserved/unused." },
      { "flag": "--tol", "name": "tol", "required": false, "type": "str", "default": null, "notes": "Override tolerance for strictly_positive." },
      { "flag": "--out", "name": "out", "required": true, "type": "str", "default": null, "notes": "JSON summary path." },
      { "flag": "--csv", "name": "csv", "required": true, "type": "str", "default": null, "notes": "CSV path for eigenvalues." }
    ]
  },
  "outputs": [
    {
      "filename": "frame_probe.json",
      "primary": true,
      "kind": "frame_probe",
      "schema_version": "v2.1",
      "blocks": {
        "inputs": { "fields": [
          { "path": "inputs.dict", "type": "str" },
          { "path": "inputs.atoms", "type": "int" },
          { "path": "inputs.sigma_min", "type": "str" },
          { "path": "inputs.sigma_max", "type": "str" },
          { "path": "inputs.k0_min", "type": "str" },
          { "path": "inputs.k0_max", "type": "str" },
          { "path": "inputs.A", "type": "str" },
          { "path": "inputs.mgrid", "type": "int" },
          { "path": "inputs.dps", "type": "int" },
          { "path": "inputs.threads", "type": "int" },
          { "path": "inputs.tol", "type": "str" }
        ]},
        "results": { "fields": [
          { "path": "results.min_eigenvalue", "type": "str" },
          { "path": "results.max_eigenvalue", "type": "str" },
          { "path": "results.condition_number", "type": "str" },
          { "path": "results.strictly_positive", "type": "bool" },
          { "path": "results.tolerance", "type": "str" }
        ]},
        "meta": { "fields": [
          { "path": "meta.tool", "type": "str" },
          { "path": "meta.algo", "type": "str" },
          { "path": "meta.dps", "type": "int" },
          { "path": "meta.created_utc", "type": "str" },
          { "path": "meta.elapsed_sec", "type": "str" },
          { "path": "meta.sha256", "type": "str" }
        ]}
      }
    }
  ]
}
```

Here’s the next batch, in the same spec style as before.

---

## `explicit_formula.py` 

**Role:**
Weil explicit formula rollup. Combines the certified band margin, tail envelopes, and (optionally) continuum operator rollup into a single inequality datum `epsilon_eff_lo`, currently chosen to **equal** the band margin lower bound. Continuum epsilon is recorded only for audit/debug.

---

#### CLI summary

* `--band-cert` *(str, required)*
  Path to `band_cert.json`.

* `--weil-psd` *(str, required)*
  Path to Weil PSD certificate JSON (e.g. `weil_psd_bochner.json`).

* `--tails` *(str, required)*
  Path to tails JSON (gamma + prime envelopes at (T_0)).

* `--continuum-cert` *(str, optional)*
  Path to `continuum_operator_rollup.json`. If omitted, continuum data is treated as zero and only logged in `meta`.

* `--dps` *(int, default `200`)*
  `mpmath.dps` precision.

* `--out` *(str, required)*
  Output JSON path.

---

#### JSON structure

On success:

```jsonc
{
  "kind": "weil_explicit",
  "inputs": {
    "band_cert_path": "<path>",
    "weil_psd_path": "<path>",
    "tails_path": "<path>",
    "continuum_cert_path": "<path or empty>",
    "dps": "<dps as string>"
  },
  "explicit_formula": {
    "band_margin_lo": "<string>",
    "gamma_env_at_T0": "<string>",
    "prime_env_at_T0": "<string>",
    "epsilon_eff_lo": "<string>"
  },
  "PASS": true,
  "meta": {
    "tool": "explicit_formula",
    "dps": "<string>",
    "created_utc": "<ISO8601Z>",
    "continuum_epsilon_eff": "<string>"
  }
}
```

On error, it writes a stub:

* `band_margin_lo = "0"`, `gamma_env_at_T0 = "0"`, `prime_env_at_T0 = "0"`, `epsilon_eff_lo = "0"`.
* `PASS = False`.
* `meta.error` includes the exception message.

All reals are normalized through `mpf_str` -> decimal strings.

---

#### Data extraction logic

* **Band margin:** via `read_band_margin(band_json)` which tries, in order:

  * `["band_cert","band_margin","lo"]`
  * `["band_cert","band_margin_lo"]`
  * `["numbers","band_margin"]`
  * `["band_margin","lo"]`
  * `["band_margin_lo"]`

* **Continuum epsilon_eff:** via `read_eps_eff(cont)` from:

  * `["numbers","eps_eff"]`
  * `["numbers","epsilon_eff"]`
  * `["eps_eff"]`
  * `["epsilon_eff"]`

* **Tails:** via `read_tails_env(tails_json)`:

  * Gamma: looks for `gamma_env_at_T0`, or nested under `tails`, or inside `gamma_tail` (including `tails_total` as a fallback).
  * Prime: looks for `prime_env_at_T0`, or nested under `tails`, or `prime_tail_envelope.env_T0_hi`, or `prime_tail.numbers.prime_tail_norm`, etc.

* **PSD status:** via `read_psd_pass(weil_json)`:

  * Checks `bochner_psd.PSD_verified`, `weil_psd.PSD_verified`, or top-level `PSD_verified`.
  * Accepts bool or `"true"/"false"` string.
  * Defaults to `True` if not clearly present (for summary runs).

All extracted values are passed through `mpf_str`, so you never leak floats or `None`.

---

#### Math / logic

* **Core inequality:**

  ```python
  band_margin = mpf_str(band_margin_raw)
  gamma_env   = mpf_str(gamma_raw)
  prime_env   = mpf_str(prime_raw)
  continuum_eps_eff = mpf_str(eps_eff_raw)
  epsilon_eff_lo = band_margin
  ```

* `PASS` is:

  ```python
  PASS = bool(psd_ok and band_margin not in ("0", "0.0"))
  ```

  i.e., explicit formula “passes” if:

  1. The Weil PSD certificate says the kernel is PSD (`psd_ok`), and
  2. The band margin is nonzero (acts as a sanity gate).

* `gamma_env_at_T0` and `prime_env_at_T0` are **logged but not combined** into `epsilon_eff_lo` in this module. The combination vs tails happens upstream/downstream in your conceptual proof; this file acts as the “Weil explicit formula data collector” rather than the final inequality comparator.

**Status:** `OK / MINOR_WARN`

* MINOR_WARN: `read_*` functions still carry legacy schema fallback paths. Once ToolkitV2 JSON is fully canonical, you could safely prune these.

---

#### Validation tasks

1. **Band + tails echo test:**

   * For a known run, manually inspect `band_cert.json`, `tails.json`, and `continuum_operator_rollup.json` and confirm that:

     * `explicit_formula.band_margin_lo` matches the canonical lower margin in `band_cert.json`.
     * `gamma_env_at_T0` and `prime_env_at_T0` match the tails file values.
     * `meta.continuum_epsilon_eff` matches the continuum rollup’s epsilon field.

2. **PSD gate:**

   * Flip `PSD_verified` to `false` in a test Weil PSD file and confirm `PASS` goes to `False` even when band_margin is positive.

3. **Schema lock-down:**

   * Once you finalize canonical paths:

     * Temporarily remove some legacy fallback paths and ensure all current JSON from ToolkitV2 still parse.

---

#### Cross-AI validation prompt

> Audit `explicit_formula.py`, which reads band_cert.json, a Weil PSD certificate, and a tails JSON, then sets epsilon_eff_lo := band_margin_lo and PASS := (PSD_verified && band_margin_lo != 0). Tails and continuum epsilon are recorded for audit only. Check whether epsilon_eff_lo should remain equal to the band margin in ToolkitV2, or whether a more explicit combination with gamma/prime tails and continuum epsilon should be encoded here instead of in a separate rollup module.

---

#### JSON/CLI spec object

```json
{
  "module": "explicit_formula.py",
  "tool_id": "explicit_formula",
  "role": "explicit_formula_rollup",
  "cli": {
    "description": "Weil explicit formula rollup: collect band margin, tails, and PSD status into epsilon_eff_lo.",
    "args": [
      { "flag": "--band-cert",      "name": "band_cert",      "required": true,  "type": "str", "default": null,  "notes": "Path to band_cert.json." },
      { "flag": "--weil-psd",       "name": "weil_psd",       "required": true,  "type": "str", "default": null,  "notes": "Path to Weil PSD certificate JSON." },
      { "flag": "--tails",          "name": "tails",          "required": true,  "type": "str", "default": null,  "notes": "Path to tails JSON (gamma + prime envelopes at T0)." },
      { "flag": "--continuum-cert", "name": "continuum_cert", "required": false, "type": "str", "default": null,  "notes": "Optional continuum_operator_rollup.json." },
      { "flag": "--dps",            "name": "dps",            "required": false, "type": "int", "default": 200,   "notes": "Decimal precision for mpmath." },
      { "flag": "--out",            "name": "out",            "required": true,  "type": "str", "default": null,  "notes": "Output JSON path." }
    ]
  },
  "outputs": [
    {
      "filename": "explicit_formula.json",
      "primary": true,
      "kind": "weil_explicit",
      "schema_version": "v2.1",
      "blocks": {
        "inputs": {
          "fields": [
            { "path": "inputs.band_cert_path",       "type": "str" },
            { "path": "inputs.weil_psd_path",        "type": "str" },
            { "path": "inputs.tails_path",           "type": "str" },
            { "path": "inputs.continuum_cert_path",  "type": "str" },
            { "path": "inputs.dps",                  "type": "str" }
          ]
        },
        "explicit_formula": {
          "fields": [
            { "path": "explicit_formula.band_margin_lo",  "type": "str" },
            { "path": "explicit_formula.gamma_env_at_T0", "type": "str" },
            { "path": "explicit_formula.prime_env_at_T0", "type": "str" },
            { "path": "explicit_formula.epsilon_eff_lo",  "type": "str" }
          ]
        },
        "root": {
          "fields": [
            { "path": "PASS", "type": "bool" }
          ]
        },
        "meta": {
          "fields": [
            { "path": "meta.tool",                 "type": "str" },
            { "path": "meta.dps",                  "type": "str" },
            { "path": "meta.created_utc",          "type": "str" },
            { "path": "meta.continuum_epsilon_eff","type": "str" },
            { "path": "meta.error",                "type": "str", "optional": true }
          ]
        }
      }
    }
  ]
}
```

---

## `fourier_inversion_cert.py` 

**Role:**
Closed-form Fourier inversion certificate for the Gaussian-notch kernel. Computes parameters for
( h(x) = A_1 e^{-a_1 x^2} - A_2 e^{-a_2 x^2} ), then outputs (h(0)), (\epsilon_\text{eff}), and several norms/bounds (L¹ norm of (h''), sup norms) used by deconvolution / operator tools.

---

#### CLI summary

* `--window-config` *(str, optional)*
  Window JSON from `window_gen.py`. Mutually exclusive with `--sigma/--k0`.

* `--sigma` *(str, optional)*
  Gaussian width; required if not using `--window-config`.

* `--k0` *(str, optional)*
  Notch parameter; required if not using `--window-config`.

* `--out` *(str, required)*
  Output JSON.

* `--dps` *(int, default `220`)*
  Precision for `mpmath`.

* `--xmax` *(str, default `"6.0"`)*
  Half-width for numeric sup probe when `--probe` is used.

* `--simpson-n` *(int, default `0`)*
  Retained for compatibility; not used in closed-form mode. Logged in JSON.

* `--probe` *(flag)*
  If set, numerically probes `sup_x |h(x)|` on `[-xmax, xmax]` and takes `max(triangle_bound, probe)`.

Exactly one input mode:

* Window mode: `--window-config` only.
* Raw parameter mode: `--sigma` and `--k0` only.

---

#### Window resolution & closed form

`read_window(args)`:

* If `--window-config`:

  * `js = jload(window_config)`
  * `window = js.get("window", js)`
  * `sigma = window["sigma"]`, `k0 = window["k0"]`, `window_mode = window.get("mode", js.get("mode","gauss"))`.

* Else raw params:

  * `sigma = mp.mpf(args.sigma)`, `k0 = mp.mpf(args.k0)`, `window_mode = "gauss"`.

If `window_mode != "gauss"`, it warns but still uses Gaussian formulas.

Closed-form mapping (Gaussian notch → difference of Gaussians):

```python
alpha1 = 1 / (sigma*sigma)
alpha2 = 1 / (sigma*sigma) + 1 / (k0*k0)

A1 = sigma
a1 = (mp.pi * sigma) ** 2

A2 = 1 / mp.sqrt(alpha2)
a2 = (mp.pi ** 2) / alpha2

h(x) = A1 * exp(-a1 x^2) - A2 * exp(-a2 x^2)
```

`h(0) = A1 - A2` and:

```python
epsilon_eff = 0.5 * h0
```

---

#### Bounds and probes

* **L¹ norm of second derivative:**

  * For (g(x) = e^{-a x^2}), second derivative:

    [
    g''(x) = (4 a^2 x^2 - 2 a) e^{-a x^2}.
    ]

  * `L1_gpp_of_gaussian(a)` integrates (|g''(x)|) exactly using a split at (x_0 = 1/\sqrt{2a}) and closed-form expressions:

    * `I0(u)`, `I2(u)` for (\int e^{-ax^2}) and (\int x^2 e^{-ax^2}).
    * Two regions [0, x0] and [x0, ∞); then doubled for evenness.

  * For (h = A_1 g_{a1} - A_2 g_{a2}):

    ```python
    L1_h2_hi = |A1| * L1_gpp_of_gaussian(a1) + |A2| * L1_gpp_of_gaussian(a2)
    ```

* **Sup bounds (triangle):**

  * For (g(x)), (\sup_x |g''(x)| = 2a) at (x = 0).
  * Crude but safe bounds:

    ```python
    sup_h_hi_triangle  = |A1| + |A2|
    sup_hpp_hi_triangle = 2*|A1|*a1 + 2*|A2|*a2
    ```

* **Numeric sup probe (`--probe`):**

  * Samples `points=2049` uniformly on `[-xmax, xmax]`.

    ```python
    sup_h_probe, where_h = sup_probe_h(...)
    sup_h = max(sup_h_tri, sup_h_probe)
    where_h2 = 0
    ```

  * Without `--probe`, uses triangle bounds only:

    ```python
    sup_h = sup_h_tri
    where_h = 0
    where_h2 = 0
    ```

---

#### JSON structure

```jsonc
{
  "kind": "fourier_inversion_cert",
  "inputs": {
    "mode": "window" | "raw_params",
    "sigma": "<string>",
    "k0": "<string>",
    "window_config_path": "<path>" // present only in window mode
  },
  "closed_form_h": {
    "A1": "<string>",
    "a1": "<string>",
    "A2": "<string>",
    "a2": "<string>",
    "h0": "<string>",
    "epsilon_eff": "<string>"
  },
  "bounds": {
    "L1_h2_hi": "<string>",
    "sup_h_hi": "<string>",
    "sup_h2_hi": "<string>",
    "where_sup_h": "<string>",
    "where_sup_h2": "<string>",
    "xmax_used": "<string>",
    "simpson_n": 0
  },
  "meta": {
    "tool": "fourier_inversion_cert",
    "dps": "<string>",
    "created_utc": "<ISO8601Z>",
    "fourier_convention": "F1: f^(xi)=∫ f(x) e^{-2π i x xi} dx; inverse uses +2π"
  }
}
```

All reals are serialized with `str()` on `mp.mpf` objects.

**Status:** `OK`

* The math is self-contained and consistent with your earlier closed-form design.

---

#### Validation tasks

1. **Closed-form vs numeric:**

   * For a few ((\sigma,k_0)), numerically integrate the inverse Fourier transform using high-precision quadrature and compare `h(0)` and sample values to the closed form used here.

2. **L¹(g'') sanity:**

   * For a test `a`, evaluate `L1_gpp_of_gaussian(a)` numerically via `mp.quad` and compare to the closed form to confirm agreement at your chosen `dps`.

3. **Sup bounds vs probe:**

   * Run with and without `--probe` and confirm `sup_h_hi` always upper-bounds the numerical `sup`.

---

#### Cross-AI validation prompt

> Audit `fourier_inversion_cert.py`, which maps the Gaussian-notch window to h(x) = A1 exp(-a1 x^2) - A2 exp(-a2 x^2), then computes epsilon_eff = 0.5*(A1 - A2), an exact L1 norm of h'' via Gaussian identities, and triangle/probe bounds for sup|h| and sup|h''|. Check the derivation of A1, a1, A2, a2, the correctness of the L1(g'') closed form, and whether epsilon_eff = h(0)/2 matches the way this kernel is used in your deconvolution operator.

---

#### JSON/CLI spec object

```json
{
  "module": "fourier_inversion_cert.py",
  "tool_id": "fourier_inversion_cert",
  "role": "fourier_inversion_cert",
  "cli": {
    "description": "Closed-form Fourier inversion certificate for the Gaussian-notch kernel.",
    "args": [
      { "flag": "--window-config", "name": "window_config", "required": false, "type": "str", "default": null,  "notes": "Path to window JSON (from window_gen.py)." },
      { "flag": "--sigma",         "name": "sigma",         "required": false, "type": "str", "default": null,  "notes": "Gaussian width when not using --window-config." },
      { "flag": "--k0",            "name": "k0",            "required": false, "type": "str", "default": null,  "notes": "Notch parameter when not using --window-config." },
      { "flag": "--out",           "name": "out",           "required": true,  "type": "str", "default": null,  "notes": "Output JSON path." },
      { "flag": "--dps",           "name": "dps",           "required": false, "type": "int", "default": 220,   "notes": "Decimal precision for mpmath." },
      { "flag": "--xmax",          "name": "xmax",          "required": false, "type": "str", "default": "6.0", "notes": "Half-width for sup probe (when --probe is set)." },
      { "flag": "--simpson-n",     "name": "simpson_n",     "required": false, "type": "int", "default": 0,     "notes": "Unused compatibility parameter (logged only)." },
      { "flag": "--probe",         "name": "probe",         "required": false, "type": "flag","default": false, "notes": "Enable numeric sup|h| probe on [-xmax, xmax]." }
    ]
  },
  "outputs": [
    {
      "filename": "fourier_inversion_cert.json",
      "primary": true,
      "kind": "fourier_inversion_cert",
      "schema_version": "v2.1",
      "blocks": {
        "inputs": {
          "fields": [
            { "path": "inputs.mode",               "type": "str" },
            { "path": "inputs.sigma",             "type": "str" },
            { "path": "inputs.k0",                "type": "str" },
            { "path": "inputs.window_config_path","type": "str", "optional": true }
          ]
        },
        "closed_form_h": {
          "fields": [
            { "path": "closed_form_h.A1",          "type": "str" },
            { "path": "closed_form_h.a1",          "type": "str" },
            { "path": "closed_form_h.A2",          "type": "str" },
            { "path": "closed_form_h.a2",          "type": "str" },
            { "path": "closed_form_h.h0",          "type": "str" },
            { "path": "closed_form_h.epsilon_eff", "type": "str" }
          ]
        },
        "bounds": {
          "fields": [
            { "path": "bounds.L1_h2_hi",   "type": "str" },
            { "path": "bounds.sup_h_hi",   "type": "str" },
            { "path": "bounds.sup_h2_hi",  "type": "str" },
            { "path": "bounds.where_sup_h","type": "str" },
            { "path": "bounds.where_sup_h2","type": "str" },
            { "path": "bounds.xmax_used",  "type": "str" },
            { "path": "bounds.simpson_n",  "type": "int" }
          ]
        },
        "meta": {
          "fields": [
            { "path": "meta.tool",               "type": "str" },
            { "path": "meta.dps",                "type": "str" },
            { "path": "meta.created_utc",        "type": "str" },
            { "path": "meta.fourier_convention", "type": "str" }
          ]
        }
      }
    }
  ]
}
```

---

## `density_prover.py` 

**Role:**
Compute (L^2) sensitivity norms (S_a, S_b) of the Fourier-side kernel with respect to density parameters (a, b). These are used as Lipschitz-style constants in density-control arguments.

---

#### CLI summary

* `--a-center` *(str, required)*
  Center value of parameter (a) (high-precision string).

* `--b-center` *(str, required)*
  Center value of parameter (b) (high-precision string).

* `--dps` *(int, default `300`)*
  `mpmath.dps`. Internally, code uses `dps + 10` for integration stability.

* `--out` *(str, required)*
  Primary JSON output path.

* `--theory-out` *(str, optional)*
  Auxiliary JSON with human-readable lemma and constants.

---

#### Math / algorithm

Let:

* (A = a), (B = a + b), and `Amax = max(a, B)`.

Derivative kernels (Fourier side):

```python
def _d_da_hat(t, a, b):
    def dA(A):
        E = exp(-pi * t**2 / A)
        return (-0.5 * A**(-1.5) + pi * t**2 * A**(-2.5)) * E
    return dA(a) - dA(a + b)

def _d_db_hat(t, a, b):
    A = a + b
    E = exp(-pi * t**2 / A)
    return -( -0.5 * A**(-1.5) + pi * t**2 * A**(-2.5) ) * E
```

Core integration cutoff (T):

```python
target = 10^{-(dps+5)}
T = sqrt( (Amax / (2*pi)) * log(1/target) )
```

* This ensures the Gaussian tail beyond (|t| > T) is negligible at the requested precision.

L² norms:

1. **Core integral** on ([-T, T]):

   ```python
   Sa_sq_core = ∫_{-T}^T |∂_a \hat{h}(t)|² dt
   Sb_sq_core = ∫_{-T}^T |∂_b \hat{h}(t)|² dt
   ```

   Implemented via `mp.quad`, with `maxn=100000`.

2. **Gaussian tail cap:**

   ```python
   valT  = |deriv_fn(T, a, b)|^2
   tail_env = (Amax / (4*pi*T)) * exp(-2*pi*T^2 / Amax)
   tail_cap = valT * 2 * tail_env
   ```

   Then:

   ```python
   Sa = sqrt(Sa_sq_core + Sa_tail)
   Sb = sqrt(Sb_sq_core + Sb_tail)
   ```

3. **Outward rounding to strings:**

   `_outward_str(x, dps, ulps=2)`:

   * Temporarily sets `mp.dps = dps+5`.
   * Adds `ulps * 10^{-dps}` to `x` to push outward.
   * Returns `mp.nstr(x, n=dps)`.

   This guarantees `S_a_hi`, `S_b_hi` are conservative upper bounds.

---

#### JSON structure

```jsonc
{
  "kind": "density_prover",
  "inputs": {
    "a_center": "<string>",
    "b_center": "<string>",
    "dps": "<string>"
  },
  "density_prover": {
    "T_core": "<string>",
    "S_a_hi": "<string>",
    "S_a_units": "L2",
    "S_b_hi": "<string>",
    "S_b_units": "L2",
    "PASS": true
  },
  "meta": {
    "tool": "density_prover",
    "dps": "<string>",
    "created_utc": "<ISO8601Z>",
    "sha256": "<string>"
  }
}
```

* Write pattern:

  1. `_write_json(out, payload)` → returns `sha256`.
  2. Set `payload["meta"]["sha256"] = h`.
  3. `_write_json(out, payload)` again.

Optional **theory JSON** (`--theory-out`):

```jsonc
{
  "lemma": "DensitySensitivityL2",
  "statement": "L2 norms of ∂_a ĥ and ∂_b ĥ are bounded by S_a_hi, S_b_hi using the core integral on [-T_core, T_core] plus a Gaussian tail cap.",
  "constants": {
    "S_a_hi": "<string>",
    "S_b_hi": "<string>",
    "T_core": "<string>"
  },
  "proven_by": {
    "tool": "density_prover",
    "dps": "<string>",
    "created_utc": "<ISO8601Z>"
  }
}
```

**Status:** `OK`

* Math is internally consistent and outward-rounded for safety.

---

#### Validation tasks

1. **Convergence test:**

   * For a chosen `(a_center, b_center)`, increase `dps` and verify that `S_a_hi`, `S_b_hi` stabilize to within the outward bump (a couple of ulps at the chosen precision).

2. **Tail dominance check:**

   * Inspect `Sa_tail` / `Sa_sq_core` and `Sb_tail` / `Sb_sq_core` for typical parameters to ensure the tail caps are genuinely small and not dominating the bound unexpectedly.

3. **Derivative correctness:**

   * Independently differentiate the closed-form Fourier kernel in a CAS (or another AI) to confirm the analytic forms of `_d_da_hat` and `_d_db_hat`.

---

#### Cross-AI validation prompt

> Audit `density_prover.py`, which defines ∂_a ĥ and ∂_b ĥ for the Fourier-side kernel, integrates |derivative|^2 over [-T, T] with T chosen from a Gaussian tail heuristic, adds a Gaussian tail cap based on Amax, and sets S_a_hi, S_b_hi as outward-rounded L2 norms. Check the derivative formulas, the choice of T, and the tail cap formula to ensure they produce rigorous upper bounds at the requested precision.

---

#### JSON/CLI spec object

```json
{
  "module": "density_prover.py",
  "tool_id": "density_prover",
  "role": "density_sensitivity",
  "cli": {
    "description": "Compute L2 sensitivity norms S_a, S_b for density parameters a, b using core integral plus Gaussian tail cap.",
    "args": [
      { "flag": "--a-center",  "name": "a_center",  "required": true,  "type": "str", "default": null,  "notes": "Center value for parameter a (high-precision string)." },
      { "flag": "--b-center",  "name": "b_center",  "required": true,  "type": "str", "default": null,  "notes": "Center value for parameter b (high-precision string)." },
      { "flag": "--dps",       "name": "dps",       "required": false, "type": "int", "default": 300,   "notes": "Decimal precision for mpmath." },
      { "flag": "--out",       "name": "out",       "required": true,  "type": "str", "default": null,  "notes": "Path to primary JSON output." },
      { "flag": "--theory-out","name": "theory_out","required": false, "type": "str", "default": null,  "notes": "Optional path to auxiliary theory JSON." }
    ]
  },
  "outputs": [
    {
      "filename": "density_prover.json",
      "primary": true,
      "kind": "density_prover",
      "schema_version": "v2.1",
      "blocks": {
        "inputs": {
          "fields": [
            { "path": "inputs.a_center", "type": "str" },
            { "path": "inputs.b_center", "type": "str" },
            { "path": "inputs.dps",      "type": "str" }
          ]
        },
        "density_prover": {
          "fields": [
            { "path": "density_prover.T_core",    "type": "str" },
            { "path": "density_prover.S_a_hi",    "type": "str" },
            { "path": "density_prover.S_a_units", "type": "str" },
            { "path": "density_prover.S_b_hi",    "type": "str" },
            { "path": "density_prover.S_b_units", "type": "str" },
            { "path": "density_prover.PASS",      "type": "bool" }
          ]
        },
        "meta": {
          "fields": [
            { "path": "meta.tool",        "type": "str" },
            { "path": "meta.dps",         "type": "str" },
            { "path": "meta.created_utc", "type": "str" },
            { "path": "meta.sha256",      "type": "str" }
          ]
        }
      }
    }
  ]
}
```

## `core_integral_prover.py` 

**Role:**
Compute the gamma tail envelope at (T_0) from the window configuration and emit a normalized `gamma_tails` JSON block used by continuum and explicit-formula rollups.

---

#### CLI summary (v2.1)

* `--T0` *(str, required)*
  Cutoff height (T_0) (high-precision string).

* `--window-config` *(str, required)*
  Path to window JSON from `window_gen.py`.

* `--dps` *(int, default `200`)*
  Decimal precision for `mpmath`.

* `--out` *(str, required)*
  Output JSON path.

---

#### Window extraction

```python
mode, sigma, k0 = read_window(window_config)
```

`read_window`:

* Loads JSON, then searches in this order: root, `window`, `params`, `data`.
* Fields:

  * `sigma` (required),
  * `notch_k0` or `k0` (required),
  * `mode` (optional, defaults to `"gauss"` if missing).

All numeric values are converted to `mp.mpf` via `mp.mpf(str(...))`.

---

#### Gamma envelope model

```python
def derive_gamma_env_T0(sigma, k0, T0):
    x = sigma * k0 * T0
    val = mp.e ** (-(x ** 2) / 2) / (1 + x)
    return mp.mpf(val)
```

Derived quantities:

* `gamma_env = gamma_env_at_T0`
* `c1 = gamma_env * T0`
* `c2 = 0`
* `tails_total = gamma_env`

So the same scalar `gamma_env_at_T0` is also stored as `tails_total` for backwards compatibility.

---

#### JSON structure

```jsonc
{
  "kind": "gamma_tails",
  "inputs": {
    "T0": "<string>",
    "window_config_path": "<path>"
  },
  "gamma_tails": {
    "gamma_env_at_T0": "<string>",
    "c1": "<string>",
    "c2": "<string>",
    "tails_total": "<string>"
  },
  "meta": {
    "tool": "core_integral_prover",
    "dps": "<string>",
    "created_utc": "<ISO8601Z>"
  }
}
```

* All reals are serialized via `mpstr` (high-precision decimal strings).
* No `PASS` flag; this is a pure data block.

---

#### Validation tasks

1. **Window consistency:**
   Confirm that the `sigma` and `k0` extracted here match the values used in your other modules (e.g. `window_gen`, `fourier_inversion_cert`).

2. **Envelope sanity:**
   For typical values of `sigma`, `k0`, `T0`, verify that `gamma_env_at_T0` is small, monotone decreasing in `T0`, and behaves as expected under your theoretical gamma tail inequality.

3. **Downstream compatibility:**
   Check that `continuum_operator_rollup.py` and `explicit_formula.py` correctly pick up `gamma_tails.gamma_env_at_T0` as their canonical gamma budget (and only fall back to `tails_total` if necessary).

---

#### Cross-AI validation prompt

> Audit `core_integral_prover.py`, which reads sigma and k0 from window_gen’s JSON and defines gamma_env_at_T0 = exp(-(sigma*k0*T0)^2/2)/(1+sigma*k0*T0). Check whether this expression matches the gamma tail bound you derived for your kernel, and whether c1 = gamma_env*T0 and c2 = 0 are consistent with your tail decomposition elsewhere.

---

#### JSON/CLI spec object

```json
{
  "module": "core_integral_prover.py",
  "tool_id": "core_integral_prover",
  "role": "gamma_tail_env",
  "cli": {
    "description": "Compute the gamma tail envelope at T0 from the window configuration.",
    "args": [
      { "flag": "--T0",            "name": "T0",            "required": true,  "type": "str", "default": null,  "notes": "Cutoff height T0 (high-precision string)." },
      { "flag": "--window-config", "name": "window_config", "required": true,  "type": "str", "default": null,  "notes": "Path to window JSON from window_gen.py." },
      { "flag": "--dps",           "name": "dps",           "required": false, "type": "int", "default": 200,   "notes": "Decimal precision for mpmath." },
      { "flag": "--out",           "name": "out",           "required": true,  "type": "str", "default": null,  "notes": "Output JSON path." }
    ]
  },
  "outputs": [
    {
      "filename": "gamma_tails.json",
      "primary": true,
      "kind": "gamma_tails",
      "schema_version": "v2.1",
      "blocks": {
        "inputs": {
          "fields": [
            { "path": "inputs.T0",                 "type": "str" },
            { "path": "inputs.window_config_path", "type": "str" }
          ]
        },
        "gamma_tails": {
          "fields": [
            { "path": "gamma_tails.gamma_env_at_T0", "type": "str" },
            { "path": "gamma_tails.c1",              "type": "str" },
            { "path": "gamma_tails.c2",              "type": "str" },
            { "path": "gamma_tails.tails_total",     "type": "str" }
          ]
        },
        "meta": {
          "fields": [
            { "path": "meta.tool",        "type": "str" },
            { "path": "meta.dps",         "type": "str" },
            { "path": "meta.created_utc", "type": "str" }
          ]
        }
      }
    }
  ]
}
```

---

## `deconv_prover.py` 

**Role:**
Wiener-style deconvolution certificate. Given:

* explicit formula data (band margin, epsilon_eff),
* tails data (gamma and prime envelopes at (T_0)),
* minimum gain from Fourier inversion,

it proves that the **stopband error** of the deconvolution operator is safely below a **tail budget** derived from the tails.

Core inequality:

[
\text{total_error_hi} < \text{tail_budget_hi}.
]

---

#### CLI summary (v2.1)

* `--explicit` *(str, required)*
  Path to `explicit_formula.json`.

* `--tails` *(str, required)*
  Path to tails JSON (gamma + prime envelopes + (T_0)).

* `--fourier` *(str, required)*
  Path to `fourier_inversion_cert.json`.

* `--dps` *(int, default `400`)*
  `mpmath` precision.

* `--out` *(str, required)*
  Output JSON.

* `--verbose` *(flag)*
  Print detailed diagnostics.

---

#### Extraction utilities

* `read_band_margin(explicit_json)`:

  ```python
  coalesce(
    explicit_json,
    [
      ["explicit_formula", "epsilon_eff_lo"],
      ["explicit_formula", "band_margin_lo"],
    ],
    default="0"
  )
  ```

  Note: `band_margin_lo` is read but **not used** in the current math—only tails and min gain drive the inequality.

* `read_tails(tails_json)`:

  ```python
  gamma = coalesce(tails_json, [["gamma_env_at_T0"], ["tails","gamma_env_at_T0"]])
  prime = coalesce(tails_json, [["prime_env_at_T0"], ["tails","prime_env_at_T0"]])
  T0    = coalesce(tails_json, [["T0"], ["tails","T0"]])
  ```

* `read_min_gain(four_json)`:

  ```python
  m = coalesce(
    four_json,
    [
      ["closed_form_h", "m_lo"],   # preferred if present
      ["min_gain"],
      ["m_lo"],
    ],
    default=None
  )
  return mp.mpf(str(m)) if m is not None else mp.mpf("1.0")
  ```

So it allows future addition of `closed_form_h.m_lo` while supporting older schemas.

---

#### Math / inequality

Set precision:

```python
mp.dps = args.dps
```

Extracted:

```python
gamma, prime, T0  # mp.mpf
m_lo              # min gain
operator_norm_hi = 1 / m_lo
```

Tails → Gaussian parameter:

* If gamma or prime is non-positive, its log contribution is treated as `+∞`:

  ```python
  ln_gamma = -mp.log(gamma) if gamma > 0 else mp.inf
  ln_prime = -mp.log(prime) if prime > 0 else mp.inf
  B = max(ln_gamma, ln_prime) / (T0*T0)
  ```

Stopband tail integral:

[
\int_{T_0}^{\infty} e^{-2 B t^2},dt
]

implemented as:

```python
def gaussian_tail_integral(B, T0):
    f = lambda t: mp.e ** (-2 * B * t * t)
    return mp.quad(f, [T0, mp.inf])
```

Then:

```python
tail_int = gaussian_tail_integral(B, T0)
stopband_error_hi = mp.sqrt(tail_int)
total_error_hi = operator_norm_hi * stopband_error_hi
tail_budget_hi = max(gamma, prime)
PASS = bool(total_error_hi < tail_budget_hi)
```

So the operator norm amplifies a tail energy bound to produce an absolute error upper bound, which is compared to a per-tail budget.

---

#### JSON structure

```jsonc
{
  "kind": "deconv_prover",
  "inputs": {
    "explicit_path": "<path>",
    "tails_path": "<path>",
    "fourier_path": "<path>",
    "dps": "<string>"
  },
  "deconv_prover": {
    "T0": "<string>",
    "m_lo": "<string>",
    "operator_norm_hi": "<string>",
    "B_from_tails": "<string>",
    "stopband_error_hi": "<string>",
    "total_error_hi": "<string>",
    "tail_budget_hi": "<string>",
    "PASS": true
  },
  "meta": {
    "tool": "deconv_prover",
    "dps": "<string>",
    "created_utc": "<ISO8601Z>",
    "sha256": "<digest>"
  }
}
```

All numeric entries are passed through `mpf_str` so they are high-precision decimal strings.

---

#### Validation tasks

1. **Min gain path check:**
   Ensure your current `fourier_inversion_cert.json` actually provides a realistic `m_lo` (either via `closed_form_h.m_lo` or legacy fields), and that defaulting to `1.0` is acceptable only in obviously safe/sanity contexts.

2. **Tail consistency:**
   Confirm that `gamma`, `prime`, and `T0` in the tails JSON are the same quantities you used in `core_integral_prover` and `prime_tail_envelope`—the Gaussian stopband model hinges on that.

3. **Strictness of PASS test:**
   For some typical runs, compute `total_error_hi` and `tail_budget_hi` at higher `dps` and verify:

   * The inequality still holds.
   * The margin is not too razor-thin (you ideally want a comfortable safety gap).

4. **Band margin usage (future):**
   Decide whether `band_margin_lo` from `explicit_formula` should enter this module’s inequality or remain unused; right now it is read but not used, which is fine but worth documenting.

---

#### Cross-AI validation prompt

> Audit `deconv_prover.py`, which reads gamma_env(T0), prime_env(T0), and T0 from a tails JSON, a minimum gain m_lo from fourier_inversion_cert.json, and computes a stopband error bound total_error_hi = (1/m_lo) * sqrt(∫_{T0}^∞ exp(-2 B t^2) dt), with B = max(-ln gamma, -ln prime)/T0^2, then checks total_error_hi < max(gamma, prime). Verify that this Gaussian model is conservative for your kernel, that the choice of B is correct, and that handling of nonpositive gamma/prime is safe.

---

#### JSON/CLI spec object

```json
{
  "module": "deconv_prover.py",
  "tool_id": "deconv_prover",
  "role": "deconvolution_cert",
  "cli": {
    "description": "Wiener-style deconvolution certificate using tails and Fourier min gain.",
    "args": [
      { "flag": "--explicit", "name": "explicit", "required": true,  "type": "str", "default": null, "notes": "Path to explicit_formula.json." },
      { "flag": "--tails",    "name": "tails",    "required": true,  "type": "str", "default": null, "notes": "Path to tails JSON with gamma_env, prime_env, and T0." },
      { "flag": "--fourier",  "name": "fourier",  "required": true,  "type": "str", "default": null, "notes": "Path to fourier_inversion_cert.json." },
      { "flag": "--dps",      "name": "dps",      "required": false, "type": "int", "default": 400,  "notes": "mpmath precision." },
      { "flag": "--out",      "name": "out",      "required": true,  "type": "str", "default": null, "notes": "Output JSON path." },
      { "flag": "--verbose",  "name": "verbose",  "required": false, "type": "flag","default": false,"notes": "Print diagnostic output." }
    ]
  },
  "outputs": [
    {
      "filename": "deconv_prover.json",
      "primary": true,
      "kind": "deconv_prover",
      "schema_version": "v2.1",
      "blocks": {
        "inputs": {
          "fields": [
            { "path": "inputs.explicit_path", "type": "str" },
            { "path": "inputs.tails_path",    "type": "str" },
            { "path": "inputs.fourier_path",  "type": "str" },
            { "path": "inputs.dps",           "type": "str" }
          ]
        },
        "deconv_prover": {
          "fields": [
            { "path": "deconv_prover.T0",               "type": "str" },
            { "path": "deconv_prover.m_lo",             "type": "str" },
            { "path": "deconv_prover.operator_norm_hi", "type": "str" },
            { "path": "deconv_prover.B_from_tails",     "type": "str" },
            { "path": "deconv_prover.stopband_error_hi","type": "str" },
            { "path": "deconv_prover.total_error_hi",   "type": "str" },
            { "path": "deconv_prover.tail_budget_hi",   "type": "str" },
            { "path": "deconv_prover.PASS",             "type": "bool" }
          ]
        },
        "meta": {
          "fields": [
            { "path": "meta.tool",        "type": "str" },
            { "path": "meta.dps",         "type": "str" },
            { "path": "meta.created_utc", "type": "str" },
            { "path": "meta.sha256",      "type": "str" }
          ]
        }
      }
    }
  ]
}
```

---

## `continuum_operator_rollup.py` 

**Role:**
Continuum operator inequality rollup. Combines:

* band margin (from `band_cert.json`),
* prime block cap (from `prime_block_norm.json`),
* prime tail norm (from `prime_tail_envelope.json`),
* gamma tail envelope at (T_0) (from `gamma_tails.json`),
* grid error bound (from `grid_error_bound.json`),

into a single inequality:

[
\text{lhs_total} = \text{prime_block_cap} + \text{prime_tail_norm} + \text{grid_error_norm},
]
[
\epsilon_{\text{eff}} = \text{band_margin} - \text{gamma_tails},
]

and certifies `PASS` iff:

[
\text{lhs_total} \le \epsilon_{\text{eff}}.
]

---

#### CLI summary (v2.1)

* `--band-cert` *(str, required)*
  Path to `band_cert.json`.

* `--prime-block` *(str, required)*
  Path to `prime_block_norm.json`.

* `--prime-tail` *(str, required)*
  Path to `prime_tail_envelope.json`.

* `--gamma-tails` *(str, optional)*
  Path to `gamma_tails.json` from `core_integral_prover`. If omitted/missing, gamma term is treated as 0.

* `--grid-error` *(str, optional)*
  Path to `grid_error_bound.json` from `op_grid_error_bound`. If omitted/missing, grid error is treated as 0.

* `--dps` *(int, default `200`)*
  `mpmath` precision.

* `--out` *(str, required)*
  Output JSON path.

---

#### Schema-tolerant extractors

All go through `mpf_from_paths(js, paths, default)`:

* **Band margin:**

  ```python
  get_band_margin(js):
    paths = [
      ("band_cert", "band_margin_lo"),
      ("band_cert", "band_margin", "lo"),
      ("numbers", "band_margin"),
      ("band_margin",),
    ]
  ```

* **Prime block cap:**

  ```python
  get_prime_block_cap(js):
    paths = [
      ("prime_block_norm", "cap_total_hi"),
      ("prime_block_norm", "used_operator_norm"),
      ("numbers", "cap_total_hi"),
      ("used_operator_norm",),
      ("operator_norm_cap_hi",),
      ("operator_norm_cap",),
    ]
  ```

  Canonical is `prime_block_norm.cap_total_hi`; others are fallbacks.

* **Prime tail norm:**

  ```python
  get_prime_tail_norm(js):
    paths = [
      ("prime_tail", "norm"),
      ("numbers", "prime_tail_norm"),
      ("prime_tail_norm",),
    ]
  ```

  Canonical is `prime_tail.norm`.

* **Gamma at T0:**

  ```python
  get_gamma_env_T0(js):
    paths = [
      ("gamma_tails", "gamma_env_at_T0"),
      ("gamma_env_at_T0",),
      ("gamma_tails", "tails_total"),
      ("tails_total",),
    ]
    default="0"
  ```

  Canonical is `gamma_tails.gamma_env_at_T0`; falls back to `tails_total` or `0`.

* **Grid error:**

  ```python
  get_grid_error(js):
    paths = [
      ("grid_error_bound", "bound_hi"),
      ("numbers", "grid_error_norm"),
      ("grid_error_norm",),
    ]
    default="0"
  ```

---

#### Math / inequality

After loading JSONs (non-required ones may be skipped if path missing / file absent):

```python
band_margin    = get_band_margin(band_js)
prime_block_cap= get_prime_block_cap(pblk_js)
prime_tail_norm= get_prime_tail_norm(ptail_js)
gamma_env_T0   = get_gamma_env_T0(gamma_js)  # or 0 if not provided
grid_error_norm= get_grid_error(grid_js)     # or 0 if not provided

lhs_total   = prime_block_cap + prime_tail_norm + grid_error_norm
epsilon_eff = band_margin - gamma_env_T0
PASS        = bool(lhs_total <= epsilon_eff)
```

So the continuum inequality says: **all non-band continuum contributions (prime block, tail, grid error) fit within the effective margin left after subtracting gamma tails from the band margin.**

---

#### JSON structure

```jsonc
{
  "kind": "continuum_operator_cert",
  "inputs": {
    "band_cert_path": "<path>",
    "prime_block_path": "<path>",
    "prime_tail_path": "<path>",
    "gamma_tails_path": "<path or empty>",
    "grid_error_path": "<path or empty>"
  },
  "numbers": {
    "band_margin": "<string>",
    "prime_block_cap": "<string>",
    "prime_tail_norm": "<string>",
    "gamma_tails": "<string>",
    "grid_error_norm": "<string>",
    "lhs_total": "<string>",
    "epsilon_eff": "<string>"
  },
  "PASS": true,
  "meta": {
    "tool": "continuum_operator_rollup",
    "dps": "<string>",
    "created_utc": "<ISO8601Z>"
  }
}
```

All numeric entries serialized with `mpstr`.

---

#### Validation tasks

1. **Budget accounting sanity:**
   For a known “good” run, verify:

   * `band_margin` matches `band_cert`’s canonical margin.
   * `prime_block_cap` matches `prime_block_norm.prime_block_norm.cap_total_hi`.
   * `prime_tail_norm` matches `prime_tail.norm`.
   * `gamma_tails` matches `gamma_tails.gamma_env_at_T0` from `core_integral_prover`.
   * `grid_error_norm` matches `grid_error_bound.bound_hi`.

2. **Inequality margin:**
   Compute `epsilon_eff - lhs_total` for real runs and ensure the margin is comfortably positive, not just barely ≥ 0.

3. **Optional components behavior:**
   Run with and without `--gamma-tails` and `--grid-error`:

   * If omitted, confirm gamma and grid terms are treated as 0, and `PASS` behaves as expected.
   * This is useful for incremental testing.

4. **Schema pruning plan:**
   Once all generators are on v2.1, you can consider removing legacy paths from `mpf_from_paths` to make the rollup stricter.

---

#### Cross-AI validation prompt

> Audit `continuum_operator_rollup.py`, which reads band_margin from band_cert.json, prime_block_cap from prime_block_norm.json, prime_tail_norm from prime_tail_envelope.json, gamma_env_at_T0 from gamma_tails.json, and grid_error_norm from grid_error_bound.json, then forms lhs_total = prime_block_cap + prime_tail_norm + grid_error_norm and epsilon_eff = band_margin - gamma_env_T0, declaring PASS if lhs_total <= epsilon_eff. Check that this matches your theoretical continuum inequality and that the chosen scalar representatives (cap_total_hi, prime_tail.norm, gamma_env_at_T0, bound_hi) are the correct ones to use.

---

#### JSON/CLI spec object

```json
{
  "module": "continuum_operator_rollup.py",
  "tool_id": "continuum_operator_rollup",
  "role": "continuum_operator_cert",
  "cli": {
    "description": "Continuum operator inequality rollup combining band margin, prime block cap, prime tail, gamma tails, and grid error.",
    "args": [
      { "flag": "--band-cert",   "name": "band_cert",   "required": true,  "type": "str", "default": null, "notes": "Path to band_cert.json." },
      { "flag": "--prime-block", "name": "prime_block", "required": true,  "type": "str", "default": null, "notes": "Path to prime_block_norm.json." },
      { "flag": "--prime-tail",  "name": "prime_tail",  "required": true,  "type": "str", "default": null, "notes": "Path to prime_tail_envelope.json." },
      { "flag": "--gamma-tails", "name": "gamma_tails", "required": false, "type": "str", "default": null, "notes": "Path to gamma_tails.json (core_integral_prover)." },
      { "flag": "--grid-error",  "name": "grid_error",  "required": false, "type": "str", "default": null, "notes": "Path to grid_error_bound.json (op_grid_error_bound)." },
      { "flag": "--dps",         "name": "dps",         "required": false, "type": "int", "default": 200,  "notes": "mpmath precision." },
      { "flag": "--out",         "name": "out",         "required": true,  "type": "str", "default": null, "notes": "Output JSON path." }
    ]
  },
  "outputs": [
    {
      "filename": "continuum_operator_cert.json",
      "primary": true,
      "kind": "continuum_operator_cert",
      "schema_version": "v2.1",
      "blocks": {
        "inputs": {
          "fields": [
            { "path": "inputs.band_cert_path",  "type": "str" },
            { "path": "inputs.prime_block_path","type": "str" },
            { "path": "inputs.prime_tail_path", "type": "str" },
            { "path": "inputs.gamma_tails_path","type": "str" },
            { "path": "inputs.grid_error_path", "type": "str" }
          ]
        },
        "numbers": {
          "fields": [
            { "path": "numbers.band_margin",     "type": "str" },
            { "path": "numbers.prime_block_cap", "type": "str" },
            { "path": "numbers.prime_tail_norm", "type": "str" },
            { "path": "numbers.gamma_tails",     "type": "str" },
            { "path": "numbers.grid_error_norm", "type": "str" },
            { "path": "numbers.lhs_total",       "type": "str" },
            { "path": "numbers.epsilon_eff",     "type": "str" }
          ]
        },
        "root": {
          "fields": [
            { "path": "PASS", "type": "bool" }
          ]
        },
        "meta": {
          "fields": [
            { "path": "meta.tool",        "type": "str" },
            { "path": "meta.dps",         "type": "str" },
            { "path": "meta.created_utc", "type": "str" }
          ]
        }
      }
    }
  ]
}
```

## `band_cert.py` 

**Role:**
Rigorous **band certificate** using interval arithmetic: given a Gaussian-notch window and a bands JSON, it computes lower/upper bounds for
(|W(f)|) on each band and certifies a **global band margin**.

---

#### CLI summary (v2.1)

* `--window-config` *(str, required)*
  Path to window JSON from `window_gen.py` (kind `"window"`).

* `--bands` *(str, required)*
  Bands specification JSON (from `bands_make.py` or compatible).

* `--out` *(str, required)*
  Output `band_cert.json`.

* `--dps` *(int, default `220`)*
  `mpmath` precision.

* `--tol` *(str, default `"1e-30"`)*
  Subdivision tolerance for the interval refinement.

* `--max-parts` *(int, default `16384`)*
  Max subintervals per band.

* `--tqdm` *(flag)*
  Show per-band progress bar if `tqdm` is installed.

---

#### Window + bands

* `make_window(window_js)` expects a canonical Gaussian notch window:

  ```jsonc
  {
    "kind": "window",
    "mode": "gauss",
    "sigma": "...",
    "k0": "...",
    "window": {
      "mode": "gauss",
      "sigma": "...",
      "k0": "..."
    }
  }
  ```

  * Accepts either the top-level block or `window` sub-block as the source.
  * Requires `sigma > 0`, `k0 > 0`.
  * Constructs an **interval-valued** magnitude function:

    ```python
    I = iv.mpf([a, b])                   # interval in frequency
    g = iv.exp(-(I / sigma)**2)          # Gaussian envelope
    n = 1 - iv.exp(-(I / k0)**2)         # multiplicative notch
    w = g * n
    lo = max(w.a, 0)
    hi = max(w.b, 0)
    ```

* `parse_bands_generic(bands_js)` accepts multiple schemas:

  1. `[{ "left": "...", "right": "...", "label": "..." }, ...]`
  2. `{ "bands": [ ... ] }`
  3. `{ "bands": { name: { left, right, ... }, ... } }`
  4. `{ "named_grids": { name: { left, right, ... }, ... } }`

  All endpoints are converted to `mp.mpf` and require `left < right`.

---

#### Math / margin

For each band ([L,R]):

1. `band_min_bounds(W_abs_iv_on, L, R, max_parts, tol)` does heap-based interval subdivision:

   * Maintains a priority queue of subintervals keyed by the current lower bound.
   * Splits intervals until:

     * `hi - lo <= tol`, or
     * `parts >= max_parts`, or
     * global `best_hi - best_lo <= tol`.

2. Aggregates global:

   ```python
   glo_lo = min_band_lo   # min over all bands of the bandwise lower bound
   glo_hi = min_band_hi   # min over all bands of the bandwise upper bound
   ```

3. PASS condition:

   ```python
   PASS_bool = bool(glo_lo > 0)
   ```

   i.e., if the **global lower bound** for (|W(f)|) over all bands is strictly positive.

Optional: if any band has label `"critical"`, a `critical_band` entry is echoed.

---

#### JSON structure

```jsonc
{
  "kind": "band_cert",
  "created_utc": "<ISO8601Z>",
  "inputs": {
    "window_config_path": "<path>",
    "bands_path": "<path>",
    "mode": "gauss",
    "sigma": "<string>",
    "k0": "<string>",
    "dps": 220
  },
  "numbers": {
    "band_margin_lo": "<string>",
    "band_margin_hi": "<string>",
    "bands_count": 3
  },
  "band_cert": {
    "band_margin": {
      "lo": "<string>",
      "hi": "<string>"
    },
    "per_band": [
      {
        "label": "critical",
        "left": "<string>",
        "right": "<string>",
        "min_abs_lo": "<string>",
        "min_abs_hi": "<string>"
      }
      // ...
    ],
    "status": "PASS" | "FAIL",
    "critical_band": {
      "left": "<string>",
      "right": "<string>"
    } | null
  },
  "PASS": true,
  "meta": {
    "tool": "band_cert",
    "dps": 220,
    "sha256": "<digest>"
  }
}
```

All reals are stored as strings via `mp_str`; `bands_count`, `dps` remain ints.

---

#### Validation tasks

1. **Window consistency:**
   Confirm this Gaussian + notch expression is exactly the same spectral object used in `weil_kernel` / `fourier_inversion`, so the band margin is a true lower bound for the actual kernel.

2. **Interval safety:**
   Check that `band_min_bounds` cannot miss lower dips:

   * Test a few bands with a very small `tol` and a large `max_parts` and compare with a dense **pointwise** sample of `|W(f)|`.

3. **Margin usage downstream:**
   Make sure downstream modules (e.g., `continuum_operator_rollup`) always treat `band_margin_lo` as the official band margin, and only use `band_margin_hi` for diagnostics, not for inequalities.

---

#### Cross-AI validation prompt

> Audit `band_cert.py`, which uses mpmath interval arithmetic to bound |W(f)| for a Gaussian-notch window over each frequency band, then defines band_margin_lo as the global lower bound and sets PASS if band_margin_lo > 0. Check whether the interval model W_abs_iv_on (exp(-(t/sigma)^2)*(1-exp(-(t/k0)^2))) is correct, and whether the refinement strategy in band_min_bounds is sufficient to avoid underestimating the true minimum.

---

#### JSON/CLI spec object

```json
{
  "module": "band_cert.py",
  "tool_id": "band_cert",
  "role": "band_margin_cert",
  "cli": {
    "description": "Rigorous band certificate using interval arithmetic for the Gaussian-notch window.",
    "args": [
      { "flag": "--window-config", "name": "window_config", "required": true,  "type": "str", "default": null,   "notes": "Window JSON from window_gen.py (kind='window')." },
      { "flag": "--bands",         "name": "bands",         "required": true,  "type": "str", "default": null,   "notes": "Bands JSON (from bands_make.py or compatible)." },
      { "flag": "--out",           "name": "out",           "required": true,  "type": "str", "default": null,   "notes": "Output band_cert JSON." },
      { "flag": "--dps",           "name": "dps",           "required": false, "type": "int", "default": 220,    "notes": "Decimal precision for mpmath." },
      { "flag": "--tol",           "name": "tol",           "required": false, "type": "str", "default": "1e-30","notes": "Interval refinement tolerance." },
      { "flag": "--max-parts",     "name": "max_parts",     "required": false, "type": "int", "default": 16384,  "notes": "Maximum subdivisions per band." },
      { "flag": "--tqdm",          "name": "tqdm",          "required": false, "type": "flag","default": false,  "notes": "Show progress bar if tqdm is installed." }
    ]
  },
  "outputs": [
    {
      "filename": "band_cert.json",
      "primary": true,
      "kind": "band_cert",
      "schema_version": "v2.1",
      "blocks": {
        "inputs": {
          "fields": [
            { "path": "inputs.window_config_path", "type": "str" },
            { "path": "inputs.bands_path",         "type": "str" },
            { "path": "inputs.mode",               "type": "str" },
            { "path": "inputs.sigma",              "type": "str" },
            { "path": "inputs.k0",                 "type": "str" },
            { "path": "inputs.dps",                "type": "int" }
          ]
        },
        "numbers": {
          "fields": [
            { "path": "numbers.band_margin_lo", "type": "str" },
            { "path": "numbers.band_margin_hi", "type": "str" },
            { "path": "numbers.bands_count",    "type": "int" }
          ]
        },
        "band_cert": {
          "fields": [
            { "path": "band_cert.band_margin.lo", "type": "str" },
            { "path": "band_cert.band_margin.hi", "type": "str" },
            { "path": "band_cert.status",         "type": "str" },
            { "path": "band_cert.per_band[]",     "type": "list" },
            { "path": "band_cert.critical_band",  "type": "object|null" }
          ]
        },
        "root": {
          "fields": [
            { "path": "PASS", "type": "bool" }
          ]
        },
        "meta": {
          "fields": [
            { "path": "meta.tool",    "type": "str" },
            { "path": "meta.dps",     "type": "int" },
            { "path": "meta.sha256",  "type": "str" }
          ]
        }
      }
    }
  ]
}
```

---

## `bands_make.py` 

**Role:**
Create **exact bands + uniform grids** with proof-grade I/O: decimal endpoints, exact steps, deterministic JSON, and `sha256` in meta. Feeds `band_cert`, `fourier_inversion`, etc.

---

#### CLI summary (v2.1-ish)

* `--window-config` *(str, required)*
  Path to `window.json` (kind `"window"`) from `window_gen.py`.

* `--out` *(str, required)*
  Output bands JSON (e.g. `packs/rh/inputs/auto_bands.json`).

* `--digits` *(int, default `80`)*
  Decimal digits for endpoints, step size, and nodes.

* `--grid` *(int, default `6000`)*
  Number of grid points per band (≥ 2).

* `--critical-left`, `--critical-right` *(str, required)*
  Endpoints of the **critical band**.

* `--inner-left`, `--inner-right` *(str, optional)*
  Optional inner band.

* `--outer-left`, `--outer-right` *(str, optional)*
  Optional outer band.

All band endpoints are decimal strings.

---

#### Behavior / math

* Uses Python `decimal.Decimal` with precision `max(100, digits+20)`.

* For each band:

  ```python
  h = exact_step(left, right, grid)     # (right-left)/(grid-1)
  nodes = [left + i*h for i in range(grid)]
  assert left + h*(grid-1) == right
  ```

  * Step `h` and all `nodes` are quantized to `digits` decimal places.
  * An assertion ensures **exact closure**: final node matches `right` exactly.

* Bands and grids:

  * `flat_bands`: `[{ "label": "...", "left": "...", "right": "..." }, ...]`
  * `named_grids[label]`: `{ left, right, grid, h, nodes[...] }`.

* Meta includes system info (python version, OS, CPU, workers, digits, grid, runtime, created_utc, sha256).

---

#### JSON structure

```jsonc
{
  "kind": "bands",
  "version": "1.2",
  "source_window": {
    "window_config_path": "<path>",
    "mode": "gauss"
  },
  "bands": [
    { "label": "critical", "left": "<string>", "right": "<string>" },
    { "label": "inner",    "left": "<string>", "right": "<string>" },
    { "label": "outer",    "left": "<string>", "right": "<string>" }
  ],
  "named_grids": {
    "critical": {
      "left": "<string>",
      "right": "<string>",
      "grid": 6000,
      "h": "<string>",
      "nodes": ["<string>", "..."]
    }
    // ...
  },
  "critical_left": "<string>",
  "critical_right": "<string>",
  "grid_N": 6000,
  "bands_count": 3,
  "meta": {
    "tool": "bands_make",
    "digits": 80,
    "grid": 6000,
    "python": "...",
    "os": "...",
    "cpu": "...",
    "workers_detected": 16,
    "runtime_sec": "0.123456",
    "created_utc": "<ISO8601Z>",
    "sha256": "<digest>"
  }
}
```

---

#### Validation tasks

1. **Endpoint integrity:**
   For each band, confirm `nodes[0] == left` and `nodes[-1] == right` and that `h` is consistent: `right-left = (grid-1)*h`.

2. **Consistency with band_cert:**
   Verify that `band_cert.parse_bands_generic` correctly interprets both the `bands` list and `named_grids` dict form produced here.

3. **Digits vs dps:**
   Make sure your chosen `digits` is compatible with the `dps` you use in `band_cert` and other modules so you don’t lose effective precision from too-coarse decimal quantization.

---

#### Cross-AI validation prompt

> Audit `bands_make.py`, which uses Decimal to build exact uniform grids for each band with grid nodes satisfying left + h*(N-1) = right exactly, and writes a bands JSON with both bands[] and named_grids{}. Check whether this representation is sufficient to reconstruct the integration grids used in the spectral toolkit, and confirm that no rounding or overflow issues occur for your typical band endpoints and grid sizes.

---

#### JSON/CLI spec object

```json
{
  "module": "bands_make.py",
  "tool_id": "bands_make",
  "role": "bands_and_grids_generator",
  "cli": {
    "description": "Create exact bands and uniform grids from a window.json artifact.",
    "args": [
      { "flag": "--window-config",   "name": "window_config",   "required": true,  "type": "str", "default": null, "notes": "Path to window.json (kind='window')." },
      { "flag": "--out",             "name": "out",             "required": true,  "type": "str", "default": null, "notes": "Output bands JSON." },
      { "flag": "--digits",          "name": "digits",          "required": false, "type": "int", "default": 80,   "notes": "Decimal digits for endpoints, h, and nodes." },
      { "flag": "--grid",            "name": "grid",            "required": false, "type": "int", "default": 6000, "notes": "Uniform grid size per band (>=2)." },
      { "flag": "--critical-left",   "name": "critical_left",   "required": true,  "type": "str", "default": null, "notes": "Left endpoint of critical band." },
      { "flag": "--critical-right",  "name": "critical_right",  "required": true,  "type": "str", "default": null, "notes": "Right endpoint of critical band." },
      { "flag": "--inner-left",      "name": "inner_left",      "required": false, "type": "str", "default": null, "notes": "Optional inner band left." },
      { "flag": "--inner-right",     "name": "inner_right",     "required": false, "type": "str", "default": null, "notes": "Optional inner band right." },
      { "flag": "--outer-left",      "name": "outer_left",      "required": false, "type": "str", "default": null, "notes": "Optional outer band left." },
      { "flag": "--outer-right",     "name": "outer_right",     "required": false, "type": "str", "default": null, "notes": "Optional outer band right." }
    ]
  },
  "outputs": [
    {
      "filename": "bands.json",
      "primary": true,
      "kind": "bands",
      "schema_version": "1.2",
      "blocks": {
        "root": {
          "fields": [
            { "path": "kind",               "type": "str" },
            { "path": "version",            "type": "str" },
            { "path": "critical_left",      "type": "str" },
            { "path": "critical_right",     "type": "str" },
            { "path": "grid_N",             "type": "int" },
            { "path": "bands_count",        "type": "int" }
          ]
        },
        "source_window": {
          "fields": [
            { "path": "source_window.window_config_path", "type": "str" },
            { "path": "source_window.mode",               "type": "str" }
          ]
        },
        "bands": {
          "fields": [
            { "path": "bands[]",             "type": "list" }
          ]
        },
        "named_grids": {
          "fields": [
            { "path": "named_grids",         "type": "object" }
          ]
        },
        "meta": {
          "fields": [
            { "path": "meta.tool",           "type": "str" },
            { "path": "meta.digits",         "type": "int" },
            { "path": "meta.grid",           "type": "int" },
            { "path": "meta.python",         "type": "str" },
            { "path": "meta.os",             "type": "str" },
            { "path": "meta.cpu",            "type": "str" },
            { "path": "meta.workers_detected","type": "int" },
            { "path": "meta.runtime_sec",    "type": "str" },
            { "path": "meta.created_utc",    "type": "str" },
            { "path": "meta.sha256",         "type": "str" }
          ]
        }
      }
    }
  ]
}
```

---

## `bochner_psd_cert.py` 

**Role:**
Bochner-style **PSD certificate** for the Gaussian-notch window.
Analytically certifies that (\hat h(t)) is nonnegative for all (t), and provides a numeric sweep over ([-T, T]) for telemetry.

Window form:

[
\hat h(t) = e^{-(t/\sigma)^2},\bigl(1 - e^{-(t/k_0)^2}\bigr).
]

---

#### CLI summary

* `--window` *(str, required)*
  Path to `window.json` (various schemas supported; not necessarily v2.1-only).

* `--out` *(str, required)*
  Output JSON for the Bochner certificate.

* `--dps` *(int, default `200`)*
  Decimal precision (`mp.dps`).

* `--sweep-T` *(float, default `200.0`)*
  Half-width for numeric sweep ([-T, T]).

* `--sweep-steps` *(int, default `40001`)*
  Number of sample points in the sweep.

---

#### Window parsing

```python
def parse_window(path):
    js = load_json(path)
    mode  = coalesce(js, "mode", ("window","mode"), ("window","type"), default="gauss")
    sigma = coalesce(js, "sigma", "gauss_sigma",
                     ("window","sigma"), ("window","gauss_sigma"),
                     ("window","params","sigma"))
    k0    = coalesce(js, "notch_k0", "k0",
                     ("window","notch_k0"), ("window","params","notch_k0"),
                     ("notch","k0"), ("window","notch","k0"))

    if sigma is None: raise KeyError(...)
    if k0 is None:    raise KeyError(...)

    sigma = mp.mpf(str(sigma))
    k0    = mp.mpf(str(k0))
    return mode, sigma, k0, js
```

So it supports both legacy (`notch_k0`) and newer (`k0`) fields, top-level or nested.

---

#### Math / PSD certificate

* Spectral density:

  ```python
  def hhat(t, sigma, k0):
      return mp.e**(-(t/sigma)**2) * (1 - mp.e**(-(t/k0)**2))
  ```

* Analytic PSD check:

  ```python
  def analytic_psd_holds(sigma, k0):
      # sigma>0, k0>0 => exp(-(t/s)^2) >= 0 and 1-exp(-(t/k0)^2) >= 0
      return (sigma > 0) and (k0 > 0)
  ```

  This is based on the fact that for all real (t):

  * (e^{-(t/\sigma)^2} \ge 0)
  * (e^{-(t/k_0)^2} \in (0,1]), so (1 - e^{-(t/k_0)^2} \in [0,1))
  * Product is ≥ 0, thus Bochner ⇒ PSD.

* Numeric sweep for telemetry:

  ```python
  def numeric_sweep(sigma, k0, T=100.0, steps=20001):
      T = mp.mpf(T)
      steps = max(int(steps), 2)
      mn = mp.inf
      argmin = mp.ninf
      for i in range(steps):
          t = -T + (2*T)*mp.mpf(i)/(steps-1)
          val = hhat(t, sigma, k0)
          if val < mn:
              mn = val
              argmin = t
      return mn, argmin
  ```

* Main:

  ```python
  mode, sigma, k0, wraw = parse_window(args.window)
  passed = analytic_psd_holds(sigma, k0)
  min_val, t_at_min = numeric_sweep(sigma, k0, T=args.sweep_T, steps=args.sweep_steps)
  ```

---

#### JSON structure

```jsonc
{
  "weil_psd_bochner": {
    "PASS": true,
    "reason": "nonnegative_spectral_density: exp(-...)^2) * (1 - exp(-(t/k0)^2)) >= 0 for all real t; Bochner ⇒ PSD",
    "certificate": {
      "type": "Bochner",
      "mode": "gauss",
      "sigma": "<string>",
      "notch_k0": "<string>"
    },
    "eval": {
      "min_hat_h_sample": "<string>",
      "t_at_min": "<string>",
      "sweep_T": 200.0,
      "sweep_steps": 40001
    },
    "window_echo": { /* full window.json content */ }
  },
  "meta": {
    "tool": "bochner_psd_cert",
    "dps": "<string>",
    "created_utc": "<ISO8601Z>"
  },
  "kind": "weil_psd_bochner"
}
```

* `PASS` is purely from the analytic logic; the numeric sweep does **not** affect PASS, it’s telemetry.

---

#### Validation tasks

1. **Kernel match:**
   Confirm that this (\hat h(t)) is exactly the Fourier transform of the **time-domain kernel** used elsewhere (especially in `weil_kernel`, `fourier_inversion_cert`). Any mismatch would decouple the Bochner certificate from the actual kernel.

2. **Window schema compatibility:**
   With the new `window_gen` v2.1, make sure at least one of the `coalesce` paths always hits (`sigma`, `k0`) for your actual artifacts (e.g., top-level `sigma`/`k0`).

3. **Numeric sweep sanity:**
   For a few runs, verify that `min_hat_h_sample` is nonnegative and close to 0 near the expected minimum (usually at or near 0). If you ever see a significantly negative minimum, that’s a red flag (either numerical or conceptual).

---

#### Cross-AI validation prompt

> Audit `bochner_psd_cert.py`, which defines hhat(t) = exp(-(t/sigma)^2)*(1-exp(-(t/k0)^2)) and claims this is ≥ 0 for all real t when sigma,k0>0, using this to certify PSD via Bochner’s theorem. Check the logic of the analytic_psd_holds() function, verify that the assumed frequency-domain kernel matches the rest of the toolkit, and consider whether there are any edge cases (e.g., sigma or k0 extremely small) that could cause numerical issues in the sweep.

---

#### JSON/CLI spec object

```json
{
  "module": "bochner_psd_cert.py",
  "tool_id": "bochner_psd_cert",
  "role": "bochner_psd_cert",
  "cli": {
    "description": "Bochner PSD certificate for the Gaussian-notch window with numeric sweep telemetry.",
    "args": [
      { "flag": "--window",     "name": "window",     "required": true,  "type": "str", "default": null,  "notes": "Path to window.json (various schemas allowed)." },
      { "flag": "--out",        "name": "out",        "required": true,  "type": "str", "default": null,  "notes": "Output Bochner PSD certificate JSON." },
      { "flag": "--dps",        "name": "dps",        "required": false, "type": "int", "default": 200,   "notes": "mpmath precision for sigma,k0 and numeric sweep." },
      { "flag": "--sweep-T",    "name": "sweep_T",    "required": false, "type": "float","default": 200.0,"notes": "Half-width for sample interval [-T, T]." },
      { "flag": "--sweep-steps","name": "sweep_steps","required": false, "type": "int", "default": 40001, "notes": "Number of sample points in the sweep." }
    ]
  },
  "outputs": [
    {
      "filename": "weil_psd_bochner.json",
      "primary": true,
      "kind": "weil_psd_bochner",
      "schema_version": "v2.1",
      "blocks": {
        "root": {
          "fields": [
            { "path": "kind",                "type": "str" }
          ]
        },
        "bochner": {
          "fields": [
            { "path": "weil_psd_bochner.PASS",                     "type": "bool" },
            { "path": "weil_psd_bochner.reason",                   "type": "str" },
            { "path": "weil_psd_bochner.certificate.type",         "type": "str" },
            { "path": "weil_psd_bochner.certificate.mode",         "type": "str" },
            { "path": "weil_psd_bochner.certificate.sigma",        "type": "str" },
            { "path": "weil_psd_bochner.certificate.notch_k0",     "type": "str" },
            { "path": "weil_psd_bochner.eval.min_hat_h_sample",    "type": "str" },
            { "path": "weil_psd_bochner.eval.t_at_min",            "type": "str" },
            { "path": "weil_psd_bochner.eval.sweep_T",             "type": "number" },
            { "path": "weil_psd_bochner.eval.sweep_steps",         "type": "int" },
            { "path": "weil_psd_bochner.window_echo",              "type": "object" }
          ]
        },
        "meta": {
          "fields": [
            { "path": "meta.tool",           "type": "str" },
            { "path": "meta.dps",            "type": "str" },
            { "path": "meta.created_utc",    "type": "str" }
          ]
        }
      }
    }
  ]
}
```

## `analytic_tail_fit.py` 

**Role:**
Fit **analytic 1/T^a tail models** to existing numeric tails in a PROOF_PACKET, and collect the key constants into a single JSON:

* pulls `epsilon_eff_lo` from `continuum_operator_cert.json`
* pulls `grid_error_hi` from `grid_error_bound.json`
* pulls prime tail `(T0, env_T0_hi)` from `prime_tail_envelope.json`
* pulls gamma tail `(T0, gamma_env_at_T0)` from `gamma_tails.json` (v2.1) or `gamma_tail.json` (legacy)
* converts each numeric tail into a model `C / T^a` at its own T0.

---

#### CLI summary

* `--packet-dir` *(str, required)*
  Path to PROOF_PACKET directory.

* `--Ap` *(str, default `"1.0"`)*
  Prime-tail exponent (a_p) in model (C_p / T^{a_p}).

* `--Ag` *(str, default `"1.0"`)*
  Gamma-tail exponent (a_g) in model (C_g / T^{a_g}).

* `--out` *(str, optional)*
  Output JSON path; default `<packet-dir>/analytic_tail_fit.json`.

* `--dps` *(int, default `220`)*
  `mpmath.dps` precision.

---

#### Inputs consumed (relative to `packet-dir`)

* `continuum_operator_cert.json`
* `grid_error_bound.json`
* `prime_tail_envelope.json`
* `gamma_tails.json` (preferred, v2.1) or `gamma_tail.json` (legacy fallback)

If any required file is missing or required fields cannot be found, the script prints an error and exits with code 1.

---

#### Data extraction & math

1. **Effective epsilon** from continuum rollup:

   ```python
   eps_eff_s = coalesce(
       cont,
       [["numbers", "epsilon_eff"], ["numbers", "eps_eff"]],
       None
   )
   eps_eff_lo = mp.mpf(str(eps_eff_s))
   ```

2. **Grid error bound**:

   ```python
   grid_hi_s = coalesce(
       grid,
       [["grid_error_bound", "bound_hi"], ["numbers", "grid_error_norm"]],
       None
   )
   grid_hi = mp.mpf(str(grid_hi_s))
   ```

3. **Prime tail T0 and envelope at T0**:

   ```python
   T0_pt_s = coalesce(pt, [["inputs","T0"], ["T0"], ["prime_tail","T0"]])
   env_pt_s = coalesce(
       pt,
       [["prime_tail","env_T0_hi"],
        ["prime_tail_envelope","env_T0_hi"],
        ["numbers","prime_tail_norm"]]
   )
   T0_pt  = mp.mpf(str(T0_pt_s))
   env_pt = mp.mpf(str(env_pt_s))
   ```

4. **Gamma tail T0 and envelope at T0** (supports v2.1 + legacy):

   ```python
   T0_gt_s = coalesce(gt, [["inputs","T0"], ["T0"], ["gamma_tail","T0"]])
   env_gt_s = coalesce(
       gt,
       [["gamma_tails","gamma_env_at_T0"],
        ["gamma_tail","gamma_env_at_T0"],
        ["gamma_env_at_T0"]]
   )
   T0_gt  = mp.mpf(str(T0_gt_s))
   env_gt = mp.mpf(str(env_gt_s))
   ```

5. **Exponents:**

   ```python
   a_p = mp.mpf(str(args.Ap))
   a_g = mp.mpf(str(args.Ag))
   # require a_p > 0, a_g > 0
   ```

6. **Analytic model constants** (one-point fit at T0):

   For model (C / T^a \ge \text{env}(T)) and forcing equality at (T_0),

   ```python
   C_prime = env_pt * (T0_pt ** a_p)
   C_gamma = env_gt * (T0_gt ** a_g)
   ```

   So for (T \ge T_0):

   * prime: ( C_p/T^{a_p} \ge \text{env}_\text{prime}(T) )
   * gamma: ( C_g/T^{a_g} \ge \text{env}_\gamma(T) )

---

#### JSON structure

```jsonc
{
  "kind": "analytic_tail_fit",
  "inputs": {
    "packet_dir": "<packet-dir>",
    "Ap": "<string>",          // exponent a_p
    "Ag": "<string>",          // exponent a_g
    "dps": "<string>"
  },
  "bounds": {
    "eps_eff_lo": "<string>",
    "grid_error_hi": "<string>",
    "prime_tail": {
      "C": "<string>",
      "a": "<string>",
      "T0": "<string>",
      "env_T0_hi": "<string>"
    },
    "gamma_tail": {
      "C": "<string>",
      "a": "<string>",
      "T0": "<string>",
      "env_T0_hi": "<string>"
    }
  },
  "meta": {
    "tool": "analytic_tail_fit",
    "dps": "<string>",
    "created_utc": "<ISO8601Z>"
  }
}
```

All numeric fields in `bounds` are serialized with `mp_str` at current `mp.dps`.

---

#### Validation tasks

1. **Field path sanity:**
   Confirm that v2.1 `continuum_operator_cert.json`, `grid_error_bound.json`, `prime_tail_envelope.json`, and `gamma_tails.json` all populate the expected paths, so no legacy fallbacks are needed.

2. **Model check:**
   For a chosen run, check that for several (T \ge T_0):

   * `env_prime_numeric(T) <= C_prime / T^a_p`,
   * `env_gamma_numeric(T) <= C_gamma / T^a_g`.

3. **Sensitivity to Ap/Ag:**
   Try varying `Ap`, `Ag` and confirm resulting `C` values behave as expected and remain compatible with later analytic arguments (e.g., integrability, decay rates).

---

#### Cross-AI validation prompt

> Audit `analytic_tail_fit.py`, which reads epsilon_eff_lo, grid_error_hi, and numeric tails at T0 from PROOF_PACKET JSONs, then fits analytic models C_prime/T^Ap and C_gamma/T^Ag with C = env_T0_hi * T0^a. Check that the extracted values (epsilon_eff, grid bound, T0s, envelopes) are the correct ones from your pipeline, and verify that the resulting tail models are conservative for T >= T0.

---

#### JSON/CLI spec object

```json
{
  "module": "analytic_tail_fit.py",
  "tool_id": "analytic_tail_fit",
  "role": "analytic_tail_model_fit",
  "cli": {
    "description": "Fit analytic 1/T^a tail models for prime and gamma tails using existing PROOF_PACKET artifacts.",
    "args": [
      { "flag": "--packet-dir", "name": "packet_dir", "required": true,  "type": "str", "default": null,  "notes": "Path to PROOF_PACKET directory containing continuum_operator_cert.json, grid_error_bound.json, prime_tail_envelope.json, gamma_tails.json/gamma_tail.json." },
      { "flag": "--Ap",         "name": "Ap",         "required": false, "type": "str", "default": "1.0", "notes": "Exponent a_p for prime tail model." },
      { "flag": "--Ag",         "name": "Ag",         "required": false, "type": "str", "default": "1.0", "notes": "Exponent a_g for gamma tail model." },
      { "flag": "--out",        "name": "out",        "required": false, "type": "str", "default": null,  "notes": "Output JSON path (default: <packet-dir>/analytic_tail_fit.json)." },
      { "flag": "--dps",        "name": "dps",        "required": false, "type": "int", "default": 220,   "notes": "mpmath precision." }
    ]
  },
  "outputs": [
    {
      "filename": "analytic_tail_fit.json",
      "primary": true,
      "kind": "analytic_tail_fit",
      "schema_version": "v2.1",
      "blocks": {
        "inputs": {
          "fields": [
            { "path": "inputs.packet_dir", "type": "str" },
            { "path": "inputs.Ap",         "type": "str" },
            { "path": "inputs.Ag",         "type": "str" },
            { "path": "inputs.dps",        "type": "str" }
          ]
        },
        "bounds": {
          "fields": [
            { "path": "bounds.eps_eff_lo",                  "type": "str" },
            { "path": "bounds.grid_error_hi",               "type": "str" },
            { "path": "bounds.prime_tail.C",                "type": "str" },
            { "path": "bounds.prime_tail.a",                "type": "str" },
            { "path": "bounds.prime_tail.T0",               "type": "str" },
            { "path": "bounds.prime_tail.env_T0_hi",        "type": "str" },
            { "path": "bounds.gamma_tail.C",                "type": "str" },
            { "path": "bounds.gamma_tail.a",                "type": "str" },
            { "path": "bounds.gamma_tail.T0",               "type": "str" },
            { "path": "bounds.gamma_tail.env_T0_hi",        "type": "str" }
          ]
        },
        "meta": {
          "fields": [
            { "path": "meta.tool",        "type": "str" },
            { "path": "meta.dps",         "type": "str" },
            { "path": "meta.created_utc", "type": "str" }
          ]
        }
      }
    }
  ]
}
```

---

##. `analytic_bounds.py` 

**Role:**
Emit **simple analytic helper bounds**:

* Gamma tail constants (c_1(\sigma), c_2(\sigma)) as coarse sigma-dependent envelopes.
* Prime tail constant (C(K, A') = 2 (K+1) A').

Intended as upstream parameter providers for other modules / paperwork, not a deep proof step.

---

#### CLI summary

* `--sigma` *(str, default `"6.0"`)*
  Gaussian width parameter.

* `--A-prime` *(str, default `"1.2762"`, dest=`A_prime`)*
  Constant (A') for prime tail inequalities.

* `--K` *(int, default `3`)*
  Integer parameter (K) in (C(K, A')).

* `--out` *(str, required)*
  Output JSON path.

* `--dps` *(int, default `220`)*
  `mpmath.dps` precision.

---

#### Math

1. **Gamma tail constants:**

   ```python
   def gamma_tail_constants(sigma):
       sigma = mp.mpf(sigma)
       c1 = 1 + 1/sigma
       c2 = 1 + 1/(sigma*sigma)
       return c1, c2
   ```

   Simple monotone-decreasing in (\sigma), with asymptotics:

   * (\sigma \to \infty): (c_1 \to 1), (c_2 \to 1)
   * (\sigma \to 0^+): both blow up.

2. **Prime tail constant:**

   ```python
   def prime_tail_constant(A_prime, K=3):
       return 2 * (K + 1) * mp.mpf(A_prime)
   ```

   So:

   [
   C(K, A') = 2 (K+1) A'.
   ]

All numeric outputs are serialized using `mp_str` at current `mp.dps`.

---

#### JSON structure

```jsonc
{
  "kind": "analytic_bounds",
  "inputs": {
    "sigma": "<string>",
    "A_prime": "<string>",
    "K": 3,
    "dps": "<string>"
  },
  "analytic_bounds": {
    "gamma": {
      "c1": "<string>",
      "c2": "<string>"
    },
    "prime": {
      "C": "<string>",
      "K": 3,
      "A_prime": "<string>"
    }
  },
  "meta": {
    "tool": "analytic_bounds",
    "dps": "<string>",
    "created_utc": "<ISO8601Z>",
    "sha256": "<digest>"
  }
}
```

* File is written twice: first without `sha256`, then with `sha256` filled via `write_json_with_sha`.

---

#### Validation tasks

1. **Use-case alignment:**
   Confirm how `c1`, `c2`, and `C` are used downstream (e.g., in tail integrals or inequalities) so that this simple form is sufficient and not too loose.

2. **Sigma dependence:**
   Check for your typical `sigma` range that `c1`, `c2` have the right magnitude compared to more precise gamma tail computations (e.g., from `gamma_tails.json`), and adjust the formulas if you want a tighter envelope.

3. **Prime constant sanity:**
   For your chosen (A') and (K), confirm that the resulting `C` is compatible with the inequalities in your prime tail model (e.g., `prime_tail_envelope` / analytic arguments).

---

#### Cross-AI validation prompt

> Audit `analytic_bounds.py`, which defines gamma tail envelopes c1 = 1 + 1/sigma, c2 = 1 + 1/sigma^2 and a prime tail constant C(K, A') = 2*(K+1)*A'. Check whether these formulas are consistent with the analytic bounds used in your RH tail estimates, and whether any sharper but still simple forms would be preferable for your final documentation.

---

#### JSON/CLI spec object

```json
{
  "module": "analytic_bounds.py",
  "tool_id": "analytic_bounds",
  "role": "analytic_helper_bounds",
  "cli": {
    "description": "Emit simple analytic helper bounds for gamma and prime tails.",
    "args": [
      { "flag": "--sigma",   "name": "sigma",   "required": false, "type": "str", "default": "6.0",    "notes": "Gaussian width parameter." },
      { "flag": "--A-prime", "name": "A_prime", "required": false, "type": "str", "default": "1.2762", "notes": "Prime-tail base constant A'." },
      { "flag": "--K",       "name": "K",       "required": false, "type": "int", "default": 3,        "notes": "Integer K in prime tail constant C(K, A')." },
      { "flag": "--out",     "name": "out",     "required": true,  "type": "str", "default": null,     "notes": "Output JSON path." },
      { "flag": "--dps",     "name": "dps",     "required": false, "type": "int", "default": 220,      "notes": "mpmath precision." }
    ]
  },
  "outputs": [
    {
      "filename": "analytic_bounds.json",
      "primary": true,
      "kind": "analytic_bounds",
      "schema_version": "v2.1",
      "blocks": {
        "inputs": {
          "fields": [
            { "path": "inputs.sigma",   "type": "str" },
            { "path": "inputs.A_prime","type": "str" },
            { "path": "inputs.K",      "type": "int" },
            { "path": "inputs.dps",    "type": "str" }
          ]
        },
        "analytic_bounds": {
          "fields": [
            { "path": "analytic_bounds.gamma.c1",  "type": "str" },
            { "path": "analytic_bounds.gamma.c2",  "type": "str" },
            { "path": "analytic_bounds.prime.C",   "type": "str" },
            { "path": "analytic_bounds.prime.K",   "type": "int" },
            { "path": "analytic_bounds.prime.A_prime", "type": "str" }
          ]
        },
        "meta": {
          "fields": [
            { "path": "meta.tool",        "type": "str" },
            { "path": "meta.dps",         "type": "str" },
            { "path": "meta.created_utc", "type": "str" },
            { "path": "meta.sha256",      "type": "str" }
          ]
        }
      }
    }
  ]
}
```
